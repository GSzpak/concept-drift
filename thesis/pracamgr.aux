\relax 
\citation{1}
\citation{2}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Wprowadzenie}{5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{r:wprowadzenie}{{1}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Uczenie z nadzorem a \textit  {concept drift}}{5}}
\newlabel{s:superv}{{1.1}{5}}
\citation{3}
\citation{4}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Schemat uczenia z nadzorem \relax }}{6}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{supervised}{{1.1}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Formalizacja problemu}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Paradygmaty uczenia si\k e}{6}}
\newlabel{ss:pardigms}{{1.2.1}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Paradygmaty uczenia w teorii uczenia maszynowego. We wszystkich przypadkach zak\IeC {\l }adamy, \.ze zbi\'or $X_{train}$ jest dost\k epny podczas uczenia, podczas gdy zbi\'or $Y_{test}$ nie jest znany.\relax }}{7}}
\newlabel{t:paradigms}{{1.1}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Ewolucja poj\k e\'c a \textit  {overfitting}}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces \textit  {Concept drift} a \textit  {overfitting} - obni\.zony wynik modelu 1. przy walidacji krzy\.zowej \'swiadczy o przeuczeniu, a nie wyst\k epowaniu ewoluuj\k acych poj\k e\'c. W drugim przypadku model mimo dobrej umiej\k etno\'sci klasyfikacji element\'ow pochodz\k acych z rozk\IeC {\l }adu $D^{source}$, cierpi na spadek jako\'sci przy ewaluacji na zbiorze pochodz\k acym z rozk\IeC {\l }adu $D^{target}$.\relax }}{8}}
\newlabel{t:overfit}{{1.2}{8}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Opis przeprowadzanego eksperymentu}{9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{r:experiment}{{2}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Przedstawienie badanego problemu}{9}}
\newlabel{s:problem}{{2.1}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Opis zbioru danych}{9}}
\newlabel{ss:data}{{2.1.1}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Rozmieszczenie czujnik\'ow na ciele stra\.zaka \relax }}{9}}
\newlabel{fireman}{{2.1}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Rozk\IeC {\l }ad klas w zbiorze treningowym \relax }}{10}}
\newlabel{classes}{{2.2}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Ewaluacja jako\'sci klasyfikatora}{11}}
\newlabel{ss:evaluation}{{2.1.2}{11}}
\newlabel{bac}{{2.2}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Opis u\.zytych klasyfikator\'ow}{11}}
\newlabel{s:klasyfikatory}{{2.2}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Klasyfikator liniowy}{11}}
\newlabel{ss:linear}{{2.2.1}{11}}
\@writefile{toc}{\contentsline {subsubsection}{Klasyfikacja oparta na regresji logistycznej (\textit  {logit})}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Wykres funkcji sigmoidalnej \relax }}{12}}
\newlabel{sigmoid}{{2.3}{12}}
\@writefile{toc}{\contentsline {subsubsection}{Maszyna wektor\'ow no\'snych}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces P\IeC {\l }aszczyzna $H_1$ nie rozdziela klas.   P\IeC {\l }aszczyzna $H_2$ rozdziela je, ale z niewielkim marginesem.  P\IeC {\l }aszczyzna $H_3$ rozdziela je z maksymalnym marginesem. \relax }}{12}}
\newlabel{svm}{{2.4}{12}}
\@writefile{toc}{\contentsline {subsubsection}{Klasyfikator "jeden przeciwko wszystkim"}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Lasy losowe}{13}}
\newlabel{ss:random_forest}{{2.2.2}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Przyk\IeC {\l }adowe drzewo decyzyjne \relax }}{13}}
\newlabel{dec_tree}{{2.5}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Przyk\IeC {\l }ad Ewolucji poj\k e\'c w analizowanym zbiorze}{14}}
\newlabel{s:data_concept_drift}{{2.3}{14}}
\citation{6}
\citation{7}
\citation{8}
\citation{9}
\citation{8}
\citation{9}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Ekstrakcja cech z szereg\'ow czasowych}{15}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{c:features}{{3}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Metody klasyfikacji szereg\'ow czasowych}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Proces ekstrakcji cech}{15}}
\newlabel{s:extraction}{{3.2}{15}}
\newlabel{d:series}{{3.2.1}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Reprezentacje pochodne szeregu czasowego}{16}}
\newlabel{ss:representations}{{3.2.1}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Po lewej wida\'c oryginalny zbi\'or danych, natomiast po prawej - drug\k a pochodn\k a po czasie \relax }}{16}}
\newlabel{example}{{3.1}{16}}
\@writefile{toc}{\contentsline {subsubsection}{Pochodna szeregu po czasie}{16}}
\@writefile{toc}{\contentsline {subsubsection}{Ca\IeC {\l }ka szeregu po czasie}{17}}
\@writefile{toc}{\contentsline {subsubsection}{Transformacja Fouriera}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Cosinusowe fale $s_1$, $s_2$, $s_3$ daj\k a razem bardziej z\IeC {\l }o\.zony sygna\IeC {\l } \relax }}{17}}
\newlabel{fourier}{{3.2}{17}}
\@writefile{toc}{\contentsline {subsubsection}{Transformacja falkowa}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Wykres falki Haara \relax }}{19}}
\newlabel{haar}{{3.3}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Statystyki wyliczane z reprezentacji szeregu}{19}}
\newlabel{ss:feaures}{{3.2.2}{19}}
\citation{11}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Rozk\IeC {\l }ady o ujemnym (pierwszy wykres) i dodatnim (drugi wykres) wsp\'o\IeC {\l }czynniku sko\'sno\'sci \relax }}{21}}
\newlabel{skew}{{3.4}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Kszta\IeC {\l }t rozk\IeC {\l }adu w zale\.zno\'sci od warto\'sci kurtozy \relax }}{21}}
\newlabel{kurthosis}{{3.5}{21}}
\newlabel{d:pearson}{{3.2.2}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Przyk\IeC {\l }adowe wykresy danych $(x, y)$ i odpowiadaj\k ace im warto\'sci wsp\'o\IeC {\l }czynnika korelacji liniowej Pearsona \relax }}{23}}
\newlabel{pearson}{{3.6}{23}}
\newlabel{d:peak}{{3.2.3}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Pozosta\IeC {\l }e cechy}{23}}
\newlabel{ss:additional}{{3.2.3}{23}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Redukcja \textit  {concept drift} poprzez selekcj\k e cech}{25}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{r:drift_reduction}{{4}{25}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Sprowadzenie problemu adaptacji dziedziny do problemu klasyfikacji}{25}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Jako\'s\'c klasyfikacji na wyekstrahowanych cechach\relax }}{25}}
\newlabel{t:res1}{{4.1}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Przyk\IeC {\l }adowy rozk\IeC {\l }ad jako\'sci cech dla problemu klasyfikacji oraz wykrywania ewoluuj\k acych poj\k e\'c \relax }}{26}}
\newlabel{drift_example}{{4.1}{26}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Miary jako\'sci cech}{27}}
\@writefile{toc}{\contentsline {subsubsection}{Wsp\'o\IeC {\l }czynnik korelacji Pearsona}{27}}
\@writefile{toc}{\contentsline {subsubsection}{Test $\chi ^2$}{27}}
\@writefile{toc}{\contentsline {subsubsection}{Informacja wzajemna}{27}}
\newlabel{entropy}{{4.2.1}{27}}
\@writefile{toc}{\contentsline {subsubsection}{Jednoczynnikowa analiza wariancji}{28}}
\@writefile{toc}{\contentsline {subsubsection}{Zysk Giniego}{28}}
\newlabel{gini_index}{{4.2.2}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Wykrywanie ewolucji poj\k e\'c mi\k edzy zbiorem treningowym a testowym}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Wyniki eksperyment\'ow}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Rozk\IeC {\l }ad jako\'sci cech przy u\.zyciu informacji wzajemnej \relax }}{30}}
\newlabel{tt_mutual_info}{{4.2}{30}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Jako\'s\'c klasyfikacji dla r\'o\.znych warto\'sci progowych przy u\.zyciu informacji wzajemnej i regresji logistycznej\relax }}{30}}
\newlabel{t:tt_mutual_info_logit}{{4.2}{30}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Jako\'s\'c klasyfikacji dla r\'o\.znych warto\'sci progowych przy u\.zyciu informacji wzajemnej i SVM\relax }}{31}}
\newlabel{t:tt_mutual_info_lsvm}{{4.3}{31}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Jako\'s\'c klasyfikacji dla r\'o\.znych warto\'sci progowych przy u\.zyciu informacji wzajemnej i las\'ow losowych\relax }}{31}}
\newlabel{t:tt_mutual_info_random}{{4.4}{31}}
\@writefile{toc}{\contentsline {subsubsection}{Jednoczynnikowa analiza wariancji}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Rozk\IeC {\l }ad jako\'sci cech przy u\.zyciu jednoczynnikowej analizy wariancji \relax }}{32}}
\newlabel{tt_anova}{{4.3}{32}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Jako\'s\'c klasyfikacji dla r\'o\.znych warto\'sci progowych przy u\.zyciu analizy wariancji i regresji logistycznej\relax }}{33}}
\newlabel{t:tt_anova_logit}{{4.5}{33}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Jako\'s\'c klasyfikacji dla r\'o\.znych warto\'sci progowych przy u\.zyciu analizy wariancji i SVM\relax }}{33}}
\newlabel{t:tt_anova_svm}{{4.6}{33}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Jako\'s\'c klasyfikacji dla r\'o\.znych warto\'sci progowych przy u\.zyciu analizy wariancji i las\'ow losowych\relax }}{34}}
\newlabel{t:tt_anova_random}{{4.7}{34}}
\@writefile{toc}{\contentsline {subsubsection}{Zysk Giniego}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Rozk\IeC {\l }ad jako\'sci cech przy u\.zyciu zysku Giniego. Wykres po prawej stronie stanowi przybli\.zenie wykresu po stronie lewej\relax }}{34}}
\newlabel{tt_gini}{{4.4}{34}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Jako\'s\'c klasyfikacji dla r\'o\.znych warto\'sci progowych przy u\.zyciu zysku Giniego i regresji logistycznej\relax }}{35}}
\newlabel{t:tt_gini_logit}{{4.8}{35}}
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces Jako\'s\'c klasyfikacji dla r\'o\.znych warto\'sci progowych przy u\.zyciu zysku Giniego i SVM\relax }}{35}}
\newlabel{t:tt_gini_svm}{{4.9}{35}}
\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces Jako\'s\'c klasyfikacji dla r\'o\.znych warto\'sci progowych przy u\.zyciu zysku Giniego i las\'ow losowych\relax }}{36}}
\newlabel{t:tt_gini_random}{{4.10}{36}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Detekcja zmiany dziedziny przy u\.zyciu klasteryzacji}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Algorytmy klasteryzacji}{37}}
\@writefile{toc}{\contentsline {subsubsection}{Algorytm k-centroid\'ow}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Opis algorytmu detekcji dziedziny}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Rozk\IeC {\l }ad jako\'sci cech przy u\.zyciu zysku Giniego. Wykres po prawej stronie stanowi przybli\.zenie wykresu po stronie lewej\relax }}{37}}
\newlabel{clustering_mutual_anova}{{4.5}{37}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Wnioski z przeprowadzonych eksperyment\'ow}{37}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Inne metody adaptacji dziedziny}{39}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Uczenie iteracyjne}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Opis algorytmu}{39}}
\@writefile{lol}{\contentsline {lstlisting}{[}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Wyniki i wnioski}{40}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Modyfikacja przestrzeni cech}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Opis algorytmu}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Wyniki i wnioski}{40}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Podsumowanie}{41}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\bibcite{1}{1}
\bibcite{2}{2}
\bibcite{3}{3}
\bibcite{4}{4}
\bibcite{5}{5}
\bibcite{6}{6}
\bibcite{7}{7}
\bibcite{8}{8}
\bibcite{9}{9}
\bibcite{10}{10}
\bibcite{11}{11}
\@writefile{toc}{\contentsline {chapter}{Bibliografia}{43}}
