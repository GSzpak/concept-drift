%
% Niniejszy plik stanowi przyk³ad formatowania pracy magisterskiej na
% Wydziale MIM UW.  Szkielet u¿ytych poleceñ mo¿na wykorzystywaæ do
% woli, np. formatujac wlasna prace.
%
% Zawartosc merytoryczna stanowi oryginalnosiagniecie
% naukowosciowe Marcina Wolinskiego.  Wszelkie prawa zastrze¿one.
%
% Copyright (c) 2001 by Marcin Woliñski <M.Wolinski@gust.org.pl>
% Poprawki spowodowane zmianami przepisów - Marcin Szczuka, 1.10.2004
% Poprawki spowodowane zmianami przepisow i ujednolicenie 
% - Seweryn Kar³owicz, 05.05.2006
% dodaj opcjê [licencjacka] dla pracy licencjackiej
\documentclass{pracamgr}

\usepackage{polski}

%Jesli uzywasz kodowania polskich znakow ISO-8859-2 nastepna linia powinna byc 
%odkomentowana
\usepackage[latin2]{inputenc}
%Jesli uzywasz kodowania polskich znakow CP-1250 to ta linia powinna byc 
%odkomentowana
%\usepackage[cp1250]{inputenc}
\usepackage[linesnumbered]{algorithm2e}
\usepackage{caption}
\usepackage{afterpage}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{makecell}
\usepackage{enumitem}

\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \newpage}

\newcommand*\mean[1]{\bar{#1}}

% Dane magistranta:

\author{Grzegorz Szpak}

\nralbumu{319400}

\title{Klasyfikacja wielowymiarowych szeregów czasowych przy ewoluuj±cych pojêciach}

\tytulang{Classification of multivariate time series in the presence of concept drift}

%kierunek: Matematyka, Informatyka, ...
\kierunek{Informatyka}

% informatyka - nie okreslamy zakresu (opcja zakomentowana)
% matematyka - zakres moze pozostac nieokreslony,
% a jesli ma byc okreslony dla pracy mgr,
% to przyjmuje jedna z wartosci:
% {metod matematycznych w finansach}
% {metod matematycznych w ubezpieczeniach}
% {matematyki stosowanej}
% {nauczania matematyki}
% Dla pracy licencjackiej mamy natomiast
% mozliwosc wpisania takiej wartosci zakresu:
% {Jednoczesnych Studiow Ekonomiczno--Matematycznych}

% \zakres{Tu wpisac, jesli trzeba, jedna z opcji podanych wyzej}

% Praca wykonana pod kierunkiem:
% (podaæ tytu³/stopieñ imiê i nazwisko opiekuna
% Instytut
% ew. Wydzia³ ew. Uczelnia (je¿eli nie MIM UW))
\opiekun{dra Andrzeja Janusza \\
  Instytut Informatyki \\
  }

% miesi±c i~rok:
\date{Grudzieñ 2016}

%Podaæ dziedzinê wg klasyfikacji Socrates-Erasmus:
\dziedzina{ 
%11.0 Matematyka, Informatyka:\\ 
%11.1 Matematyka\\ 
%11.2 Statystyka\\ 
%11.3 Informatyka\\ 
11.4 Sztuczna inteligencja TODO\\ 
%11.5 Nauki aktuarialne\\
%11.9 Inne nauki matematyczne i informatyczne
}

%Klasyfikacja tematyczna wedlug AMS (matematyka) lub ACM (informatyka)
\klasyfikacja{D. Software TODO\\
}

% S³owa kluczowe:
\keywords{Eksploracja danych, wielowymiarowy szereg czasowy, ewoluuj±ce pojêcia, dopasowanie dziedziny, ekstrakcja cech, selekcja cech, lasy losowe, regresja logistyczna, maszyna wektorów wspieraj±cych}

% Tu jest dobre miejsce na Twoje w³asne makra i~¶rodowiska:
\newtheorem{defi}{Definicja}[section]

% koniec definicji

\begin{document}
\maketitle

%tu idzie streszczenie na strone poczatkowa
\begin{abstract}
  W pracy przedstawiono sposoby wydajnej klasyfikacji szeregów czasowych dla danych pochodz±cych ze ¼ród³a o zmiennym rozk³adzie. Opisane zosta³y metody ekstrakcji cech z wielowymiarowego szeregu czasowego. Autor opisuje tak¿e metody wyboru przestrzeni atrybutów odpornej na zmiany rozk³adu ¼ród³a.
\end{abstract}

\tableofcontents
%\listoffigures
%\listoftables


\chapter{Wprowadzenie}\label{r:wprowadzenie}

\section{Uczenie z nadzorem a \textit{concept drift}} \label{s:superv}

Podstawowym problemem rozwa¿anym w teorii uczenia maszynowego jest problem uczenia z nadzorem (ang. \textit{supervised learning}). Niech dane bêd±:
\begin{itemize}
\item zbiór $X$ przyk³adów
\item zbiór $Y$ decyzji
\item funkcja $f: X \rightarrow Y$
\item Parê zbiorów $(X_{train} \subseteq X, Y_{train} \subseteq Y)$ instancji $x_1, x_2, \dots, x_n$ oraz odpowiadaj±cych im decyzji $f(x_1), f(x_2), \dots, f(x_n)$, zwan± \textit{zbiorem treningowym}
\end{itemize}
Zadanie uczenia z nadzorem polega na wyznaczeniu na podstawie zbioru treningowego oraz przy u¿yciu pewnego algorytmu ucz±cego (\textit{klasyfikatora}) takiej funkcji $c: X \rightarrow Y$ (zwanej \textit{modelem}) bêd±cej dobr± aproksymacj± funkcji $f$. Jako¶æ modelu $c$ okre¶la siê, porównuj±c jego warto¶ci dla elementów skoñczonego \textit{zbioru testowego} $X_{test}$ z rzeczywistymi warto¶ciami funkcji $f$ dla tych elementów. Istotne jest przy tym za³o¿enie, ¿e elementy zbiorów $X_{train}$ oraz $X_{test}$ losowane s± ze zbioru $X$ wed³ug tego samego rozk³adu prawdopodobieñstwa $D$. \\

Schemat rozwi±zywania problemu uczenia z nadzorem przedstawia rys. \ref{supervised}. \\

\begin{figure}[t!]
\centering
\includegraphics[scale=0.8]{supervised.png}
\caption{Schemat uczenia z nadzorem \label{supervised}}
\end{figure}


Na przestrzeni ostatnich dziesiêcioleci opracowanych zosta³o wiele algorytmów ucz±cych wykazuj±cych siê du¿± skuteczno¶ci± w przeró¿nych dziedzinach: od rozpoznawania obrazów, przez klasyfikacjê tekstów, rekomendacjê produktów, wykrywanie spamu, po przewidywanie zmian na gie³dzie czy diagnostykê medyczn±. \\

Sytuacja zmienia siê diametralnie, gdy pominiemy za³o¿enie o równo¶ci rozk³adów dla zbiorów treningowych i testowych. Problem ten nazywa siê \textit{ewolucj± pojêæ} (ang. \textit{concept drift}) lub \textit{dopasowaniem dziedziny} (ang. \textit{domain adaptation}). Jest on szczególnie widoczny w zadaniach przetwarzania jêzyka naturalnego (ang. \textit{natural language processing}, w skrócie NLP). Rozpatrzmy dla przyk³adu problem rozpoznawania nazw w³asnych (ang. \textit{named entity recognition}). Za³ó¿my, ¿e klasyfikator uczony jest na podstawie danych encyklopedycznych oraz testowany na danych pochodz±cych z komunikatora internetowego. Obydwa zbiory, jakkolwiek powi±zane, ró¿ni± siê w znacz±cy sposób - przyk³adowo, szukanie wielkich liter mo¿e byæ bardzo pomocne w pierwszej dziedzinie, a nie¶æ znacznie mniej informacji w wiadomo¶ciach z komunikatora.\\
St±d te¿ w³a¶nie w dziedzinie NLP powsta³o najwiêcej metod maj±cych rozwi±zaæ problem ewoluuj±cych pojêæ. Przyk³adami takich metod s± algorytm \textit{structural correspondence learning} opisywany w \cite{1} czy metoda odpowiedniego dopasowania przestrzeni parametrów zaproponowana przez Daume w \cite{2}. \\

Problem \textit{domain adaptation} nie jest jednak czêsto poruszany w przypadku klasyfikacji szeregów czasowych. W poni¿szej pracy autor przedstawia sposoby radzenia sobie z \textit{concept drift} podczas klasyfikacji szeregów czasowych oraz wykonuje studium przypadku na wybranym zbiorze danych.

\section{Formalizacja problemu}

\subsection{Paradygmaty uczenia siê}

Przyjmijmy definicje jak na pocz±tku sekcji \ref{s:superv}. W zale¿no¶ci od rozk³adów $D_{train}$, $D_{test}$ oraz od dostêpno¶ci zbiorów $Y_{train}, X_{test}, Y_{test}$, mo¿na (za \cite{3}) zdefiniowaæ inne paradygmaty uczenia. \\
I tak, je¶li zbiór $Y_{train}$ jest nieznany w momencie tworzenia modelu, mamy do czynienia z \textit{uczeniem bez nadzoru} (ang. \textit{unsupervised learning}). \\
Gdy zbiór $X_{test}$ nie jest znany podczas uczenia, mowa o \textit{uczeniu indukcyjnym} (ang. \textit{inductive learning}). W przeciwnym razie takie uczenie nazywa siê \textit{uczeniem transdukcyjnym} (ang. transductive learning). \\
W powy¿szym przyk³adach istotne jest za³o¿enie, i¿ zbiory $X_{train}$, $X_{test}$ pochodz± z tego samego rozkladu $D$. Odwrotna sytuacja rozpatrywana jest w paradygmacie \textit{uczenia z przeniesieniem wiedzy} (ang. \textit{transfer learning}). Przyjmuje siê w nim, ¿e dane s± dwa ró¿ne rozk³ady $D^{source}$ i $D^{target}$. Model wyuczony na danych treningowych $X^{source}_{train}, Y^{source}_{train}$ wykorzystywany jest zatem do klasyfikacji zbioru testowego $X^{target}_{test}, Y^{target}_{test}$ pochodz±cych z rozk³adu $D^{target}$. W poni¿szej pracy autor skupia siê na problemie \textit{dopasowania dziedziny}, który zak³ada, ¿e zbiór dostêpnych klas $Y$ jest ten sam dla $D^{source}$ i $D^{target}$. Przeciwieñstwem dopasowania dziedziny jest zadanie \textit{uczenia wielozadaniowego} (ang. \textit{multi-task learning}, wiêcej miêdzy innymi w \cite{4}), gdzie zbiory $X_{train}$, $ X_{test}$ pochodz± z tego samego rozk³adu, natomiast zbiory $Y_{train}$, $Y_{test}$ s± ró¿ne. \\

Powy¿sze rozwa¿ania podsumowuje tabela \ref{t:paradigms}. \\

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Paradygmaty uczenia w teorii uczenia maszynowego. We wszystkich przypadkach zak³adamy, ¿e zbiór $X_{train}$ jest dostêpny podczas uczenia, podczas gdy zbiór $Y_{test}$ nie jest znany.}
\label{t:paradigms}
\begin{tabular}{|c|c|c|c|}
\hline
Paradygmat & $Y_{train}$ dostêpny? & $X_{test}$ dostêpny? & Rozk³ad danych testowych \\ \hline
\makecell{Indukcyjne uczenie \\ bez nadzoru}  & Nie & Nie & $D^{source}$ \\ \hline
\makecell{Transdukcyjne uczenie \\ bez nadzoru}  & Nie & Tak & $D^{source}$ \\ \hline
\makecell{Indukcyjne uczenie \\ z nadzorem}  & Tak & Nie & $D^{source}$ \\ \hline
\makecell{Transdukcyjne uczenie \\ z nadzorem}  & Tak & Tak & $D^{source}$ \\ \hline
\makecell{Indukcyjne uczenie \\ bez nadzoru \\ z przeniesieniem wiedzy}  & Nie & Nie & $D^{target}$ \\ \hline
\makecell{Transdukcyjne uczenie \\ bez nadzoru \\ z przeniesieniem wiedzy}  & Nie & Tak & $D^{target}$ \\ \hline
\makecell{Indukcyjne uczenie \\ z nadzorem \\ z przeniesieniem wiedzy}  & Tak & Nie & $D^{target}$ \\ \hline
\makecell{Transdukcyjne uczenie \\ z nadzorem \\ z przeniesieniem wiedzy}  & Tak & Tak & $D^{target}$ \\ \hline
\end{tabular}
\end{table}

W poni¿szej pracy autor skupi siê na problemie transdukcyjnego uczenia z nadzorem z przeniesieniem wiedzy. Przedstawione zostan± algorytmy, które wykorzystuj± dostêpny zbiór $X_{test}$ do znalezienia reprezentacji odpornej na zmiany rozk³adu, co skutkowaæ bêdzie zwiêkszon± jako¶ci± klasyfikacji w stosunku do standardowego podej¶cia opisanego w \ref{s:superv}.

\subsection{Ewolucja pojêæ a \textit{overfitting}}

Mówi±c o problemie ewoluuj±cych pojêæ, nale¿y wspomnieæ o zagadnieniu przeuczenia (ang. \textit{overfitting}). Polega on na zbudowaniu nadmiernie skomplikowanego modelu, co skutkuje s³ab± jego jako¶ci±. \\
Obydwa pojêcia mog± byæ mylone przy niew³a¶ciwym sposobie walidacji modelu. Je¶li jako¶æ klasyfikacji sprawdzana jest wy³±cznie na zbiorach treningowym i testowym, zarówno \textit{concept drift}, jak i \textit{overfitting} daj± podobne objawy - wysoki wynik na zbiorze treningowym oraz niski na zbiorze testowym. W przypadku przeuczenia jest to spowodowane nadmiernym dopasowaniem modelu do danych treningowych i jego nisk± zdolno¶ci± do uogólniania. Je¶li mamy do czynienia z ewoluuj±cymi pojêciami, s³aba jako¶æ modelu jest spowodowana innym rozk³adem dla zbioru testowego. \\
W rozró¿nienu obydwu sytuacji pomagaæ mo¿e zastosowanie \textit{walidacji krzy¿owej} (ang. \textit{cross-validation}) na zbiorze treningowym. Walidacja krzy¿owa polega na podziale zbioru treningowego na $n$ równolicznych czê¶ci. Nastêpnie budowane jest $n$ modeli, przy czym $n - 1$ czê¶ci tworzy zbiór treningowy, natomiast pozosta³a czê¶æ - zbiór testowy. Ostateczny wynik jest ¶rednim wynikiem powsta³ych $n$ modeli. \\
Nietrudno zauwa¿yæ, ¿e w przypadku \textit{concept drift} nie powinno siê zauwa¿yæ znacznego spadku jako¶ci modelu przy wykonaniu walidacji krzy¿owej - w tym przypadku zbiór testowym pochodzi z tej samej dziedziny co treningowy. Inaczej bêdzie w przypadku przeuczenia - tu wynik walidacji krzy¿owej bêdzie wyra¼nie ni¿szy ni¿ wynik na zbiorze treningowym (tabela \ref{t:overfit}). \\ 

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{\textit{Concept drift} a \textit{overfitting} - obni¿ony wynik modelu 1. przy walidacji krzy¿owej ¶wiadczy o przeuczeniu, a nie wystêpowaniu ewoluuj±cych pojêæ. W drugim przypadku model mimo dobrej umiejêtno¶ci klasyfikacji elementów pochodz±cych z rozk³adu $D^{source}$, cierpi na spadek jako¶ci przy ewaluacji na zbiorze pochodz±cym z rozk³adu $D^{target}$.}
\label{t:overfit}
\begin{tabular}{|c|c|c|c|}
\hline
  & Wynik na $X_{train}$ & Wynik CV & Wynik na $X_{test}$ \\ \hline
Model 1  & 0.98 & 0.73 & 0.68 \\ \hline
Model 2  & 0.97 & 0.92 & 0.76 \\ \hline
\end{tabular}
\end{table}


\chapter{Opis przeprowadzanego eksperymentu}\label{r:experiment}

\section{Przedstawienie badanego problemu} \label{s:problem}

\subsection{Opis zbioru danych} \label{ss:data}

Dane, na których sprawdzana by³a jako¶æ analizowanych algorytmów, pochodz± z konkursu \textit{AAIA'15 Data Mining Competition: Tagging Firefighter Activities at a Fire Scene}\footnote{https://knowledgepit.fedcsis.org/contest/view.php?id=106} organizowanego przez Uniwersytet Warszawski oraz Szko³ê G³ówn± S³u¿by Po¿arniczej w Warszawie. \\
Na potrzeby konkursu zebrano odczyty pochodz±ce z "inteligentnego kombinezonu", który monitoruje ruchy oraz funkcje ¿yciowe stra¿aka. W sk³ad kombinezonu wchodzi³o po siedem akcelerometrów i ¿yroskopów umieszczonych na: tu³owiu, ramionach, d³oniach i nogach (rys. \ref{fireman}).

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.4]{fireman.png}
\caption{Rozmieszczenie czujników na ciele stra¿aka \label{fireman}}
\end{figure}

Ka¿da instancja w zbiorze danych sk³ada³a siê z zebranych w krótkich odcinkach czasu (oko³o 1.8 s) odczytów z zamontowanych sensorów. Dla ka¿dego akcelerometru oraz ¿yroskopu zebrano po 400 odczytów wzd³u¿ osi $x$, $y$, $z$, wraz ze wzglêdnym czasem wykonania odczytu. Dla ka¿dego wiersza daje to 42 - wymiarowy szereg czasowy o d³ugo¶ci 400. Jak ³atwo wywnioskowaæ, ¶redni odstêp miêdzy kolejnymi odczytami wynosi³ oko³o 4.5 ms. Zestaw atrybutów uzupe³nia³y dodatkowo 42 agregaty ze wskazañ urz±dzeñ monitoruj±cych funkcje ¿yciowe stra¿aka (takie jak EKG, czêstotliwo¶æ oddechu, temperatura skóry). Nieprzetworzone dane zawiera³y wiêc $400 * 43 + 42 = 17242$ atrybuty. Zarówno zbiór treningowy, jak i testowy sk³ada³y siê z $20000$ przyk³adów. Bardzo istotny dla dla analizy tego zbioru danych okaza³ siê fakt, ¿e dane treningowe i testowe pochodzi³y od ró¿nych czteroosobowych grup stra¿aków. \\
Zadaniem uczestników konkursu by³o przypisanie ka¿dej instancji w zbiorze postury stra¿aka w danym momencie oraz wykonywanej przez niego czynno¶ci. Zastosowane algorytmy mia³y pomóc w stworzeniu systemu monitoruj±cego bezpieczeñstwo stra¿aka podczas akcji. \\

Jako ¿e problem klasyfikacji wieloetykietowej nie jest tematem niniejszej pracy, autor postanowi³ skupiæ siê na problemie przewidywania czynno¶ci wykonywanej przez stra¿aka. Zbiór klas liczy³ wiêc $16$ elementów. Postawiony problem utrudnia³ dodatkowo fakt, ¿e klasy by³y wysoce niezbalansowane - najczêstsza klasa ($manipulating$) wyst±pi³a w zbiorze treningowym $6349$ razy, podczas gdy najrzadsza ($signal\_hose\_pullback$) - jedynie 98 razy.\\
Rozk³ad klas przedstawia rys. \ref{classes}. \\

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.6]{classes.png}
\caption{Rozk³ad klas w zbiorze treningowym \label{classes}}
\end{figure}

\subsection{Ewaluacja jako¶ci klasyfikatora} \label{ss:evaluation}

Standardow± miar± jako¶ci jest prezycja (ang. \textit{accuracy}):
\begin{displaymath}
ACC(c) = \frac{1}{n} \sum_{i=1}^n \mathbf{1}[c(\textbf{x}_i) = y_i]
\end{displaymath}

W opisywanym konkursie zastosowano modyfikacjê tej miary zwan± \textit{balanced accuracy}, zdefiniowan± nastêpuj±co:

\begin{equation}
ACC_i(c) = \frac{|j: \,c(\textbf{x}_j) = y_j = i|}{|j: y_j = i|} \\
\end{equation}

\begin{equation} \label{bac}
BAC(c) = \frac{\sum_{i=1}^l ACC_i(c)}{l} 
\end{equation}
Nietrudno zauwa¿yæ, ¿e miara $BAC$ jest bardziej wra¿liwa na b³êdn± klasyfikacjê rzadkich klas ni¿ standardowa miara $ACC$.

\section{Opis u¿ytych klasyfikatorów} \label{s:klasyfikatory}

W kolejnych rozdzia³ach przedstawione zostan± metody maj±ce na celu zwiêkszenie jako¶ci modelu budowanego na danych, w których obecny jest problem ewoluuj±cych pojêæ. U¿yteczno¶æ tych metod sprawdzana bêdzie dla trzech ró¿nych algorytmów uczenia: klasyfikatorze opartym na regresji logistycznej, maszynie wektorów no¶nych (ang. \textit{support vector machine}, SVM) oraz drzewach decyzyjnych.

\subsection{Klasyfikator liniowy} \label{ss:linear}

Regresja logistyczna i maszyna wektorów wspieraj±cych nale¿± do grupy klasyfikatorów liniowych. Przyjmijmy oznaczenia jak w sekcji \ref{s:superv}. Za³ó¿my, ¿e zbiór klas $Y$ jest dwuelementowy - dla uproszczenia niech $Y = \{+1, -1 \}$. Niech dalej $y \in Y$ bêdzie decyzj± dla elementu $\textbf{x} = (x_1, x_2, \dots, x_m) \in X \subseteq \mathbb{R}^m$. Klasyfikatorem liniowym nazywamy $m - 1$ - wymiarow± hiepr³aszczyznê rozdzielaj±c± punkty z $X$. Niech $\textbf{w} = (w_1, w_2, \dots, w_m) \in \mathbb{R}^m$ bêdzie wektorem wspó³czynników tej hiperp³aszczyzny. Uczenie klasyfikatora liniowego zwykle polega na minimalizacji warto¶ci pewnej funkcji b³êdu $l(\textbf{w})$ na zbiorze treningowym.

\subsubsection{Klasyfikacja oparta na regresji logistycznej (\textit{logit})}

Niech
\begin{displaymath}
g(z) = \frac{1}{1 + e^{-z}}
\end{displaymath}
zwana bêdzie funkcj± logistyczn±. Jej wykres przedstawia rysunek \ref{sigmoid}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.3]{sigmoid.png}
\caption{Wykres funkcji sigmoidalnej \label{sigmoid}}
\end{figure}

Funkcja $g$ jest oczywi¶cie ci±g³a. Jednocze¶nie $lim_{z \to -\inf} g(z) = 0$ oraz $lim_{z \to \inf} g(z) = 1$. Dziêki tym w³a¶ciwo¶ciom nadaje siê ona do modelowania prawdopodobieñstwa jakiego¶ zjawiska. Klasyfikator bazuj±cy na regresji logistycznej modeluje prawdopodobieñstwo nale¿enia do klasy pozytywnej przez funkcjê:
\begin{displaymath}
p_w(\textbf{x}) = g(\textbf{w}^\intercal\textbf{x}) = \frac{1}{1 + e^{-\textbf{w}^\intercal\textbf{x}}},
\end{displaymath}

przy czym klasyfikacja dokonywana jest przez: 

\begin{displaymath}
c_w(\textbf{x}) = 1 \iff p_w(\textbf{x}) \geq \frac{1}{2}.
\end{displaymath}

Uczenie klasyfikatora opartego na regresji logistycznej polega wiêc na znalezieniu hiperp³aszczyzny $\textbf{w}$, która minimalizuje nastêpuj±c± funkcjê straty:

\begin{displaymath}
l_{log\_loss}(\textbf{w}) = \sum_{i = i}^n log(1 + e^{-y_i\textbf{w}^\intercal\textbf{x}_i}).
\end{displaymath}

\subsubsection{Maszyna wektorów no¶nych}

Innym typem klasyfikatora liniowego jest (ang. \textit{support vector machine}, SVM). Uczenie SVM polega na znalezieniu hiperp³aszczyzny o najwiêkszej odleg³o¶ci od punktów obydwu klas (rys. \ref{svm}) - z tego powodu SVM nazywany jest klasyfikatorem maksymalnego marginesu (ang. \textit{max margin classifier}).

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.5]{svm.png}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{P³aszczyzna $H_1$ nie rozdziela klas. \\ P³aszczyzna $H_2$ rozdziela je, ale z niewielkim marginesem. \\P³aszczyzna $H_3$ rozdziela je z maksymalnym marginesem. \label{svm}}
\end{figure}

Za³o¿enie o liniowej separowalno¶ci klas jest jednak rzadko spe³nione. Uczenie klasyfikatora SVM polega wiêc na znalezieniu hiperp³aszczyzny $\textbf{w}$, która minimalizuje funkcjê
straty dan± jako

\begin{displaymath}
l_{hinge\_loss}(\textbf{w}) = \sum_{i = i}^n max(0, 1 - y_i\textbf{w}^\intercal\textbf{x}_i).
\end{displaymath}

\subsubsection{Klasyfikator "jeden przeciwko wszystkim"}

Jak wspomniano wcze¶niej, zarówno regresja logistyczna, jak i SVM s± klasyfikatorami binarnymi - zak³adaj±, ¿e zbiór klas $Y$ jest dwuelementowy. Aby u¿yæ ich do klasyfikacji danego zbioru, potrzebna by³a metoda klasyfikacji wieloklasowej. Zastosowano podej¶cie zwane "jeden przeciw wszystkim" (ang. \textit{one-vs.-all}, OvA, b±d¼ \textit{one-vs.-rest}, OvR). \\
Niech $Y = \{1, 2, \dots, k \}$. Klasyfikacja OvA polega na nauczeniu $k$ binarnych klasyfikatorów $c_1, c_2, \dots, c_k$. Klasa dla $j$ - tego klasyfikatora zdefiniowana jest nastêpuj±co:

\begin{displaymath}
y^j_i = 1 \iff y_i = j
\end{displaymath}

Ostatecznie elementowi $x$ przypisywana jest klasa, której klasyfikator daje najmniejsz± warto¶æ funkcji b³êdu:

\begin{displaymath}
c(\textbf{x}) = arg \min_{j \in 1\dots k} \,  l_j(\textbf{x})
\end{displaymath}


\subsection{Lasy losowe} \label{ss:random_forest}
Innym typem klasyfikatora jest las losowy. Jest to klasyfikator wykorzystuj±cy prostszy klasyfikator - drzewo decyzyjne. Drzewo decyzyjne to etykietowane drzewo, którego ka¿dy wêze³ odpowiada przeprowadzeniu pewnego testu na warto¶ciach atrybutów. Z wêz³a wewnêtrznego wychodzi tyle ga³êzi, ile jest mo¿liwych wyników testu odpowiadaj±cego temu wêz³owi. Ka¿dy li¶æ zawiera decyzjê o klasyfikacji obiektu. Przyk³adowe drzewo decyzyjne przedstawia rys. \ref{dec_tree}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.6]{decision_tree.png}
\caption{Przyk³adowe drzewo decyzyjne \label{dec_tree}}
\end{figure}

Uczenie lasu losowego polega na uczeniu okre¶lonej liczby drzew decyzyjnych - ka¿dego na losowej podprzestrzeni atrybutów. Finalna klasa jest mod± klas wyznaczonych przez poszczególne drzewa. Lasy losowe, podpbnie jak drzewa decyzyjne, wspieraj± klasyfikacjê wieloklasow±.

\section{Przyk³ad Ewolucji pojêæ w analizowanym zbiorze} \label{s:data_concept_drift}

Okazuje siê, ¿e g³ównym wyzwaniem w konkursie opisywanym w sekcji \ref{ss:data} s± ró¿nice w wykonywaniu poszczególnych czynno¶ci miêdzy stra¿akami. Aby siê o tym przekonaæ, nauczono las losowy na $42$ atrybutach opisuj±cych funkcje ¿yciowe, nastêpnie zmierzono jego jako¶æ (u¿ywaj±c miary $BAC$) na zbiorach treningowym i testowym. Do pomiaru jako¶ci na zbiorze treningowym zastosowano trójwarstwow± walidacjê krzy¿ow±. Problem \textit{concept drift} spowodowa³ drastyczne obni¿enie jako¶ci klasyfikatora, która spad³a z $0.993$ na $0.079$. 

\chapter{Ekstrakcja cech z szeregów czasowych} \label{c:features}

\section{Metody klasyfikacji szeregów czasowych}

Szeregi czasowe obecne s± w wielu ró¿nych dziedzinach ¿ycia - od medycyny, przez finanse, i wyszukiwanie informacji po przetwarzanie sygna³ów oraz prognozê pogody. W ostatnich latach opisanych zosta³o wiele metod do wykrywania wzorców czasowych w takich zadaniach jak: okre¶lanie stanu zdrowia pacjenta na podstawie odczytów elektrokardiografu, przewidywanie wahañ na gie³dzie, analiza mowy czy prognozowanie temperatur. \\
W¶ród metod zaproponowanych do klasyfikacji szeregów czasowych znale¼æ mo¿na wiêkszo¶æ najbardziej znanych algorytmów uczenia siê: metodê k-najbli¿szych s±siadów (ang. \textit{k-nearest neighbours}), w skrócie k-NN - wiêcej w \cite{6}), sieci neuronowe (\cite{7}) czy ukryty model Markowa (\cite{8}). Wci±¿ jednak najszerzej u¿ywane (i uznawane za najbardziej skuteczne) s± warianty algorytmu k-NN z u¿yciem ró¿nych metryk, takich jak odleg³o¶æ euklidesowa czy Dynamic Time Warping (w skrócie DTW) - wiêcej o DTW przeczytaæ mo¿na miêdzy innymi w \cite{9}. \\
W poni¿szej pracy zastosowano nieco odmienne podej¶cie.  Autor koncentruje siê na ekstrakcji cech opartych na statystycznych w³asno¶ciach szeregów. Cechy te wylliczane s± z ró¿nych reprezentacji danego szeregu. Nastêpnie na tak przekszta³conych danych uczone by³y klasyfikatory opisane w sekcji \ref{s:klasyfikatory}. Jak pokazuj± niektóre badania (przyk³adowo - \cite{8}, \cite{9}), takie podej¶cie daje czêsto lepsze wyniki ni¿ algorytmy bazuj±ce na podobieñstwie szeregów.

\section{Proces ekstrakcji cech} \label{s:extraction}

Zacznijmy od formalnego zdefiniowania \textit{szeregu czasowego}.

\begin{defi}\label{d:series}
  \emph{Jednowymiarowym szeregiem czasowym} $T_n$ nazwiemy skoñczony ci±g par
  $$(t_1, x_1), (t_2, x_2), \dots, (t_n, x_n)$$
 o d³ugo¶ci $n$, gdzie $x_k$ jest warto¶ci± szeregu w czasie $t_k$. 
\end{defi}
\hfill \\
Proces ekstrakcji cech dla szeregu czasowego przebiega³ nastêpuj±co:
\begin{enumerate}[label*=\arabic*.]
\item wyznaczenie pochodnych reprezentacji szeregu czasowego (wiêcej w sekcji \ref{ss:representations})
\item Wyliczenie statystyk z wyznaczonych reprezentacji
\item Dodanie pozosta³ych cech (bazuj±cych miêdzy innymi na korelacji miêdzy szeregami)
\end{enumerate}

W kolejnych sekcjach zostanie omówiony ka¿dy z powy¿szych kroków.

\subsection{Reprezentacje pochodne szeregu czasowego} \label{ss:representations}

Wiele przekszta³ceñ i reprezentacji szeregów czasowych zosta³o opisanych w literaturze - ich szerszy przegl±d mo¿na znale¼æ miêdzy innymi w TODO. Celem takich przekszta³ceñ jest wykrycie wzorców charakterystycznych dla klas wynikowych, które nie s± wykrywalne przy u¿yciu podstawowej reprezentacji $T_n$. \\
Gay i in. w TODO podaj± przyk³ad, kiedy to badanie drugiej pochodnej szeregu po czasie znacznie zwiêksza jako¶æ klasyfikacji (rys. \ref{example}). Dzia³aj±c na oryginalnych danych, trudno jest rozró¿nic dwie klasy. Policzenie drugiej pochodnej sprawia, ¿e klasyfikacja staje siê niemal¿e trywialna.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.8]{example.png}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Po lewej widaæ oryginalny zbiór danych, natomiast po prawej - drug± pochodn± po czasie \label{example}}
\end{figure}

Autor, poza reprezentacj± oryginaln± $T_n$, zdecydowa³ siê wykorzystaæ w procesie ekstrakcji cech cztery inn reprezentacje: 
\begin{itemize}
\item pochodn± szeregu po czasie $der_{T_n}$
\item ca³kê szeregu po czasie $int_{T_n}$
\item dyskretn± transformatê Fouriera $fourier_{T_n}$
\item dyskretn± transformatê falkow± Haara $wavelet_{T_n}$
\end{itemize}

\subsubsection{Pochodna szeregu po czasie}

Dyskretna pochodna szeregu $T_n = (t_1, x_1), (t_2, x_2), \dots, (t_n, x_n)$ po czasie wyliczana by³a w sposób nastêpuj±cy:

\begin{equation}
der_{T_n}(i) = \frac{x_i - x_{i - 1}}{t_i - t_{i - 1}}
\end{equation}

Takie przekszta³cenie pozwala na badanie lokalnej zmienno¶ci (monotoniczno¶ci i jej tempa) danego szeregu. Jako ¿e badane dane (opisywane szerzej w sekcji \ref{ss:data}) sk³ada³y siê z odczytów z sensorów (akcelerometrów i ¿yroskopów), pochodna po czasie mo¿e byæ równie¿ interpretowana w sensie fizycznym. Przyk³adowo, miara zmienno¶ci przyspieszenia w czasie zwana jest zrywem\footnote{https://pl.wikipedia.org/wiki/Zryw}.

\subsubsection{Ca³ka szeregu po czasie}

Analogicznie do pochodnej zdefiniowaæ mo¿na dyskretn± ca³kê z szeregu \\ $T_n = (t_1, x_1), (t_2, x_2), \dots, (t_n, x_n)$, wyliczan± metod± trapezów:

\begin{equation}
int_{T_n}(i) = \sum_{j= 1}^i \frac{(x_j + x_{j - 1})(t_i - t_{i - 1})}{2}
\end{equation}

Tak wyliczonej ca³ce tak¿e mo¿na przypisaæ interpretacjê fizyczn± - dla przyk³adu, warto¶æ $int_{T_n}(i)$ dla odczytu $T_n$ z akcelerometru umieszczonego na lewej rêce stra¿aka oznacza prêdko¶æ, z jak± porusza³a siê ta rêka w czasie $t_i$.  \\

\hfill \\
Pozosta³e dwa przekszta³cenia (transformata Fouriera oraz transformata falkowa) wyra¿aj± szereg czasowy w bazie pewnej przestrzeni funkcyjnych. \\

\subsubsection{Transformacja Fouriera}

Transformacja Fouriera jest jednym z najwa¿niejszych przekszta³ceñ u¿ywanych do analizy sygna³ów. Bazuje ona na odkryciu, ¿e ka¿dy szereg czasowy mo¿e byæ rozbity na sumê prostych, okresowych sygna³ów - sinusów i cosinusów o zmieniaj±cych siê amplitudzie i fazie (rys. \ref{fourier}).

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.54]{fourier.png}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Cosinusowe fale $s_1$, $s_2$, $s_3$ daj± razem bardziej z³o¿ony sygna³ \label{fourier}}
\end{figure}

Formalnie wspó³czynniki dyskretnej transformaty Fouriera zdefiniowane s± nastêpuj±co:

\begin{equation}
fourier_{T_n}(k) = \sum_{i = 0}^{n - 1} x_i \cdot (\cos(\frac{-2\pi k i}{n}) + i\sin(\frac{-2\pi k i}{n}))
\end{equation}

Wspó³czynniki $fourier_{T_n}(k)$ s± liczbami zespolonymi i reprezentuj± amplitudy oraz fazy sinusoidalnych sk³adowych sygna³u. Dla szeregów o warto¶ciach rzeczywistych, $fourier_{T_n}(i)$ jest zespolonym sprzê¿eniem $fourier_{T_n}(n - i + 1)$ (dla $i = 2, 3, \dots, \frac{n}{2}$). \\
Istnieje algorytm (zwany \textit{szybk± transformacj± Fouriera}, ang. \textit{fast Fourier Transform}), obliczaj±cy wspó³czynniki transformaty Fouriera w czasie $\mathcal{O}(n\log n)$.

\subsubsection{Transformacja falkowa}

Przekszta³ceniem podobnym do transformaty Fouriera jest transformacja falkowa. Jej g³ówn± przewag± nad transformacj± opracowan± przez francuskiego matematyka jest zachowywanie informacji zarówno o czêstotliwo¶ci, jak i o czasie. Podczas gdy przekszta³cenie Fouriera rzutuje sygna³ z dziedziny czasu na dziedzinê czêstotliwo¶ci, transformata falkowa mierzy czêstotliwo¶æ w ró¿nych momentach czasu - sygna³ jest wiêc rzutowany na p³aszczyznê czasu i czêstotliwo¶ci. \\
\textit{Dyskretna transformacja falkowa} równie¿ polega na przedstawieniu sygna³u jako sumy sygna³ów podstawowych. Podczas gdy transformata Fouriera u¿ywa³a funkcji sinusoidalnych, tutaj funkcjê podstawow± nazywa siê \textit{falk±}. Funkcje falkowe s± postaci:

\begin{displaymath}
\Psi_{j,k}(t) = 2^{\frac{j}{2}}\Psi(2^jt - k),
\end{displaymath}
gdzie $\Psi$ jest \textit{macierzyst± funkcj± falkow±}. Wtedy ka¿da funkcja $f \in L^2(\mathbb{R})$ mo¿e byæ przedstawiona w tej bazie jako
\begin{displaymath}
f(t) = \sum_{j, k} c_{j,k}\Psi_{j,k}(t),
\end{displaymath}
a $c_{j,k} = \left\langle \Psi_{j,k}(t), f(t) \right\rangle$ s± wspó³czynnikami dyskretnej transformaty falkowej. \\
Najbardziej znan± macierzyst± funkcj± falkow± jest falka Haara, zdefiniowana nastêpuj±co:
\[
    \Psi_{Haar}(t) = 
    \begin{cases} 
      0 & t < 0 \\
      1 & 0 \leq t < 0,5 \\
      -1 & 0,5 \leq t < 1 \\
      0 & t \geq 1 
   \end{cases}
\]

Wykres falki Haara przedstawia rys. \ref{haar}. Funkcja wêgierskiego matematyka zosta³a u¿yta przez autora w procesie ekstrakcji cech.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.15]{haar.png}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Wykres falki Haara \label{haar}}
\end{figure}

Podobnie jak w przypadku dyskretnej transformaty Fouriera, tak i tu istnieje szybki algorytm obliczaj±cy wspó³czynniki dyskretnej transformaty falkowej (dzia³aj±cy w czasie $\mathcal{O}(n)$ - TODO bibliografia). Czyni to obydwa przekszta³cenia niezwykle u¿yteczne w praktyce.
\newpage

\subsection{Statystyki wyliczane z reprezentacji szeregu} \label{ss:feaures}

Kolejnym krokiem w ekstrakcji cech by³o opisanie reprezentacji (przedstawionych w poprzedniej sekcji) za pomoc± zbioru statystyk, maj±cych jak najlepiej oddaæ charakter danego szeregu.
Poni¿ej znajduje siê lista statystyk (wraz z formalnym opisem) wykorzystanych przez autora. \\

\begin{itemize}
\item \textbf{Minimum}

Minimalna warto¶æ przyjmowana w szeregu czasowym:
\begin{equation}
min(T_n) = \min_{1 \leq i \leq n} x_i
\end{equation}

\item \textbf{Maksimum}

Maksymalna warto¶æ przyjmowana w szeregu czasowym:
\begin{equation}
max(T_n) = \max_{1 \leq i \leq n} x_i
\end{equation}

\item \textbf{¦rednia arytmetyczna}

¦rednia arytmetyczna warto¶ci przyjmowanych w szeregu czasowym:
\begin{equation}
mean(T_n) = \frac{\sum_{i = 1}^n x_i}{n}
\end{equation}

\item \textbf{Suma}

Suma warto¶ci przyjmowanych w szeregu czasowym:
\begin{equation}
sum(T_n) = \sum_{i = 1}^n x_i
\end{equation}

\item \textbf{Odchylenie standardowe}

Odchylenie warto¶ci przyjmowanych w szeregu czasowym:
\begin{equation}
std(T_n) = \sqrt{\frac{\sum_{i = 1}^n(x_i - mean(T_n))^2}{n}}
\end{equation}

\item \textbf{Kwantyle}

Kwantylem $q_p(T_n)$ rzêdu $p$ nazwiemy taki element $x_k$, ¿e dok³adnie $p$ elementów szeregu jest od niego mniejszych. W procesie ekstrakcji cech u¿yto siedmiu kwantyli, rzêdów kolejno: 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875. \\
Kwantyl rzêdu $0.5$ oznaczany bêdzie dalej przez $median(T_n)$.

\item \textbf{Wariancja}

Wariancja warto¶ci w szeregu czasowym:
\begin{equation}
var(T_n) = std^2(T_n)
\end{equation}

\item \textbf{B³±d standardowy}

B³±d standardowy okre¶la odchylenie standardowe dla rozk³adu ¶redniej z próby. Zdefiniowany jest jako:
\begin{equation}
sem(T_n) = \frac{std(T_n)}{\sqrt{n}}
\end{equation}

\item \textbf{Indeks pierwszego maksimum}

Indeks pierwszego maksimum szeregu (normalizowany przez d³ugo¶æ szeregu):
\begin{equation}
first\_argmax(T_n) = \frac{\min(\{i: x_i = max(T_n)\}}{n}
\end{equation}

\item \textbf{Indeks pierwszego minimum}

Indeks pierwszego minimum szeregu (normalizowany przez d³ugo¶æ szeregu):
\begin{equation}
first\_argmin(T_n) = \frac{\min(\{i: x_i = min(T_n)\}}{n}
\end{equation}

\item \textbf{Wspó³czynnik sko¶no¶ci}

Wspó³czynnik sko¶no¶ci rozk³adu to miara asymetrii rozk³adu. Przyjmuje on warto¶æ zero dla rozk³adu dla rozk³adu symetrycznego, warto¶ci ujemne dla rozk³adów o lewostronnej asymetrii (wyd³u¿one lewe ramiê rozk³adu) i warto¶ci dodatnie dla rozk³adów o prawostronnej asymetrii (wyd³u¿one prawe ramiê rozk³adu) (rys. \ref{skew}). \\
Traktuj±c warto¶ci szeregu jako warto¶ci pewnej próbki statystycznej, mo¿na wyznaczyæ jego wspó³czynnik sko¶no¶ci, zdefiniowany jako:
\begin{equation}
skew(T_n) = \frac{3(mean(T_n) - median(T_n))}{std(T_n)}
\end{equation}

\begin{figure}[ht!]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\includegraphics[scale=0.6]{skewness.png}
\caption{Rozk³ady o ujemnym (pierwszy wykres) i dodatnim (drugi wykres) wspó³czynniku sko¶no¶ci \label{skew}}
\end{figure}

\item \textbf{Kurtoza}

Kurtoza to miara koncentracji wyników wokó³ warto¶ci centralnej. Jest to druga, obok sko¶no¶ci, miara kszta³tu rozk³adu.\\
Kurtoza rozk³adu normalnego wynosi 0. Je¶li warto¶æ tej statystyki jest dodatnia, mamy do czyniena z rozk³adem leptokurtycznym (wysmuk³ym). Je¶li za¶ jest ujemna, rozk³ad jest rozk³adem platykurtycznym (sp³aszczonym) (rys. \ref{kurthosis})

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.5]{kurthosis.png}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Kszta³t rozk³adu w zale¿no¶ci od warto¶ci kurtozy \label{kurthosis}}
\end{figure}

Formalnie kurtozê definiuje siê nastêpuj±co:
\begin{equation}
kurt(T_n) = \frac{\frac{1}{n}\sum_{i=1}^n(x_i - mean(T_n))^4}{std^4(T_n)} - 3
\end{equation}

\item \textbf{¦rednia wa¿ona liniowo}

¦rednia wa¿ona warto¶ci w szeregu, przy czym wagi rosn± liniowo wraz z indeksem. W ten sposób nadaje siê najwiêksz± wagê obserwacjom wykonanym najpó¼niej (u¿ycie tej statystyki dla szeregów czasowych opisuj± Wiens i in. w \cite{11}):
\begin{equation}
linear\_weighted\_mean(T_n) = \frac{2}{n(n + 1)} \sum_{i=1}^n ix_i
\end{equation}

\item \textbf{¦rednia wa¿ona kwadratowo}

Jak wy¿ej - z t± ró¿nic±, ¿e wagi rosn± kwadratowo wraz z indeksem:
\begin{equation}
quadratic\_weighted\_mean(T_n) = \frac{6}{n(n + 1)(2n + 1)} \sum_{i=1}^n i^2x_i
\end{equation}

\item \textbf{¦rednie odchylenie bezwzglêdne od ¶redniej}

¦rednie odchylenie bezwzglêdne to kolejna, obok odchylenia standardowego i wariancji, miara rozrzutu próbki. Definuje siê je nastêpuj±co:
\begin{equation}
mean\_absolute\_deviation(T_n) = \frac{\sum_{i=1}^n |x_i - mean(T_n)|}{n}
\end{equation}

\item \textbf{Mediana bezwzglêdnego odchylenia}

Jeszcze inn± miar± rozrzutu jest mediana bezwzglêdnego odchylenia (ang. \textit{median absolute deviation}, MAD). Jest to mediana ci±gu bezwzglêdnych odchyleñ od mediany:
\begin{equation}
median\_absolute\_deviation(T_n) = median_{1 \leq i \leq n}(|x_i - median(T_n)|)
\end{equation}

\item \textbf{Ca³kowita energia}

Ca³kowit± energiê szeregu definiuje siê jako sumê kwadratów jego warto¶ci:
\begin{equation}
E(T_n) = \sum_{i=1}^n x_i^2
\end{equation}

\item \textbf{Liczba elementów mniejszych od ¶redniej}

Zdefiniowana w oczywisty sposób:
\begin{equation}
count\_below\_mean(T_n) = |\{i: x_i < mean(T_n)\}|
\end{equation}

\item \textbf{Liczba elementów wiêkszych od ¶redniej}

Analogicznie do powy¿szego:
\begin{equation}
count\_above\_mean(T_n) = |\{i: x_i > mean(T_n)\}|
\end{equation}

\item \textbf{D³ugo¶æ najd³u¿szego podci±gu o warto¶ciach poni¿ej ¶redniej}

Zdefiniowana formalnie:
\begin{equation}
strike\_below\_mean(T_n) = \max(\{j - i \; | \; 1 \leq i \leq j \leq n, \forall_{i \leq k \leq j} \; x_k < mean(T_n)\})
\end{equation}

\item \textbf{D³ugo¶æ najd³u¿szego podci±gu o warto¶ciach powy¿ej ¶redniej}

Analogicznie do powy¿szego:
\begin{equation}
strike\_above\_mean(T_n) = \max(\{j - i \; | \; 1 \leq i \leq j \leq n, \forall_{i \leq k \leq j} \; x_k > mean(T_n)\})
\end{equation}

\item \textbf{¦rednia autokorelacja}

\begin{defi}\label{d:pearson}
\emph{Wspó³czynnik korelacji Pearsona} wektorów prób losowych $\textbf{x}, \textbf{y} \in \mathbb{R}^n$ zdefiniowany jest jako
  $$pearson\_corr(\textbf{x}, \textbf{y}) = \frac{\sum_{i=1}^n(x_i - \mean{x})(y_i - \mean{y})}{\sqrt{\sum_{i=1}^n (x_i - \mean{x})^2}\sqrt{\sum_{i=1}^n (y_i - \mean{y})^2}},$$ gdzie $\mean{x}$, $\mean{y}$ oznaczaj± warto¶ci ¶rednie z tych prób, tj. $\mean{x} = \frac{\sum_{i=1}^n x_i}{n}$, $\mean{y} = \frac{\sum_{i=1}^n y_i}{n}$.
\end{defi}
Wspó³czynnik Pearsona okre¶la poziom zale¿no¶ci liniowej miêdzy zmiennymi losowymi i przyjmuje on warto¶ci z przedzia³u $[-1,1]$. Warto¶ci bliskie $1$ oznaczaj± siln± zale¿no¶æ liniow± miêdzy próbkami, warto¶ci bliskie zera - brak liniowej zale¿no¶ci, natomiast warto¶ci bliskie $-1$ - ujemn± liniow± zale¿no¶æ (rys. \ref{pearson}). \\

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.35]{pearson.png}
\captionsetup{justification=centering}
\captionsetup{width=0.7\textwidth}
\caption{Przyk³adowe wykresy danych $(x, y)$ i odpowiadaj±ce im warto¶ci wspó³czynnika korelacji liniowej Pearsona \label{pearson}}
\end{figure}


Korelacja Pearsona wykorzystywana jest przy wyliczaniu autokorelacji. Autokorelacja jest funkcj±, która argumentowi naturalnemu $k$ przypisuje warto¶æ wspó³czynnika korelacji pomiêdzy szeregiem czasowym a tym samym szeregiem cofniêtym o $k$ jednostek czasu:
\begin{displaymath}
autocorr_k(T_n) = \frac{1}{(n - k)std^2(T_n)} \sum_{i = 1}^{n - k} (x_i - mean(T_n))(x_{i + k} - mean(T_n))
\end{displaymath}

Jako cecha u¿ywana by³a ¶rednia warto¶æ autokorelacji obliczanych dla wszystkich  przesuniêæ $k$ (od 1 do $n$):
\begin{equation}
mean\_autocorr(T_n) = \frac{\sum_{k=1}^n autocorr_k(T_n)}{n}
\end{equation}

\item \textbf{Asymetryczno¶æ odwracalna w czasie}

Ta statystyka (ang. \textit{time-reversal asymmetry statistic}) zosta³a zaproponowana przez Fulchera i Jonesa w TODO. Zdefiniowana jest w zale¿no¶ci od parametru $k$ przez:
\begin{equation}
TRAS_{k}(T_n) = \frac{1}{n - 2k} \sum_{i = 0}^{n - 2k} x_{i + 2k}^2 \cdot x_{i + k} - x_{i + k} \cdot x_i^2
\end{equation}
Jako cechy wykorzystane zosta³y warto¶ci $TRAS$ dla $k = 25, 50, 100, 200$.

\item \textbf{Infromacje o skokach}

(TODO Jak sensownie przet³umaczyæ "peak"??????)
\begin{defi}\label{d:peak}
\emph{Skokiem o wsparciu $n$} nazwiemy podci±g szeregu $T_n$, w którym istnieje warto¶æ $x$ bêd±ca wiêksza ni¿ $n$ warto¶ci wystêpuj±cych bezpo¶rednio przed ni± oraz $n$ warto¶ci wystêpuj±cych bezpo¶rednio po niej.
\end{defi}

Przyk³adowo w ci±gu $(3, 0, 0, 4, 0, 0, 13)$ warto¶æ $4$ jest skokiem o wsparciu $1$ i $2$, ale nie jest skokiem o wsparciu $3$. \\
Skoki wykorzystano przy ekstrakcji piêciu kolejnych cech, które oznacza³y (kolejno) liczbê skoków o wsparciu: 5, 10, 25, 50, 100.
\end{itemize}

\hfill \\
Funkcje $min$, $max$, $mean$, $std$, $quantiles$ nazywane bêd± \textit{statystykami podstawowymi}. Z reprezentacji pochodnych (pochodnej, ca³ki, transformaty Fouriera, transformaty falkowej) wyliczane by³y tylko statystyki podstawowe. Warto¶ci wszystkich opisanych wy¿ej statystyk obliczono tylko dla bazowej reprezentacji szeregu. \\
W ten sposób z $42$ szeregów obecnych w zbiorze danych otrzymano oko³o $5000$ cech.

\subsection{Pozosta³e cechy} \label{ss:additional}

Moerchen udowadnia w (TODO biblio), ¿e u¿yteczne przy klasyfikacji szeregów czasowych jest $k$ najwiêkszych wspó³czynników transformaty Fouriera oraz transformaty falkowej. Autor zdecydowa³ siê wiêc dodaæ po 10 najwiêkszych wspó³czynników dla obydwu transformat wyliczonych dla ka¿dego z szeregów. \\
Kolejne cechy oparte by³y na korelacji miêdzy dwoma szeregami czasowymi. Analogicznie do autokorelacji, korelacjê miêdzy szeregami  $T_n = (t_1, x_1), \dots, (t_n, x_n)$  i  
$T'_n = (t_1, x'_1), \dots, (t_n, x'_n)$ definuje siê jako korelacjê Pearsona (def \ref{d:pearson}) miêdzy wektorami $(x_1, \dots x_n)$ oraz $(x_1', \dots, x_n')$. \\

Ostatecznie otrzymano oko³o 6500 cech (przypomnijmy - pocz±tkowa reprezentacja zbioru danych zawiera³a 17242 atrybuty). \\

Warto zwróæiæ uwagê, jak elastyczna jest powy¿sza metoda ekstrakcji cech - mo¿na zastosowaæ j± do praktycznie dowolnego szeregu. Inn± zalet± tej metody jest jej nied³ugi czas dzia³ania. Przyk³adowo, przekszta³cenie zbioru treningowego (sk³adaj±cego siê z 20000 instancji) zajê³o oko³o dwóch godzin na komputerze wyposa¿onym w dwurdzeniowy procesor Intel Core i5 o taktowaniu 2,7 GHz.


\chapter{Redukcja \textit{concept drift} poprzez selekcjê cech}\label{r:drift_reduction}

\section{Sprowadzenie problemu adaptacji dziedziny do problemu klasyfikacji}



\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliografia}

\bibitem[1]{1} John Blitzer, Ryan McDonald, Fernando Pereira, \textit{Domain adaptation with structural correspondence learning}

\bibitem[2]{2} Hall Daume, \textit{Frustratingly easy domain adaptation}

\bibitem[3]{3} Andrew Arnold, Ramesh Nallapati, William W. Cohen, \textit{A comparative study of methods for transductive transfer learning}

\bibitem[4]{4} R. K. Ando, T. Zhang, \textit{A framework for learning predictive structures from multiple tasks and unlabeled data}

\bibitem[5]{5} L. Breiman, \textit{Random forests}, Machine Learning, 45(1), 5-32, 2001.

\bibitem[6]{6} Wanpracha Art Chaovalitwongse, Ya-Ju Fan, Rajesh C. Sachdeo, \textit{On the time series k-nearest neighbor
classification of abnormal brain activity}

\bibitem[7]{7} Alex Nanopoulos, Rob Alcock, Yannis Manolopoulos, \textit{Feature-based classification of time-series data}

\bibitem[8]{8} Seyoung Kim, Padhraic Smyth, \textit{Segmental hidden markov models with random effects for waveform modeling}

\bibitem[9]{9} Chotirat Ann Ratanamahatana, Eamonn Keogh, \textit{Everything you know about Dynamic Time Warping is wrong}

\bibitem[10]{10} Dominique Gay, Romain Guigoures, Marc Boulle, Fabrice Clerot \textit{Feature Extraction over Multiple Representations for Time Series Classification}

\bibitem[11]{11} Jenna Wiens, John V. Guttag, Eric Horvitz, \textit{Patient Risk Stratification for Hospital-Associated C. diff as a Time-Series Classification Task}

\end{thebibliography}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: latin-2
%%% End:
