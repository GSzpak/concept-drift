%
% Niniejszy plik stanowi przyk³ad formatowania pracy magisterskiej na
% Wydziale MIM UW.  Szkielet u¿ytych poleceñ mo¿na wykorzystywaæ do
% woli, np. formatujac wlasna prace.
%
% Zawartosc merytoryczna stanowi oryginalnosiagniecie
% naukowosciowe Marcina Wolinskiego.  Wszelkie prawa zastrze¿one.
%
% Copyright (c) 2001 by Marcin Woliñski <M.Wolinski@gust.org.pl>
% Poprawki spowodowane zmianami przepisów - Marcin Szczuka, 1.10.2004
% Poprawki spowodowane zmianami przepisow i ujednolicenie 
% - Seweryn Kar³owicz, 05.05.2006
% dodaj opcjê [licencjacka] dla pracy licencjackiej
\documentclass{pracamgr}

\usepackage{polski}

%Jesli uzywasz kodowania polskich znakow ISO-8859-2 nastepna linia powinna byc 
%odkomentowana
\usepackage[latin2]{inputenc}
%Jesli uzywasz kodowania polskich znakow CP-1250 to ta linia powinna byc 
%odkomentowana
%\usepackage[cp1250]{inputenc}
\usepackage[linesnumbered]{algorithm2e}
\usepackage{caption}
\usepackage{afterpage}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{makecell}
\usepackage{enumitem}
\usepackage{csvsimple}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}

\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \newpage}

\newcommand*\mean[1]{\bar{#1}}

\DeclareCaptionFormat{listing}{\rule{\dimexpr\textwidth+17pt\relax}{0.4pt}\vskip1pt#1#2#3}
\captionsetup[lstlisting]{format=listing,singlelinecheck=false, margin=0pt, font={sf},labelsep=space,labelfont=bf}

\renewcommand\lstlistingname{Algorytm}
% Dane magistranta:

\author{Grzegorz Szpak}

\nralbumu{319400}

\title{Klasyfikacja wielowymiarowych szeregów czasowych przy ewoluuj±cych pojêciach}

\tytulang{Classification of multivariate time series in the presence of concept drift}

%kierunek: Matematyka, Informatyka, ...
\kierunek{Informatyka}

% informatyka - nie okreslamy zakresu (opcja zakomentowana)
% matematyka - zakres moze pozostac nieokreslony,
% a jesli ma byc okreslony dla pracy mgr,
% to przyjmuje jedna z wartosci:
% {metod matematycznych w finansach}
% {metod matematycznych w ubezpieczeniach}
% {matematyki stosowanej}
% {nauczania matematyki}
% Dla pracy licencjackiej mamy natomiast
% mozliwosc wpisania takiej wartosci zakresu:
% {Jednoczesnych Studiow Ekonomiczno--Matematycznych}

% \zakres{Tu wpisac, jesli trzeba, jedna z opcji podanych wyzej}

% Praca wykonana pod kierunkiem:
% (podaæ tytu³/stopieñ imiê i nazwisko opiekuna
% Instytut
% ew. Wydzia³ ew. Uczelnia (je¿eli nie MIM UW))
\opiekun{dra Andrzeja Janusza \\
  Instytut Informatyki \\
  }

% miesi±c i~rok:
\date{Grudzieñ 2016}

%Podaæ dziedzinê wg klasyfikacji Socrates-Erasmus:
\dziedzina{ 
%11.0 Matematyka, Informatyka:\\ 
%11.1 Matematyka\\ 
%11.2 Statystyka\\ 
11.3 Informatyka TODO\\ 
%11.4 Sztuczna inteligencja\\ 
%11.5 Nauki aktuarialne\\
%11.9 Inne nauki matematyczne i informatyczne
}

%Klasyfikacja tematyczna wedlug AMS (matematyka) lub ACM (informatyka)
\klasyfikacja{D. Software TODO\\
}

% S³owa kluczowe:
\keywords{Eksploracja danych, wielowymiarowy szereg czasowy, ewoluuj±ce pojêcia, dopasowanie dziedziny, ekstrakcja cech, selekcja cech, lasy losowe, regresja logistyczna, maszyna wektorów wspieraj±cych}

% Tu jest dobre miejsce na Twoje w³asne makra i~¶rodowiska:
\newtheorem{defi}{Definicja}[section]

% koniec definicji

\begin{document}
\maketitle

%tu idzie streszczenie na strone poczatkowa
\begin{abstract}
  W pracy przedstawiono sposoby wydajnej klasyfikacji szeregów czasowych dla danych pochodz±cych ze ¼ród³a o zmiennym rozk³adzie. Opisane zosta³y metody ekstrakcji cech z wielowymiarowego szeregu czasowego. Autor opisuje tak¿e metody wyboru przestrzeni atrybutów odpornej na zmiany rozk³adu ¼ród³a. Przedstawia równie¿ algorytmy adaptacji dziedziny opisywane w literaturze.
\end{abstract}

\tableofcontents
%\listoffigures
%\listoftables

\chapter*{Wprowadzenie}
\addcontentsline{toc}{chapter}{Wprowadzenie}
Jedn± z g³ównych trudno¶ci, z jak± zmierzyæ siê musz± twórcy algorytmów uczenia maszynowego, jest z pewno¶ci± ogromna ró¿norodno¶æ danych. Nawet w obrêbie tego samego zagadnienia natrafiæ mo¿na na wielkie zró¿nicowanie badanych obiektów. Rozpatrzmy na przyk³ad problem wykrywania niechcianej poczty, w którym regu³y uzyskane przez tradycyjne algorytmy musz± byæ dostosowywane do indywidualnych preferencji danego u¿ytkownika. Innym przyk³adem mo¿e byæ rozpoznawanie obrazów - badane obiekty zale¿± od wielu czynników, takich jak o¶wietlenie, t³o, czy rozdzielczo¶æ. Problem ró¿norodno¶ci danych jest równie¿ wyra¼nie widoczny w dziedzinie klasyfikacji tekstu. Istotnie, w zale¿no¶ci od tematyki tekstu czy ¼ród³a jego pochodzenia ten sam wyraz mo¿e przyjmowaæ wiele znaczeñ. \\
Z tego powodu stosunkowo nowym obszarem badañ w dziedzinie uczenia maszynowego sta³y siê algorytmy tak zwanej \textit{adaptacji dziedziny}, czyli konstrukcji takich klasyfikatorów, które w obrêbie okre¶lonego zadania bêd± zachowywaæ wydajno¶æ dla danych pochodz±cych z ró¿nych ¼róde³. Zdecydowana wiêkszo¶æ opracowanych dotychczas metod dotyczy problemów zwi±zanych z rozpoznawaniem tekstu (\cite{BlitzerMP06}, \cite{Daume07}, \cite{XiaYXW14}, \cite{BlitzerDP07}) oraz klasyfikacj± obrazów (\cite{MirrashedR13}, \\ \cite{KulisSD11}). \\
Niewiele jest natomiast algorytmów dotykaj±cych zagadnienia adaptacji dziedziny dla zadania klasyfikacji szeregów czasowych, którego to zadania problem ró¿norodno¶ci ¼róde³ danych tak¿e dotyczy. Wystarczy wzi±æ pod uwagê takie zadania jak rozpoznawanie mowy, badanie fal mózgowych czy wykrywanie anomalii w odczytach elektrokardiografu - w ka¿dym z nich interpretacja wyników mocno zale¿y od badanej osoby. W niniejszej pracy autor postara siê uzupe³niæ tê lukê, prezentuj±c sposoby ekstrakcji cech z szeregów czasowych oraz opisuj±c metodê wybierania podprzestrzeni cech odpornych na zmianê ¼ród³a danych. Autorskie podej¶cie zostanie równie¿ skonforntowane z wybranymi algorytmami adaptacji dziedziny.


\chapter{Podstawowe pojêcia}\label{r:wprowadzenie}

\section{Uczenie z nadzorem a \textit{concept drift}} \label{s:superv}

Rozwa¿my nastêpuj±cy problem: na podstawie zbioru informacji personalnych (takich jak wiek, dochody, stan cywilny) napisaæ algorytm, który bêdzie umia³ z du¿± dok³adno¶ci± okre¶liæ ryzyko kredytowe danej osoby i na tej podstawie podj±æ decyzjê o udzieleniu kredytu. Takie zadanie w teorii uczenia maszynowego nazywa siê problemem \textit{uczenia z nadzorem} (ang. \textit{supervised learning}). Dany zbiór informacji nazywa siê \textit{zbiorem treningowym}. Zbiór decyzji (w tym przypadku dwuelementowy) nazywa siê z kolei \textit{klasami} b±d¼ \textit{etykietami}. \\
Mówi±c bardziej formalnie, niech dane bêd±:
\begin{itemize}
\item zbiór $X$ przyk³adów
\item zbiór $Y$ decyzji
\item funkcja $f: X \rightarrow Y$
\item Para zbiorów $(X_{train} \subseteq X, Y_{train} \subseteq Y)$ instancji $x_1, x_2, \dots, x_n$ oraz odpowiadaj±cych im decyzji $f(x_1), f(x_2), \dots, f(x_n)$, zwana \textit{zbiorem treningowym}
\end{itemize}
Zadanie uczenia z nadzorem polega na wyznaczeniu na podstawie zbioru treningowego oraz przy u¿yciu pewnego algorytmu ucz±cego (\textit{klasyfikatora}) takiej funkcji $c: X \rightarrow Y$ (zwanej \textit{modelem}), która bêdzie dobr± aproksymacj± funkcji $f$. Jako¶æ modelu $c$ okre¶la siê, porównuj±c jego warto¶ci dla elementów skoñczonego \textit{zbioru testowego} $X_{test}$ z rzeczywistymi warto¶ciami funkcji $f$ dla tych elementów. Istotne jest przy tym za³o¿enie, ¿e elementy zbiorów $X_{train}$ oraz $X_{test}$ losowane s± ze zbioru $X$ wed³ug tego samego rozk³adu prawdopodobieñstwa $D$. \\
Schemat rozwi±zywania problemu uczenia z nadzorem przedstawia rys. \ref{supervised}.

\begin{figure}[t!]
\centering
\includegraphics[scale=0.6]{supervised.png}
\caption{Schemat uczenia z nadzorem \label{supervised}}
\end{figure}


Na przestrzeni ostatnich dziesiêcioleci opracowanych zosta³o wiele algorytmów ucz±cych wykazuj±cych siê du¿± skuteczno¶ci± w przeró¿nych dziedzinach: od rozpoznawania obrazów, przez klasyfikacjê tekstów, rekomendacjê produktów, wykrywanie niechcianej poczty, po przewidywanie zmian na gie³dzie czy diagnostykê medyczn±. \\
Sytuacja zmienia siê diametralnie, gdy pominiemy za³o¿enie o równo¶ci rozk³adów dla zbiorów treningowych i testowych. Wiele klasyfikatorów cierpi wtedy na znaczny spadek jako¶ci. Problem ten nazywa siê \textit{ewolucj± pojêæ} (ang. \textit{concept drift}) lub \textit{dopasowaniem dziedziny} (ang. \textit{domain adaptation}). Jest on szczególnie widoczny w zadaniach przetwarzania jêzyka naturalnego (ang. \textit{natural language processing}, w skrócie NLP). Rozpatrzmy dla przyk³adu problem rozpoznawania nazw w³asnych (ang. \textit{named entity recognition}). Za³ó¿my, ¿e klasyfikator uczony jest na podstawie danych encyklopedycznych oraz testowany na danych pochodz±cych z komunikatora internetowego. Obydwa zbiory, jakkolwiek powi±zane, ró¿ni± siê w znacz±cy sposób - przyk³adowo, szukanie wielkich liter mo¿e byæ bardzo pomocne w pierwszej dziedzinie, a nie¶æ znacznie mniej informacji w wiadomo¶ciach z komunikatora.\\
St±d te¿ w³a¶nie w dziedzinie NLP powsta³o najwiêcej metod maj±cych rozwi±zaæ problem ewoluuj±cych pojêæ. Przyk³adami takich metod s± algorytm \textit{structural correspondence learning} opisywany w \cite{BlitzerMP06} czy metoda odpowiedniego dopasowania przestrzeni parametrów zaproponowana przez Daum{\'{e}} w \cite{Daume07}. \\

Problem \textit{domain adaptation} nie jest jednak czêsto poruszany w przypadku klasyfikacji szeregów czasowych. W poni¿szej pracy autor przedstawia sposoby radzenia sobie z adaptacj± dziedziny podczas klasyfikacji szeregów czasowych oraz wykonuje studium przypadku na wybranym zbiorze danych.

\section{Formalizacja problemu}

\subsection{Paradygmaty uczenia siê} \label{ss:pardigms}

Przyjmijmy definicje jak na pocz±tku sekcji \ref{s:superv}. W zale¿no¶ci od dostêpno¶ci zbiorów $Y_{train}$, $X_{test}$, $Y_{test}$, mo¿na (za \cite{ArnoldNC07}) zdefiniowaæ inne paradygmaty uczenia. \\
I tak, je¶li zbiór $Y_{train}$ jest nieznany w momencie tworzenia modelu, mamy do czynienia z \textit{uczeniem bez nadzoru} (ang. \textit{unsupervised learning}). \\
Gdy zbiór $X_{test}$ nie jest znany podczas uczenia, mowa o \textit{uczeniu indukcyjnym} (ang. \textit{inductive learning}). W przeciwnym razie takie uczenie nazywa siê \textit{uczeniem transdukcyjnym} (ang. transductive learning). \\
W powy¿szym przyk³adach istotne jest za³o¿enie, i¿ zbiory $X_{train}$, $X_{test}$ pochodz± z tego samego rozkladu $D$. Odwrotna sytuacja rozpatrywana jest w paradygmacie \textit{uczenia z przeniesieniem wiedzy} (ang. \textit{transfer learning}). Przyjmuje siê w nim, ¿e dane s± dwa ró¿ne rozk³ady $D^{source}$ i $D^{target}$. Model wyuczony na danych treningowych $X^{source}_{train}, Y^{source}_{train}$ z rozk³adu $D^{source}$ wykorzystywany jest do klasyfikacji zbioru testowego $X^{target}_{test}, Y^{target}_{test}$ pochodz±cych z rozk³adu $D^{target}$. W poni¿szej pracy autor skupia siê na problemie \textit{dopasowania dziedziny}, który zak³ada, ¿e zbiór dostêpnych klas $Y$ jest ten sam dla $D^{source}$ i $D^{target}$. Przeciwieñstwem dopasowania dziedziny jest zadanie \textit{uczenia wielozadaniowego} (ang. \textit{multi-task learning}, wiêcej miêdzy innymi w \cite{AndoZ05}), gdzie zbiory $X_{train}$, $ X_{test}$ pochodz± z tego samego rozk³adu, natomiast zbiory $Y_{train}$, $Y_{test}$ s± ró¿ne. \\

Powy¿sze rozwa¿ania podsumowuje tabela \ref{t:paradigms}.

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.7\textwidth}
\caption[Paradygmaty uczenia w teorii uczenia maszynowego]{Paradygmaty uczenia w teorii uczenia maszynowego. We wszystkich przypadkach zak³adamy, ¿e zbiór $X_{train}$ jest dostêpny podczas uczenia, podczas gdy zbiór $Y_{test}$ nie jest znany. Dane treningowe pochodz± z rozk³adu $D^{source}$.}
\label{t:paradigms}
\begin{tabular}{|c|c|c|c|}
\hline
Paradygmat & $Y_{train}$ dostêpny? & $X_{test}$ dostêpny? & Rozk³ad danych testowych \\ \hline
\makecell{Indukcyjne uczenie \\ bez nadzoru}  & Nie & Nie & $D^{source}$ \\ \hline
\makecell{Transdukcyjne uczenie \\ bez nadzoru}  & Nie & Tak & $D^{source}$ \\ \hline
\makecell{Indukcyjne uczenie \\ z nadzorem}  & Tak & Nie & $D^{source}$ \\ \hline
\makecell{Transdukcyjne uczenie \\ z nadzorem}  & Tak & Tak & $D^{source}$ \\ \hline
\makecell{Indukcyjne uczenie \\ bez nadzoru \\ z przeniesieniem wiedzy}  & Nie & Nie & $D^{target}$ \\ \hline
\makecell{Transdukcyjne uczenie \\ bez nadzoru \\ z przeniesieniem wiedzy}  & Nie & Tak & $D^{target}$ \\ \hline
\makecell{Indukcyjne uczenie \\ z nadzorem \\ z przeniesieniem wiedzy}  & Tak & Nie & $D^{target}$ \\ \hline
\makecell{Transdukcyjne uczenie \\ z nadzorem \\ z przeniesieniem wiedzy}  & Tak & Tak & $D^{target}$ \\ \hline
\end{tabular}
\end{table}

W poni¿szej pracy autor skupi siê na problemie uczenia z nadzorem z przeniesieniem wiedzy. Przedstawione zostan± algorytmy, które wykorzystuj± dostêpny zbiór $X_{test}$ do znalezienia reprezentacji odpornej na zmiany rozk³adu, co skutkowaæ bêdzie zwiêkszon± jako¶ci± klasyfikacji w stosunku do standardowego podej¶cia opisanego w \ref{s:superv}. \\
Warto jednak zwróciæ uwagê na fakt, ¿e bardziej powszechna jest sytuacja, gdy zbiór testowy nie jest znany podczas uczenia - czyli du¿o czê¶ciej mamy do czynienia z podproblemem uczenia indukcyjnego. Istotnie, w wielu sytuacjach dziedzin, z których mog± pochodziæ dane, jest tak wiele, ¿e ciê¿ko by³oby zawrzeæ w $X_{test}$ reprezentatywn± próbkê dla ka¿dej z nich. Przyk³adem bêdzie zbiór przedstawiony w rozdziale \ref{r:experiment}. Z tego powodu autor proponuje w rozdziale \ref{r:drift_reduction}. metodê selekcji cech niewra¿liwych na zmianê dziedziny niewymagaj±c± posiadania zbioru testowego podczas uczenia.

\subsection{Ewolucja pojêæ a problem przeuczenia}

Mówi±c o problemie ewoluuj±cych pojêæ, nale¿y wspomnieæ o zagadnieniu przeuczenia (ang. \textit{overfitting}). Polega on na zbudowaniu modelu nadmiernie dopasowanego do danych treningowych, co skutkuje s³ab± jego jako¶ci± (rys. \ref{overfitting}).

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.1]{overfitting.png}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption[Przyk³ad przeuczenia]{Przyk³ad modelu przeuczonego (zielona linia) i zregularyzowanego (czarna linia) \label{overfitting}}
\end{figure}

Obydwa pojêcia mog± byæ mylone przy niew³a¶ciwym sposobie walidacji modelu. Je¶li jako¶æ klasyfikacji sprawdzana jest wy³±cznie na zbiorach treningowym i testowym, zarówno \textit{concept drift}, jak i \textit{overfitting} daj± podobne objawy - wysoki wynik na zbiorze treningowym oraz niski na zbiorze testowym. W przypadku przeuczenia jest to spowodowane nadmiernym dopasowaniem modelu do danych treningowych i jego nisk± zdolno¶ci± do uogólniania. Je¶li mamy do czynienia z ewoluuj±cymi pojêciami, s³aba jako¶æ modelu jest spowodowana innym rozk³adem dla zbioru testowego. \\
W rozró¿nienu obydwu sytuacji pomagaæ mo¿e zastosowanie \textit{walidacji krzy¿owej} (ang. \textit{cross-validation}) na zbiorze treningowym. Walidacja krzy¿owa polega na podziale zbioru treningowego na $n$ równolicznych czê¶ci. Nastêpnie budowane jest $n$ modeli, przy czym $n - 1$ czê¶ci tworzy zbiór treningowy, natomiast pozosta³a czê¶æ - zbiór testowy. Ostateczny wynik jest ¶rednim wynikiem powsta³ych $n$ modeli. \\
Nietrudno zauwa¿yæ, ¿e w przypadku \textit{concept drift} nie powinno siê zauwa¿yæ znacznego spadku jako¶ci modelu przy wykonaniu walidacji krzy¿owej na $X_{train}$ - w tym przypadku zbiór walidacyjny pochodzi z tej samej dziedziny co treningowy. Inaczej bêdzie w przypadku przeuczenia - tu wynik walidacji krzy¿owej bêdzie wyra¼nie ni¿szy ni¿ wynik klasyfikacji na samym zbiorze treningowym (tabela \ref{t:overfit}). \\ 

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption[\textit{Concept drift} a \textit{overfitting}]{\textit{Concept drift} a \textit{overfitting} - obni¿ony wynik modelu 1. przy walidacji krzy¿owej ¶wiadczy o przeuczeniu, a nie wystêpowaniu ewoluuj±cych pojêæ. W drugim przypadku model mimo dobrej umiejêtno¶ci klasyfikacji elementów pochodz±cych z rozk³adu $D^{source}$, cierpi na spadek jako¶ci przy ewaluacji na zbiorze pochodz±cym z rozk³adu $D^{target}$.}
\label{t:overfit}
\begin{tabular}{|c|c|c|c|}
\hline
  & Wynik na $X_{train}$ & Wynik CV & Wynik na $X_{test}$ \\ \hline
Model 1  & 0.98 & 0.73 & 0.68 \\ \hline
Model 2  & 0.97 & 0.92 & 0.76 \\ \hline
\end{tabular}
\end{table}

\subsection{Uk³ad pracy} \label{s:content}

Celem niniejszej pracy jest zbudowanie wydajnego klasyfikatora dla zbioru danych z³o¿onego z wielowymiarowych szeregów czasowych, w którym obecny jest problem ewolucji pojêæ miêdzy zbiorem treningowym a testowym. \\
W rozdziale \ref{r:experiment}. przedstawiony jest badany zbiór danych. Autor opisuje równie¿ pokrótce klasyfikatory wykorzystane podczas badañ oraz daje przyk³ad obecno¶ci \textit{concept drift} w analizowanym zbiorze. Rozdzia³ \ref{r:features}. prezentuje proces ekstrakcji cech z szeregów czasowych. W rozdziale \ref{r:drift_reduction}. autor opisuje metodê wyboru takiej podprzestrzeni cech, która bêdzie odporna na efekt ewolucji pojêæ i jednocze¶niej umo¿liwi wydajn± klasyfikacjê zadanych szeregów. Przedstawione s± najbardziej znane miary jako¶ci atrybutów jak równie¿ dwa algorytmy wykrywania zmiany dziedziny. Autor prezentuje tak¿e wyniki szeregu eksperymentów maj±cych sprawdziæ wydajno¶æ opisywanej metody w praktyce.
Rozdzia³ \ref{r:other}. zawiera opis dwóch innych algorytmów adaptacji dziedziny - uczenia iteracyjnego oraz powiêkszania przestrzeni cech. W rozdziale \ref{r:summary}. znajduje siê podsumowanie ca³ej pracy oraz wnioski z niej p³yn±ce.

\chapter{Opis przeprowadzanego eksperymentu}\label{r:experiment}

\section{Przedstawienie badanego problemu} \label{s:problem}

\subsection{Opis zbioru danych} \label{ss:data}

Dane, na których sprawdzana by³a jako¶æ analizowanych algorytmów, pochodz± z konkursu \textit{AAIA'15 Data Mining Competition: Tagging Firefighter Activities at a Fire Scene}\footnote{https://knowledgepit.fedcsis.org/contest/view.php?id=106} organizowanego przez Uniwersytet Warszawski oraz Szko³ê G³ówn± S³u¿by Po¿arniczej w Warszawie. \\
Na potrzeby konkursu zebrano odczyty pochodz±ce z "inteligentnego kombinezonu", który monitoruje ruchy oraz funkcje ¿yciowe stra¿aka. W sk³ad kombinezonu wchodzi³o po siedem akcelerometrów i ¿yroskopów umieszczonych na: tu³owiu, ramionach, d³oniach i nogach (rys. \ref{fireman}).

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.35]{fireman.png}
\caption{Rozmieszczenie czujników na ciele stra¿aka \label{fireman}}
\end{figure}

Ka¿da instancja w zbiorze danych sk³ada³a siê z zebranych w krótkich odcinkach czasu (oko³o 1.8 s) odczytów z zamontowanych sensorów. Dla ka¿dego akcelerometru oraz ¿yroskopu zebrano po 400 odczytów wzd³u¿ osi $x$, $y$, $z$, wraz ze wzglêdnym czasem wykonania odczytu. Dla ka¿dego wiersza daje to 42-wymiarowy szereg czasowy o d³ugo¶ci 400. Jak ³atwo wywnioskowaæ, ¶redni odstêp miêdzy kolejnymi odczytami wynosi³ oko³o 4.5 ms. Zestaw atrybutów uzupe³nia³y dodatkowo 42 agregaty ze wskazañ urz±dzeñ monitoruj±cych funkcje ¿yciowe stra¿aka (takie jak EKG, czêstotliwo¶æ oddechu, temperatura skóry). Nieprzetworzone dane zawiera³y wiêc $400 * 43 + 42 = 17242$ atrybuty. Zarówno zbiór treningowy, jak i testowy sk³ada³y siê z $20000$ przyk³adów. Bardzo istotny dla dla analizy tego zbioru danych okaza³ siê fakt, ¿e dane treningowe i testowe pochodzi³y od ró¿nych czteroosobowych grup stra¿aków. \\
Zadaniem uczestników konkursu by³o przypisanie ka¿dej instancji w zbiorze postury stra¿aka w danym momencie oraz wykonywanej przez niego czynno¶ci. Zastosowane algorytmy mia³y pomóc w stworzeniu systemu monitoruj±cego bezpieczeñstwo stra¿aka podczas akcji. \\
Szczegó³owe podsumowanie konkursu (miêdzy innymi opis procedury zbierania danych, miary u¿ytej do ewaluacji wyników oraz rezultatów uzyskanych przez uczestników) znale¼æ mo¿na w \cite{MeinaJRSCK15}.

Jako ¿e problem klasyfikacji wieloetykietowej nie jest tematem niniejszej pracy, autor postanowi³ skupiæ siê na problemie przewidywania czynno¶ci wykonywanej przez stra¿aka. Zbiór klas liczy³ wiêc $16$ elementów. Postawiony problem utrudnia³ dodatkowo fakt, ¿e klasy by³y wysoce niezbalansowane - najczêstsza klasa ($manipulating$) wyst±pi³a w zbiorze treningowym $6349$ razy, podczas gdy najrzadsza ($signal\_hose\_pullback$) - jedynie 98 razy.\\
Rozk³ad klas przedstawia rys. \ref{classes}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.5]{classes.png}
\caption{Rozk³ad klas w zbiorze treningowym \label{classes}}
\end{figure}

\subsection{Ewaluacja jako¶ci klasyfikatora} \label{ss:evaluation}

Standardow± miar± jako¶ci jest prezycja (ang. \textit{accuracy}):
\begin{displaymath}
ACC(c) = \frac{1}{n} \sum_{i=1}^n \mathbf{1}[c(\textbf{x}_i) = y_i]
\end{displaymath}
W opisywanym konkursie zastosowano modyfikacjê tej miary zwan± \textit{balanced accuracy}, zdefiniowan± nastêpuj±co:

\begin{equation}
ACC_i(c) = \frac{|j: \,c(\textbf{x}_j) = y_j = i|}{|j: y_j = i|} \\
\end{equation}

\begin{equation} \label{bac}
BAC(c) = \frac{\sum_{i=1}^l ACC_i(c)}{l} 
\end{equation}
Nietrudno zauwa¿yæ, ¿e miara $BAC$ jest bardziej wra¿liwa na b³êdn± klasyfikacjê rzadkich klas ni¿ standardowa miara $ACC$. \\
Jak wspomniano wcze¶niej, zadaniem w konkursie by³a klasyfikacja zarówno postury, jak i czynno¶ci stra¿aka. Ostateczny wynik w zawodach obliczany by³ przez:
\begin{equation}
score(c_p, c_a) = \frac{BAC(c_p) + 2 \cdot BAC(c_a)}{3},
\end{equation}
gdzie $c_p$ by³ modelem dla postury, a $c_a$ - modelem dla czynno¶ci. Poniewa¿ autor niniejszej pracy analizuje wy³±cznie czynno¶ci wykonywane przez stra¿aków, prezentowanych wyników nie mo¿na bezpo¶rednio porównywaæ z rezultatami uzyskanymi przez uczestników konkursu.

\section{Opis u¿ytych klasyfikatorów} \label{s:klasyfikatory}

W kolejnych rozdzia³ach przedstawione zostan± metody maj±ce na celu zwiêkszenie jako¶ci modelu budowanego na danych, w których obecny jest problem ewoluuj±cych pojêæ. U¿yteczno¶æ tych metod sprawdzana bêdzie dla trzech ró¿nych algorytmów uczenia: klasyfikatorze opartym na regresji logistycznej, maszynie wektorów no¶nych (ang. \textit{support vector machine}, SVM) oraz drzewach decyzyjnych.

\subsection{Klasyfikator liniowy} \label{ss:linear}

Regresja logistyczna i maszyna wektorów wspieraj±cych nale¿± do grupy klasyfikatorów liniowych. Przyjmijmy oznaczenia jak w sekcji \ref{s:superv}. Za³ó¿my, ¿e zbiór klas $Y$ jest dwuelementowy - dla uproszczenia niech $Y = \{+1, -1 \}$. Niech dalej $y \in Y$ bêdzie decyzj± dla elementu $\textbf{x} = (x_1, x_2, \dots, x_m) \in X \subseteq \mathbb{R}^m$. Klasyfikatorem liniowym nazywamy $m - 1$ - wymiarow± hiepr³aszczyznê rozdzielaj±c± punkty z $X$. Niech $\textbf{w} = (w_1, w_2, \dots, w_m) \in \mathbb{R}^m$ bêdzie wektorem wspó³czynników tej hiperp³aszczyzny. Uczenie klasyfikatora liniowego zwykle polega na minimalizacji warto¶ci pewnej funkcji b³êdu $l(\textbf{w})$ na zbiorze treningowym.

\subsubsection{Klasyfikacja oparta na regresji logistycznej (\textit{logit})}

Niech
\begin{displaymath}
g(z) = \frac{1}{1 + e^{-z}}
\end{displaymath}
zwana bêdzie funkcj± logistyczn±. Jej wykres przedstawia rysunek \ref{sigmoid}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.3]{sigmoid.png}
\caption{Wykres funkcji logistycznej \label{sigmoid}}
\end{figure}

Funkcja $g$ jest oczywi¶cie ci±g³a. Jednocze¶nie $\lim_{z \to -\inf} \; g(z) = 0$ oraz $\lim_{z \to \inf} \; g(z) = 1$. Dziêki tym w³a¶ciwo¶ciom nadaje siê ona do modelowania prawdopodobieñstwa danego zjawiska. Klasyfikator bazuj±cy na regresji logistycznej modeluje prawdopodobieñstwo nale¿enia do klasy pozytywnej przez funkcjê:
\begin{displaymath}
p_w(\textbf{x}) = g(\textbf{w}^\intercal\textbf{x}) = \frac{1}{1 + e^{-\textbf{w}^\intercal\textbf{x}}},
\end{displaymath}

przy czym klasyfikacja dokonywana jest przez: 

\begin{displaymath}
c_w(\textbf{x}) = 1 \iff p_w(\textbf{x}) \geq \frac{1}{2}.
\end{displaymath}

Uczenie klasyfikatora opartego na regresji logistycznej polega wiêc na znalezieniu hiperp³aszczyzny $\textbf{w}$, która minimalizuje nastêpuj±c± funkcjê straty:

\begin{displaymath}
l_{log\_loss}(\textbf{w}) = \sum_{i = i}^n log(1 + e^{-y_i\textbf{w}^\intercal\textbf{x}_i}).
\end{displaymath}

\subsubsection{Maszyna wektorów no¶nych}

Innym typem klasyfikatora liniowego jest (ang. \textit{support vector machine}, SVM). Uczenie SVM polega na znalezieniu hiperp³aszczyzny o najwiêkszej odleg³o¶ci od punktów obydwu klas (rys. \ref{svm}) - z tego powodu SVM nazywany jest klasyfikatorem maksymalnego marginesu (ang. \textit{max margin classifier}).

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.5]{svm.png}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption[Przyk³ad klasyfikacji za pomoc± SVM]{P³aszczyzna $H_1$ nie rozdziela klas. \\ P³aszczyzna $H_2$ rozdziela je, ale z niewielkim marginesem. \\P³aszczyzna $H_3$ rozdziela je z maksymalnym marginesem. \label{svm}}
\end{figure}

Za³o¿enie o liniowej separowalno¶ci klas jest jednak rzadko spe³nione. Uczenie klasyfikatora SVM polega wiêc na znalezieniu hiperp³aszczyzny $\textbf{w}$, która minimalizuje funkcjê
straty dan± jako

\begin{displaymath}
l_{hinge\_loss}(\textbf{w}) = \sum_{i = i}^n max(0, 1 - y_i\textbf{w}^\intercal\textbf{x}_i).
\end{displaymath}

\subsubsection{Klasyfikator "jeden przeciwko wszystkim"}

Jak wspomniano wcze¶niej, zarówno regresja logistyczna, jak i SVM s± klasyfikatorami binarnymi - zak³adaj±, ¿e zbiór klas $Y$ jest dwuelementowy. Aby u¿yæ ich do klasyfikacji danego zbioru, potrzebna by³a metoda klasyfikacji wieloklasowej. Zastosowano podej¶cie zwane "jeden przeciw wszystkim" (ang. \textit{one-vs.-all}, OvA, b±d¼ \textit{one-vs.-rest}, OvR). \\
Niech $Y = \{1, 2, \dots, k \}$. Klasyfikacja OvA polega na nauczeniu $k$ binarnych klasyfikatorów $c_1, c_2, \dots, c_k$. Klasa dla $j$ - tego klasyfikatora zdefiniowana jest nastêpuj±co:

\begin{displaymath}
y^j_i = 1 \iff y_i = j
\end{displaymath}

Ostatecznie elementowi $x$ przypisywana jest klasa, której klasyfikator daje najmniejsz± warto¶æ funkcji b³êdu:

\begin{displaymath}
c(\textbf{x}) = arg \min_{j \in 1\dots k} \,  l_j(\textbf{x})
\end{displaymath}


\subsection{Lasy losowe} \label{ss:random_forest}
Innym typem klasyfikatora jest las losowy. Jest to klasyfikator wykorzystuj±cy prostszy klasyfikator - drzewo decyzyjne.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.6]{decision_tree.png}
\caption{Przyk³adowe drzewo decyzyjne \label{dec_tree}}
\end{figure}

Drzewo decyzyjne to etykietowane drzewo, którego ka¿dy wêze³ odpowiada przeprowadzeniu pewnego testu na warto¶ciach atrybutów. Z wêz³a wewnêtrznego wychodzi tyle ga³êzi, ile jest mo¿liwych wyników testu odpowiadaj±cego temu wêz³owi. Ka¿dy li¶æ zawiera decyzjê o klasyfikacji obiektu. Przyk³adowe drzewo decyzyjne przedstawia rys. \ref{dec_tree}. \\
Uczenie lasu losowego polega na uczeniu okre¶lonej liczby drzew decyzyjnych - ka¿dego na losowej podprzestrzeni atrybutów. Finalna klasa wyznaczana jest na podstawie wyników pojedynczych drzew. Lasy losowe, podobnie jak drzewa decyzyjne, wspieraj± klasyfikacjê wieloklasow±. Pe³en algorytm uczenia lasów losowych opisany jest w \cite{Breiman01}.

\chapter{Ekstrakcja cech z szeregów czasowych} \label{r:features}

\section{Metody klasyfikacji szeregów czasowych}

Szeregi czasowe obecne s± w wielu ró¿nych dziedzinach ¿ycia - od medycyny, przez finanse, wyszukiwanie informacji, po przetwarzanie sygna³ów oraz prognozê pogody. W ostatnich latach opisanych zosta³o wiele metod do wykrywania wzorców czasowych w takich zadaniach jak: okre¶lanie stanu zdrowia pacjenta na podstawie odczytów elektrokardiografu, przewidywanie wahañ na gie³dzie, analiza mowy czy prognozowanie temperatur. \\
W¶ród metod zaproponowanych do klasyfikacji szeregów czasowych znale¼æ mo¿na wiêkszo¶æ najbardziej znanych algorytmów uczenia siê: metodê k-najbli¿szych s±siadów (ang. \textit{k-nearest neighbours}, w skrócie k-NN - wiêcej w \cite{ChaovalitwongseFS07}), sieci neuronowe (\cite{RavikumarD14}) czy ukryty model Markowa (\cite{KimS06}). Wci±¿ jednak najszerzej u¿ywane (i uznawane za najbardziej skuteczne) s± warianty algorytmu k-NN z u¿yciem ró¿nych metryk, takich jak odleg³o¶æ euklidesowa czy Dynamic Time Warping (w skrócie DTW) - wiêcej o DTW przeczytaæ mo¿na miêdzy innymi w \cite{dtwyouknow}. \\
W poni¿szej pracy zastosowano nieco odmienne podej¶cie.  Autor koncentruje siê na ekstrakcji cech opartych na statystycznych w³asno¶ciach szeregów. Cechy te wyliczane s± z ró¿nych reprezentacji danego szeregu. Nastêpnie na tak przekszta³conych danych uczone by³y klasyfikatory opisane w sekcji \ref{s:klasyfikatory}. Jak pokazuj± niektóre badania (przyk³adowo - \\ \cite{RavikumarD14}, \cite{GayGBC13}), takie podej¶cie daje czêsto lepsze wyniki ni¿ algorytmy bazuj±ce na podobieñstwie szeregów.

\section{Proces ekstrakcji cech} \label{s:extraction}

Zacznijmy od formalnego zdefiniowania \textit{szeregu czasowego}.

\begin{defi}\label{d:series}
  \emph{Jednowymiarowym szeregiem czasowym} $T_n$ nazwiemy skoñczony ci±g par
  $$(t_1, x_1), (t_2, x_2), \dots, (t_n, x_n)$$
 o d³ugo¶ci $n$, gdzie $x_k$ jest warto¶ci± szeregu w czasie $t_k$. 
\end{defi}
\hfill \\
Proces ekstrakcji cech dla szeregu czasowego przebiega³ nastêpuj±co:
\begin{enumerate}[label*=\arabic*.]
\item Wyznaczenie pochodnych reprezentacji szeregu czasowego (wiêcej w sekcji \ref{ss:representations})
\item Wyliczenie statystyk z wyznaczonych reprezentacji
\item Dodanie pozosta³ych cech (bazuj±cych miêdzy innymi na korelacji miêdzy szeregami)
\end{enumerate}
\hfill \\
W kolejnych sekcjach zostanie omówiony ka¿dy z powy¿szych kroków.

\subsection{Reprezentacje pochodne szeregu czasowego} \label{ss:representations}

Wiele przekszta³ceñ i reprezentacji szeregów czasowych zosta³o opisanych w literaturze - ich szerszy przegl±d mo¿na znale¼æ miêdzy innymi w \cite{FulcherJ14}. Celem takich przekszta³ceñ jest wykrycie wzorców charakterystycznych dla klas wynikowych, które nie s± wykrywalne przy u¿yciu podstawowej reprezentacji $T_n$. \\
\cite{GayGBC13} podaje przyk³ad, kiedy to badanie drugiej pochodnej szeregu po czasie znacznie zwiêksza jako¶æ klasyfikacji (rys. \ref{example}). Dzia³aj±c na oryginalnych danych, trudno jest rozró¿nic dwie klasy. Policzenie drugiej pochodnej sprawia, ¿e klasyfikacja staje siê niemal¿e trywialna.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.8]{example.png}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption[Przyk³ad korzy¶ci z badania reprezentacji pochodnych szeregu]{Po lewej widaæ oryginalny zbiór danych, natomiast po prawej - drug± pochodn± po czasie \label{example}}
\end{figure}

Autor, poza reprezentacj± oryginaln± $T_n$, zdecydowa³ siê wykorzystaæ w procesie ekstrakcji cech cztery inn reprezentacje: 
\begin{itemize}
\item pochodn± szeregu po czasie $der_{T_n}$
\item ca³kê szeregu po czasie $int_{T_n}$
\item dyskretn± transformatê Fouriera $fourier_{T_n}$
\item dyskretn± transformatê falkow± Haara $wavelet_{T_n}$
\end{itemize}

\subsubsection{Pochodna szeregu po czasie}

Dyskretna pochodna szeregu $T_n = (t_1, x_1), (t_2, x_2), \dots, (t_n, x_n)$ po czasie wyliczana by³a w sposób nastêpuj±cy:

\begin{equation}
der_{T_n}(i) = \frac{x_i - x_{i - 1}}{t_i - t_{i - 1}}, \quad i \geq 1
\end{equation}

Takie przekszta³cenie pozwala na badanie lokalnej zmienno¶ci (monotoniczno¶ci i jej tempa) danego szeregu. Jako ¿e badane dane (opisywane szerzej w sekcji \ref{ss:data}) sk³ada³y siê z odczytów z sensorów (akcelerometrów i ¿yroskopów), pochodna po czasie mo¿e byæ równie¿ interpretowana w sensie fizycznym. Przyk³adowo, miara zmienno¶ci przyspieszenia w czasie zwana jest zrywem\footnote{https://pl.wikipedia.org/wiki/Zryw}.

\subsubsection{Ca³ka szeregu po czasie}

Analogicznie do pochodnej zdefiniowaæ mo¿na dyskretn± ca³kê z szeregu \\ $T_n = (t_1, x_1), (t_2, x_2), \dots, (t_n, x_n)$, wyliczan± metod± trapezów:

\begin{equation}
int_{T_n}(i) = \sum_{j= 1}^i \frac{(x_j + x_{j - 1})(t_i - t_{i - 1})}{2}, \quad i \geq 1
\end{equation}

Tak wyliczonej ca³ce tak¿e mo¿na przypisaæ interpretacjê fizyczn± - dla przyk³adu, warto¶æ $int_{T_n}(i)$ dla odczytu $T_n$ z akcelerometru umieszczonego na lewej rêce stra¿aka oznacza prêdko¶æ, z jak± porusza³a siê ta rêka w czasie $t_i$.  \\

\hfill \\
Pozosta³e dwa przekszta³cenia (transformata Fouriera oraz transformata falkowa) wyra¿aj± szereg czasowy w bazie pewnej przestrzeni funkcyjnej. \\

\subsubsection{Transformacja Fouriera}

Transformacja Fouriera jest jednym z najwa¿niejszych przekszta³ceñ u¿ywanych do analizy sygna³ów. Bazuje ona na odkryciu, ¿e ka¿dy szereg czasowy mo¿e byæ rozbity na sumê prostych, okresowych sygna³ów - sinusów i cosinusów o zmieniaj±cych siê amplitudzie i fazie (rys. \ref{fourier}).

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.54]{fourier.png}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption[Przyk³ad transformacji Fouriera]{Cosinusowe fale $s_1$, $s_2$, $s_3$ daj± po zsumowaniu bardziej z³o¿ony sygna³ \label{fourier}}
\end{figure}

Formalnie wspó³czynniki dyskretnej transformaty Fouriera zdefiniowane s± nastêpuj±co:

\begin{equation}
fourier_{T_n}(k) = \sum_{i = 0}^{n - 1} x_i \cdot (\cos(\frac{-2\pi k i}{n}) + i\sin(\frac{-2\pi k i}{n}))
\end{equation}

Wspó³czynniki $fourier_{T_n}(k)$ s± liczbami zespolonymi i reprezentuj± amplitudy oraz fazy sinusoidalnych sk³adowych sygna³u. Dla szeregów o warto¶ciach rzeczywistych, $fourier_{T_n}(i)$ jest zespolonym sprzê¿eniem $fourier_{T_n}(n - i + 1)$ (dla $i = 2, 3, \dots, \frac{n}{2}$). \\
Istnieje algorytm (zwany \textit{szybk± transformacj± Fouriera}, ang. \textit{fast Fourier transform}), obliczaj±cy wspó³czynniki transformaty Fouriera w czasie $\mathcal{O}(n\log n)$ (\cite{Morchen_2003_time}).

\subsubsection{Transformacja falkowa}

Przekszta³ceniem podobnym do transformaty Fouriera jest transformacja falkowa. Jej g³ówn± przewag± nad transformacj± opracowan± przez francuskiego matematyka jest zachowywanie informacji zarówno o czêstotliwo¶ci, jak i o czasie. Podczas gdy przekszta³cenie Fouriera rzutuje sygna³ z dziedziny czasu na dziedzinê czêstotliwo¶ci, transformata falkowa mierzy czêstotliwo¶æ w ró¿nych momentach czasu - sygna³ jest wiêc rzutowany na p³aszczyznê czasu i czêstotliwo¶ci. \\
\textit{Dyskretna transformacja falkowa} równie¿ polega na przedstawieniu sygna³u jako sumy sygna³ów podstawowych. Podczas gdy transformata Fouriera u¿ywa³a funkcji sinusoidalnych, tutaj funkcjê podstawow± nazywa siê \textit{falk±}. Funkcje falkowe s± postaci:

\begin{displaymath}
\Psi_{j,k}(t) = 2^{\frac{j}{2}}\Psi(2^jt - k),
\end{displaymath}
gdzie $\Psi$ jest \textit{macierzyst± funkcj± falkow±}. Wtedy ka¿da funkcja $f \in L^2(\mathbb{R})$ mo¿e byæ przedstawiona w tej bazie jako
\begin{displaymath}
f(t) = \sum_{j, k} c_{j,k}\Psi_{j,k}(t),
\end{displaymath}
a $c_{j,k} = \left\langle \Psi_{j,k}(t), f(t) \right\rangle$ s± wspó³czynnikami dyskretnej transformaty falkowej. \\
Najbardziej znan± macierzyst± funkcj± falkow± jest falka Haara, zdefiniowana nastêpuj±co:
\[
    \Psi_{Haar}(t) = 
    \begin{cases} 
      0 & t < 0 \\
      1 & 0 \leq t < 0,5 \\
      -1 & 0,5 \leq t < 1 \\
      0 & t \geq 1 
   \end{cases}
\]

Wykres falki Haara przedstawia rys. \ref{haar}. Funkcja wêgierskiego matematyka zosta³a u¿yta przez autora w procesie ekstrakcji cech.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.15]{haar.png}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Wykres falki Haara \label{haar}}
\end{figure}

Podobnie jak w przypadku dyskretnej transformaty Fouriera, tak i tu istnieje szybki algorytm obliczaj±cy wspó³czynniki dyskretnej transformaty falkowej (dzia³aj±cy w czasie $\mathcal{O}(n)$ - \cite{Mallat}). Czyni to obydwa przekszta³cenia niezwykle u¿ytecznymi w praktyce.
\newpage

\subsection{Statystyki wyliczane z reprezentacji szeregu} \label{ss:feaures}

Kolejnym krokiem w ekstrakcji cech by³o opisanie reprezentacji (przedstawionych w poprzedniej sekcji) za pomoc± zbioru statystyk, maj±cych jak najlepiej oddaæ charakter danego szeregu.
Poni¿ej znajduje siê lista statystyk (wraz z formalnym opisem) wykorzystanych przez autora. \\

\begin{itemize}
\item \textbf{Minimum}

Minimalna warto¶æ przyjmowana w szeregu czasowym:
\begin{equation}
min(T_n) = \min_{1 \leq i \leq n} x_i
\end{equation}

\item \textbf{Maksimum}

Maksymalna warto¶æ przyjmowana w szeregu czasowym:
\begin{equation}
max(T_n) = \max_{1 \leq i \leq n} x_i
\end{equation}

\item \textbf{¦rednia arytmetyczna}

¦rednia arytmetyczna warto¶ci przyjmowanych w szeregu czasowym:
\begin{equation}
mean(T_n) = \frac{\sum_{i = 1}^n x_i}{n}
\end{equation}

\item \textbf{Suma}

Suma warto¶ci przyjmowanych w szeregu czasowym:
\begin{equation}
sum(T_n) = \sum_{i = 1}^n x_i
\end{equation}

\item \textbf{Odchylenie standardowe}

Odchylenie warto¶ci przyjmowanych w szeregu czasowym:
\begin{equation}
std(T_n) = \sqrt{\frac{\sum_{i = 1}^n(x_i - mean(T_n))^2}{n}}
\end{equation}

\item \textbf{Kwantyle}

Kwantylem $q_p(T_n)$ rzêdu $p$ nazwiemy taki element $x_k$, ¿e dok³adnie $p$ elementów szeregu jest od niego mniejszych. W procesie ekstrakcji cech u¿yto siedmiu kwantyli, rzêdów kolejno: 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875. \\
Kwantyl rzêdu $0.5$ oznaczany bêdzie dalej przez $median(T_n)$.

\item \textbf{Wariancja}

Wariancja warto¶ci w szeregu czasowym:
\begin{equation}
var(T_n) = std^2(T_n)
\end{equation}

\item \textbf{B³±d standardowy}

B³±d standardowy okre¶la odchylenie standardowe dla rozk³adu ¶redniej z próby. Zdefiniowany jest jako:
\begin{equation}
sem(T_n) = \frac{std(T_n)}{\sqrt{n}}
\end{equation}

\item \textbf{Indeks pierwszego maksimum}

Indeks pierwszego maksimum szeregu (normalizowany przez d³ugo¶æ szeregu):
\begin{equation}
first\_argmax(T_n) = \frac{\min(\{i: x_i = max(T_n)\}}{n}
\end{equation}

\item \textbf{Indeks pierwszego minimum}

Indeks pierwszego minimum szeregu (normalizowany przez d³ugo¶æ szeregu):
\begin{equation}
first\_argmin(T_n) = \frac{\min(\{i: x_i = min(T_n)\}}{n}
\end{equation}

\item \textbf{Wspó³czynnik sko¶no¶ci}

Wspó³czynnik sko¶no¶ci rozk³adu to miara asymetrii rozk³adu. Przyjmuje on warto¶æ zero dla rozk³adu symetrycznego, warto¶ci ujemne dla rozk³adu o lewostronnej asymetrii (wyd³u¿one lewe ramiê rozk³adu) i warto¶ci dodatnie dla rozk³adów o prawostronnej asymetrii (wyd³u¿one prawe ramiê rozk³adu) (rys. \ref{skew}). \\
Traktuj±c warto¶ci szeregu jako warto¶ci pewnej próbki statystycznej, mo¿na wyznaczyæ jego wspó³czynnik sko¶no¶ci, zdefiniowany jako:
\begin{equation}
skew(T_n) = \frac{3(mean(T_n) - median(T_n))}{std(T_n)}
\end{equation}

\begin{figure}[ht!]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\includegraphics[scale=0.6]{skewness.png}
\caption[Rozk³ady o ujemnym i dodatnim wspó³czynniku sko¶no¶ci]{Rozk³ady o ujemnym (pierwszy wykres) i dodatnim (drugi wykres) wspó³czynniku sko¶no¶ci \label{skew}}
\end{figure}

\item \textbf{Kurtoza}

Kurtoza to miara koncentracji wyników wokó³ warto¶ci centralnej. Jest to druga, obok sko¶no¶ci, miara kszta³tu rozk³adu.\\
Kurtoza rozk³adu normalnego wynosi 0. Je¶li warto¶æ tej statystyki jest dodatnia, mamy do czyniena z rozk³adem leptokurtycznym (wysmuk³ym). Je¶li za¶ jest ujemna, rozk³ad jest rozk³adem platykurtycznym (sp³aszczonym) (rys. \ref{kurthosis})

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.5]{kurthosis.png}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Kszta³t rozk³adu w zale¿no¶ci od warto¶ci kurtozy \label{kurthosis}}
\end{figure}

Formalnie kurtozê definiuje siê nastêpuj±co:
\begin{equation}
kurt(T_n) = \frac{\frac{1}{n}\sum_{i=1}^n(x_i - mean(T_n))^4}{std^4(T_n)} - 3
\end{equation}

\item \textbf{¦rednia wa¿ona liniowo}

¦rednia wa¿ona warto¶ci w szeregu, przy czym wagi rosn± liniowo wraz z indeksem. W ten sposób nadaje siê najwiêksz± wagê obserwacjom wykonanym najpó¼niej (u¿ycie tej statystyki dla szeregów czasowych opisuj \cite{WiensGH12}):
\begin{equation}
linear\_weighted\_mean(T_n) = \frac{2}{n(n + 1)} \sum_{i=1}^n ix_i
\end{equation}

\item \textbf{¦rednia wa¿ona kwadratowo}

Jak wy¿ej - z t± ró¿nic±, ¿e wagi rosn± kwadratowo wraz z indeksem:
\begin{equation}
quadratic\_weighted\_mean(T_n) = \frac{6}{n(n + 1)(2n + 1)} \sum_{i=1}^n i^2x_i
\end{equation}

\item \textbf{¦rednie odchylenie bezwzglêdne od ¶redniej}

¦rednie odchylenie bezwzglêdne to kolejna, obok odchylenia standardowego i wariancji, miara rozrzutu próbki. Definuje siê je nastêpuj±co:
\begin{equation}
mean\_absolute\_deviation(T_n) = \frac{\sum_{i=1}^n |x_i - mean(T_n)|}{n}
\end{equation}

\item \textbf{Mediana bezwzglêdnego odchylenia}

Jeszcze inn± miar± rozrzutu jest mediana bezwzglêdnego odchylenia (ang. \textit{median absolute deviation}, MAD). Jest to mediana ci±gu bezwzglêdnych odchyleñ od mediany:
\begin{equation}
median\_absolute\_deviation(T_n) = median_{1 \leq i \leq n}(|x_i - median(T_n)|)
\end{equation}

\item \textbf{Ca³kowita energia}

Ca³kowit± energiê szeregu definiuje siê jako sumê kwadratów jego warto¶ci:
\begin{equation}
E(T_n) = \sum_{i=1}^n x_i^2
\end{equation}

\item \textbf{Liczba elementów mniejszych od ¶redniej}

Zdefiniowana w oczywisty sposób:
\begin{equation}
count\_below\_mean(T_n) = |\{i: x_i < mean(T_n)\}|
\end{equation}

\item \textbf{Liczba elementów wiêkszych od ¶redniej}

Analogicznie do powy¿szego:
\begin{equation}
count\_above\_mean(T_n) = |\{i: x_i > mean(T_n)\}|
\end{equation}

\item \textbf{D³ugo¶æ najd³u¿szego podci±gu o warto¶ciach poni¿ej ¶redniej}

Zdefiniowana formalnie:
\begin{equation}
strike\_below\_mean(T_n) = \max(\{j - i\; | \; 1 \leq i \leq j \leq n, \forall_{i < k \leq j} \; x_k < mean(T_n)\})
\end{equation}

\item \textbf{D³ugo¶æ najd³u¿szego podci±gu o warto¶ciach powy¿ej ¶redniej}

Analogicznie do powy¿szego:
\begin{equation}
strike\_above\_mean(T_n) = \max(\{j - i \; | \; 1 \leq i \leq j \leq n, \forall_{i < k \leq j} \; x_k > mean(T_n)\})
\end{equation}

\item \textbf{¦rednia autokorelacja}

\begin{defi}\label{d:pearson}
\emph{Wspó³czynnik korelacji Pearsona} wektorów prób losowych $\textbf{x}, \textbf{y} \in \mathbb{R}^n$ zdefiniowany jest jako
  $$pearson\_corr(\textbf{x}, \textbf{y}) = \frac{\sum_{i=1}^n(x_i - \mean{x})(y_i - \mean{y})}{\sqrt{\sum_{i=1}^n (x_i - \mean{x})^2}\sqrt{\sum_{i=1}^n (y_i - \mean{y})^2}},$$ gdzie $\mean{x}$, $\mean{y}$ oznaczaj± warto¶ci ¶rednie z tych prób, tj. $\mean{x} = \frac{\sum_{i=1}^n x_i}{n}$, $\mean{y} = \frac{\sum_{i=1}^n y_i}{n}$.
\end{defi}
Wspó³czynnik Pearsona okre¶la poziom zale¿no¶ci liniowej miêdzy zmiennymi losowymi i przyjmuje warto¶ci z przedzia³u $[-1,1]$. Warto¶ci bliskie $1$ oznaczaj± siln± zale¿no¶æ liniow± miêdzy próbkami, warto¶ci bliskie zera - brak liniowej zale¿no¶ci, natomiast warto¶ci bliskie $-1$ - ujemn± liniow± zale¿no¶æ (rys. \ref{pearson}). \\

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.35]{pearson.png}
\captionsetup{justification=centering}
\captionsetup{width=0.7\textwidth}
\caption[Przyk³adowe wykresy danych i odpowiadaj±ce im warto¶ci wspó³czynnika korelacji liniowej Pearsona]{Przyk³adowe wykresy danych $(x, y)$ i odpowiadaj±ce im warto¶ci wspó³czynnika korelacji liniowej Pearsona \label{pearson}}
\end{figure}


Korelacja Pearsona wykorzystywana jest przy wyliczaniu autokorelacji. Autokorelacja jest funkcj±, która argumentowi naturalnemu $k$ przypisuje warto¶æ wspó³czynnika korelacji pomiêdzy szeregiem czasowym a tym samym szeregiem cofniêtym o $k$ jednostek czasu:
\begin{displaymath}
autocorr_k(T_n) = \frac{1}{(n - k)std^2(T_n)} \sum_{i = 1}^{n - k} (x_i - mean(T_n))(x_{i + k} - mean(T_n))
\end{displaymath}

Jako cecha u¿ywana by³a ¶rednia warto¶æ autokorelacji obliczanych dla wszystkich  przesuniêæ $k$ (od 1 do $n$):
\begin{equation}
mean\_autocorr(T_n) = \frac{\sum_{k=1}^n autocorr_k(T_n)}{n}
\end{equation}

\item \textbf{Asymetryczno¶æ odwracalna w czasie}

Ta statystyka (ang. \textit{time-reversal asymmetry statistic}) zosta³a zaproponowana przez Fulchera i Jonesa w \cite{FulcherJ14}. Zdefiniowana jest w zale¿no¶ci od parametru $k$ przez:
\begin{equation}
TRAS_{k}(T_n) = \frac{1}{n - 2k} \sum_{i = 0}^{n - 2k} x_{i + 2k}^2 \cdot x_{i + k} - x_{i + k} \cdot x_i^2
\end{equation}
Jako cechy wykorzystane zosta³y warto¶ci $TRAS$ dla $k = 25, 50, 100, 200$.

\item \textbf{Informacje o skokach}

\begin{defi}\label{d:peak}
\emph{Skokiem o wsparciu $n$} nazwiemy podci±g szeregu $T_n$, w którym istnieje warto¶æ $x$ bêd±ca wiêksza ni¿ $n$ warto¶ci wystêpuj±cych bezpo¶rednio przed ni± oraz $n$ warto¶ci wystêpuj±cych bezpo¶rednio po niej.
\end{defi}

Przyk³adowo w ci±gu $(3, 0, 0, 4, 0, 0, 13)$ warto¶æ $4$ jest skokiem o wsparciu $1$ i $2$, ale nie jest skokiem o wsparciu $3$. \\
Skoki wykorzystano przy ekstrakcji piêciu kolejnych cech, które oznacza³y (kolejno) liczbê skoków o wsparciu: 5, 10, 25, 50, 100.
\end{itemize}

\hfill \\
Funkcje $min$, $max$, $mean$, $sum$, $std$, $quantiles$ nazywane bêd± \textit{statystykami podstawowymi}. Z reprezentacji pochodnych (pochodnej, ca³ki, transformaty Fouriera, transformaty falkowej) wyliczane by³y tylko statystyki podstawowe. Warto¶ci wszystkich opisanych wy¿ej statystyk obliczono tylko dla bazowej reprezentacji szeregu. \\
W ten sposób z $42$ szeregów obecnych w zbiorze danych otrzymano oko³o 4500 cech.

\subsection{Pozosta³e cechy} \label{ss:additional}

M\"{o}rchen udowadnia w \cite{Morchen_2003_time}, ¿e u¿yteczne przy klasyfikacji szeregów czasowych jest $k$ najwiêkszych wspó³czynników transformaty Fouriera oraz transformaty falkowej. Autor zdecydowa³ siê wiêc dodaæ po 10 najwiêkszych wspó³czynników dla obydwu transformat wyliczonych dla ka¿dego z szeregów. \\
Kolejne cechy oparte by³y na korelacji miêdzy dwoma szeregami czasowymi. Analogicznie do autokorelacji, korelacjê miêdzy szeregami  $T_n = (t_1, x_1), \dots, (t_n, x_n)$  i  
$T'_n = (t_1, x'_1), \dots, (t_n, x'_n)$ definuje siê jako korelacjê Pearsona (def \ref{d:pearson}) miêdzy wektorami $(x_1, \dots x_n)$ oraz $(x_1', \dots, x_n')$. \\

Ostatecznie otrzymano oko³o 6000 cech (przypomnijmy - pocz±tkowa reprezentacja zbioru danych zawiera³a 17242 atrybuty). \\

Warto zwróæiæ uwagê, jak elastyczna jest powy¿sza metoda ekstrakcji cech - mo¿na zastosowaæ j± do praktycznie dowolnego szeregu. Inn± zalet± tej metody jest jej nied³ugi czas dzia³ania. Przyk³adowo, przekszta³cenie zbioru treningowego (sk³adaj±cego siê z 20000 instancji) zajê³o oko³o dwóch godzin na komputerze wyposa¿onym w dwurdzeniowy procesor Intel Core i5 o taktowaniu 2,7 GHz.


\chapter{Redukcja \textit{concept drift} poprzez selekcjê cech}\label{r:drift_reduction}

\section{Sprowadzenie problemu adaptacji dziedziny do problemu klasyfikacji}

Zacznijmy od sprawdzenia jako¶ci klasyfikatorów przedstawionych w rozdziale \ref{r:experiment} na reprezentacji opisanej w poprzednim rozdziale przy u¿yciu metryki $BAC$. Wynik na zbiorze treningowym wyliczany by³ za pomoc± trójwarstwowej walidacji krzy¿owej. Rezultaty przedstawia tabela \ref{t:res1}.

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji na wyekstrahowanych cechach}
\label{t:res1}
\begin{tabular}{|c|c|c|}
\hline
  & Wynik na $X_{train}$ & Wynik na $X_{test}$ \\ \hline
Regresja logistyczna & 0.95 & 0.53 \\ \hline
SVM  & 0.96 & 0.53 \\ \hline
Lasy losowe & 0.99 & 0.71 \\ \hline
\end{tabular}
\end{table}

\hfill \\
Okazuje siê, ¿e problem ewoluuj±cych pojêæ by³ g³ówn± przeszkod± przy budowie wydajnego modelu dla zadanego problemu. Mówi±c bardziej szczegó³owo, wystêpowa³y wyra¼ne ró¿nice w wykonywaniu poszczególnych czynno¶ci miêdzy stra¿akami. Widaæ to po rezultatach prezentowanych w tabeli \ref{t:res1}. Mimo rewelacyjnych wyników na zborze treningowym (klasyfikator bazuj±cy na lasach losowych  by³ niemal¿e bezb³êdny), jako¶æ predyktorów testowanych na innej grupie stra¿aków okaza³a siê du¿o ni¿sza - wynik pogorszy³ siê o ok. $0.3$ w przypadku lasów losowych oraz o prawie $0.5$ dla klasyfikatorów liniowych. \\

Celem tego rozdzia³u bêdzie przedstawienie metody wyboru takiej poprzestrzeni cech, która bêdzie spe³niaæ dwa wymogi:
\begin{itemize}
\item bêdzie umo¿liwiaæ zbudowanie wydajnego klasyfikatora,
\item bêdzie mozliwie odpodrna na zmiany dziedziny
\end{itemize}

Opisywane podej¶cie stanowi rozszerzenie pomys³u zaproponowanego przez Boull{\'{e}} w \\ \cite{Boulle15} oraz \cite{BonduB11}. Intuicja jest nastêpuj±ca: za³ó¿my, ¿e jeste¶my w stanie sprowadziæ problem wykrywania \textit{concept drift} do problemu klasyfikacji (zostanie to opisane szerzej w kolejnych podrozdzia³ach). Za³ó¿my te¿, ¿e mamy dan± funkcjê $f$, która dla danego atrybutu okre¶la jego jako¶æ w odniesieniu do ustalonego problemu klasyfikacji. Przyk³adem takiej funkcji jest test $\chi^2$. \\

Celem jest wybranie tych cech, które jednocze¶nie:
\begin{itemize}
\item daj± najwy¿szy wynik dla oryginalnego problemu klasyfikacji,
\item daj± najni¿szy wynik dla problemu klasyfikacji, do którego sprowadzone zosta³o zadanie wykrywania ewoluuj±cych pojêæ.
\end{itemize}

Przy takim wyborze w oczywisty sposób zostan± spe³nione postawione wcze¶niej wymagania. Intuicyjnie, je¶li bêdziemy wstanie wybraæ reprezentacjê, która daje dobr± jako¶æ klasyfikacji, ale s³abo wykrywa zmianê dziedziny, to nasz klasyfikator bêdzie mniej czu³y na ewolucjê pojêæ, co skutkowaæ bêdzie zmniejszeniem ró¿nicy jako¶ci miêdzy zbiorami treningowym a testowym. \\
Rysunek \ref{drift_example} przedstawia rozk³ad jako¶ci cech wraz z przyk³adowym wyborem intuicyjnie "dobrej" reprezentacji.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.7]{drift_example.png}
\captionsetup{justification=centering}
\captionsetup{width=0.7\textwidth}
\caption{Przyk³adowy rozk³ad jako¶ci cech dla problemu klasyfikacji oraz zadania wykrywania ewoluuj±cych pojêæ \label{drift_example}}
\end{figure}

O¶ $x$ przedstawia jako¶æ cech dla bazowego problemu klasyfikacji, natomiast o¶ $y$ - jako¶æ dla problemu detekcji \textit{concept drift}. Przyk³adowym wyborem jest selekcja cech poni¿ej czerwonej linii (atrybuty s³abo rozró¿niaj±ce ró¿ne dziedziny) oraz na prawo od linii zielonej (cechy o wysokim wyniku dla postawionego problemu klasyfikacji). Oczywi¶cie nie zawsze taki wybór bêdzie mo¿liwy, co poka¿± kolejne podrozdzia³y. \\
G³ównym wyzwaniem w opisywanym podej¶ciu jest sprowadzenie problemu wykrywania zmiennej dziedziny do problemu klasyfikacji. Zanim jednak poruszona zostanie ta kwestia, autor zaprezentuje u¿ywane najczê¶ciej miary jako¶ci cech.

\section{Miary jako¶ci cech}

Podstawowe miary jako¶ci atrybutów pochodz± ze statystki oraz teorii informacji. Do najbardziej znanych nale¿±:

\begin{itemize}
\item wspó³czynnik korelacji Pearsona
\item test $\chi^2$
\item informacja wzajemna
\item jednoczynnikowa analiza wariancji
\item zysk Giniego
\end{itemize}

W bie¿±cej sekcji zostanie przedstawiony opis ka¿dej z tych miar.

\subsubsection{Wspó³czynnik korelacji Pearsona}

Zdefiniowany w \ref{d:pearson} wspó³czynnik korelacji liniowej Pearsona mo¿e byæ te¿ u¿ywany do mierzenia jako¶ci atrybutu. Niech przewidywana zmienna $y$ bêdzie ci±g³a. Dla danego ci±g³ego atrybutu $x$ warto¶æ $pearson\_corr(x, y)$ okre¶la poziom liniowej zale¿no¶ci miêdzy tym atrybutem a $y$. Badanie korelacji jest czêsto wykorzystywane przy analizie mikromacierzowej DNA (\cite{GuyonE03}).

\subsubsection{Test $\chi^2$}

W statystyce testu $\chi^2$ u¿ywa siê do badania niezale¿no¶ci dwóch zdarzeñ $A$ i $B$, gdzie dwa zdarzenia s± uznawane za niezale¿ne, je¶li $P(A \cap B) = P(A)P(B)$, b±d¼ równowa¿nie: $P(A | B) = P(A)$ i analogicznie $P(B | A) = P(B)$. W uczeniu maszynowym test $\chi^2$ stosowany jest do badania niezale¿no¶ci pomiêdzy atrybutami a klas± wynikow±. Za warto¶ciowe uwa¿ane s± te cechy, które nie s± niezale¿nie od przewidywanej zmiennej. \\
Test ten mo¿e byæ zastosowany tylko w przypadku gdy zarówno atrybut, jak i klasa wynikowa s± zmiennymi kategorycznymi. W przypadku zmiennych ci±g³ych stosuje siê dyskretyzacjê.

\subsubsection{Informacja wzajemna}

Z punktu widzenia teorii informacji klasyfikator mo¿e byæ traktowany jako narzêdzie redukuj±ce poziom \textit{niepewno¶ci} odno¶nie przewidywanej zmiennej. Klasyfikator, "konsumuj±c" informacjê niesion± przez kolejne instancje zbioru treningowego, stopniowo zmniejsza pocz±tkow± niepewno¶æ zmiennej wynikowej. W przypadku klasyfikatora idealnego (to jest takiego, który zawsze dobrze przewiduje klasê wynikow±) koñcowa niepewno¶æ bêdzie wynosi³a 0. \\
W teorii informacji pocz±tkow± niepewno¶æ definiuje siê formalnie przez pojêcie \textit{entropii}.
\begin{defi}\label{entropy}
Je¶li przewidywana zmienna $C$ jest zmienn± dyskretn± przyjmuj±c± $m$ warto¶ci $c_1, c_2, \dots, c_m$, \emph{entropia} definiowana jest jako
$$H(C) = -\sum_{i=1}^m P_C(c_i) \log P_C(c_i)$$
\end{defi}
Niech teraz atrybut $F$ bêdzie atrybutem dyskretnym przyjmuj±cym $k$ warto¶ci $f_1, f_2, \dots, f_k$. Wtedy niepewno¶æ po poznaniu warto¶ci cechy $F$ nazywa siê \textit{entropi± warunkow±}:
\begin{displaymath}
H(C | F) = \sum_{i=1}^k P_F(f_i) H(C|F=f_i) = 
\end{displaymath}
\begin{displaymath}
= -\sum_{i=1}^k P_F(f_i) (\sum_{j=1}^m P_{C|F}(c_j | f_i) \log P_{C|F}(c_j | f_i) )
\end{displaymath}
Zachodzi wtedy:
\begin{displaymath}
H(C | F) \leq H(C),
\end{displaymath}
czyli entropia warunkowa jest nie wiêksza ni¿ entropia pocz±tkowa. Równo¶æ zachodzi wtedy i tylko wtedy, gdy zmienne $C$ i $F$ s± niezale¿ne. \\
\textit{Informacjê wzajemn±} $I(C; F)$ definiuje siê wtedy jako warto¶æ, o jak± pocz±tkowa niepewno¶æ odno¶nie klasy wynikowej zosta³a pomniejszona po poznaniu warto¶ci cechy $F$, czyli formalnie:
\begin{equation}
I(C; F) = H(C) - H(C | F)
\end{equation}
Po nietrudnych przekszta³ceniach mo¿na otrzymaæ zwarty wzór na informacjê wzajemn±:
\begin{equation}
I(C; F) = \sum_{i=1}^k \sum_{j=1}^m P_{CF}(c_j, f_i) \log(\frac{P_{CF}(c_j, f_i)}{P_C(c_j)P_F(f_i)})
\end{equation}

\subsubsection{Jednoczynnikowa analiza wariancji}

Jednoczynnikowa analiza wariancji u¿ywa testu statystycznego $F$ do mierzenia jako¶ci cechy. Test $F$ okre¶la, czy warto¶ci oczekiwane danej cechy $X$ wewn±trz $m$ okre¶lonych grup (odpowiadaj±cych $m$ warto¶ciom klasy wynikowej) ró¿ni± siê miêdzy sob±. Warto¶æ $F$-testu zdefiniowana jest jako:
\begin{displaymath}
F = \frac{MS_M}{MS_W}
\end{displaymath}
$MS_M$ okre¶la wariancjê miêdzy grupami i jest zdefiniowana jako:
\begin{displaymath}
MS_M = \frac{\sum_{i=1}^m n_i(\mean{x_i} - \mean{x})^2}{m - 1},
\end{displaymath}
gdzie $n_i$ oznacza liczbê obserwacji w $i$-tej grupie, $\mean{x_i}$ oznacza ¶redni± w $i$ - tej grupie, a $\mean{x}$ - ¶redni± z ca³ej próbki. $MS_W$ okre¶la z kolei wariancjê wewn±trz grup, zdefiniowan± jako:
\begin{displaymath}
MS_W = \frac{\sum_{ij} (x_{ij} - \mean{x_i})^2}{n - m},
\end{displaymath}
gdzie $x_{ij}$ oznacza$j$-t± obserwacjê $i$-tej grupy.

\subsubsection{Zysk Giniego}

Niech ponownie zmienna przewidywana $C$ bêdzie zmienn± dyskretn± przyjmuj±c± $m$ warto¶ci $c_1, c_2, \dots, c_m$.
\begin{defi}\label{gini_index}
\emph{Indeksem Giniego} zmiennej C nazywa siê warto¶æ
$$Gini(C) = 1 - \sum_{i=1}^m P_C^2(c_i)$$
\end{defi}
Podobnie jak entropia, indeks Giniego jest miar± \textit{niejednorodno¶ci} zbioru. Przyk³adowo, dla jednej klasy indeks Giniego (niejednorodno¶æ zbioru) wynosi $1 - 1^2 = 0$. Je¶li rozk³ad klas jest jednostajny (czyli $P_C(c_i) = \frac{1}{m}$, indeks Giniego osi±ga maksimum. \\
Ze wzglêdu na podobieñstwo miêdzy indeksem Giniego a entropi±, \textit{zysk Giniego} definiuje siê analogicznie do informacji wzajemnej. Dla atrybutu dyskretnego $F$ przyjmuj±cego warto¶ci $f_1, f_2, \dots, f_k$ zysk Giniego wyra¿a, o ile zmala³a niejednorodno¶æ zbioru (jego indeks Giniego) po pozaniu warto¶ci cechy $F$:
\begin{equation}
GiniGain(C; F) = Gini(C) - Gini(C | F) = Gini(C) - \sum_{i=1}^k P_F(f_i) Gini(C | F = f_i)
\end{equation}

\hfill \\  
W dalszych eksperymentach autor wykorzysta³ trzy miary jako¶ci cech: informacjê wzajemn±, jednoczynnikow± analizê wariancji oraz zysk Giniego.

\section{Wykrywanie ewolucji pojêæ miêdzy zbiorem treningowym a testowym} \label{s:tt}

Wróæmy do problemu wykrywania ewolucji pojêæ. Przypomnijmy, ¿e celem jest przypisanie instancjom takich klas, aby obiekty pochodz±ce z tej samej dziedziny otrzyma³y tê sam± klasê. Przy tak stworzonej klasie wynikowej mierzona bêdzie jako¶æ poszczególnych atrybutów i wybierane bêd± te cechy, które uzyskaj± najgorszy wynik, czyli takie, które najgorzej rozró¿niaj± dziedziny. \\
W celu wykrycia \textit{concept drift} miêdzy zbiorem treningowym a zbiorem testowym wykorzystany zosta³ pomys³ opisywany w \cite{Boulle15}. Zbiory $X_{train}$ i $X_{test}$ zosta³y po³±czone w jeden: $X = X_{train} \cup X_{test}$. Klasa wynikowa by³a dwuelementowa i przyjmowa³a warto¶æ "train" dla obiektów ze zbioru treningowego oraz "test" dla zbioru testowego. Nastêpnie wybierane by³y te cechy, które s³abo rozró¿nia³y obiekty ze zbioru treningowego od obiektów ze zbioru testowego i jednocze¶nie dobrze przewidywa³y czynno¶ci wykonywane przez stra¿aków. \\
Opisana metoda, jakkolwiek obiecuj±ca ze wzglêdu na swoj± prostotê (zarówno ideologiczn±, jak i implementacyjn±), nie ma jednak zastosowania w przypadku uczenia indukcyjnego (por. tabela \ref{t:paradigms}). W istocie, za³o¿enie posiadania zbioru testowego w momencie uczenia znacznie ogranicza mo¿liwo¶ci wykorzystania przedstawionego podej¶cia w praktyce. Jak bowiem wspomniano wcze¶niej, podroblem uczenia indukcyjnego z przeniesieniem wiedzy wystêpuje czê¶ciej ni¿ podproblem uczenia transdukcyjnego.

\subsection{Wyniki eksperymentów}

Poni¿ej zaprezentowane zostan± rezultaty selekcji cech przy u¿yciu trzech miar jako¶ci wspomnianych w poprzedniej sekcji - informacji wzajemnej, jednoczynnikowej analizy wariancji i zysku Giniego. W opisie ka¿dego z eksperymentów $threshold_{drift}$ bêdzie oznacza³ górny próg warto¶ci miary przy zadaniu detekcji \textit{concept drift}, natomiast $threshold_{class}$ - dolny próg jako¶ci cechy przy klasyfikacji czynno¶ci wykonywanej przez stra¿aka (analogicznie do rysunku \ref{drift_example}).

\subsubsection*{Informacja wzajemna}

Rysunek \ref{tt_mutual_info} przedstawia rozk³ad jako¶ci cech przy u¿yciu informacji wzajemnej jako miary. 
Widoczna jest wysoka dodatnia korelacja miêdzy jako¶ci± cechy dla klasyfikacji a jej jako¶ci± dla problemu ewolucji pojêæ. Utrudnia to w oczywisty sposób dobranie dobrych warto¶ci dla progów $threshold_{drift}$ oraz $threshold_{class}$ - eliminuj±c atrybuty "s³abe" dla detekcji \textit{concept drift}, eliminujemy jednocze¶nie cechy "dobre" dla klasyfikacji czynno¶ci stra¿aka. Znajduje to swoje odzwierciedlenie w jako¶ci otrzymanych klasyfikatorów. Tabele \ref{t:tt_mutual_info_logit}, \ref{t:tt_mutual_info_lsvm}, \ref{t:tt_mutual_info_random} prezentuj± jako¶æ klasyfikacji dla ró¿nych warto¶ci $threshold_{class}$ i $threshold_{drift}$ odpowiednio dla klasyfikatorów: regresji logistycznej, SVM i lasów losowych. Pierwszy wiersz ka¿dej tabeli zawiera wyniki bez selekcji atrybutów.

\begin{figure}[!htbp]
\centering
\includegraphics[scale=0.5]{train_test_mutual_info.png}
\captionsetup{justification=centering}
\captionsetup{width=0.7\textwidth}
\caption{Rozk³ad jako¶ci cech przy u¿yciu informacji wzajemnej \label{tt_mutual_info}}
\end{figure}

\begin{table}[!htbp]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji dla ró¿nych warto¶ci progowych przy u¿yciu informacji wzajemnej i regresji logistycznej}
\label{t:tt_mutual_info_logit}
\begin{tabular}{|c|c|c|c|c|}
\hline
$threshold_{class}$ & $threshold_{drift}$ & Liczba cech & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
0.0                 & 0.7                 & 6027        & 0.9341            & 0.5227           \\ \hline
0.0                 & 0.05                & 2867        & 0.9116            & 0.516            \\ \hline
0.0                 & 0.1                 & 3559        & 0.9201            & 0.509            \\ \hline
0.0                 & 0.2                 & 4362        & 0.9209            & 0.5492           \\ \hline
\textbf{0.25}                & \textbf{0.05}                & \textbf{950}         & \textbf{0.8494}            & \textbf{0.5468}           \\ \hline
0.25                & 0.1                 & 1448        & 0.915             & 0.4899           \\ \hline
0.25                & 0.2                 & 2246        & 0.9471            & 0.5313           \\ \hline
0.5                 & 0.05                & 266         & 0.7615            & 0.5008           \\ \hline
0.5                 & 0.1                 & 597         & 0.9292            & 0.5499           \\ \hline
0.5                 & 0.2                 & 1379        & 0.9662            & 0.5453           \\ \hline
0.5                 & 0.4                 & 2044        & 0.944             & 0.5225           \\ \hline
1.0                 & 0.1                 & 15          & 0.1636            & 0.1358           \\ \hline
1.0                 & 0.3                 & 443         & 0.7416            & 0.4221           \\ \hline
1.0                 & 0.5                 & 920         & 0.7788            & 0.4255           \\ \hline
1.5                 & 0.7                 & 486         & 0.6942            & 0.4673           \\ \hline
\end{tabular}
\end{table}

\newpage

\begin{table}[!htbp]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji dla ró¿nych warto¶ci progowych przy u¿yciu informacji wzajemnej i SVM}
\label{t:tt_mutual_info_lsvm}
\begin{tabular}{|c|c|c|c|c|}
\hline
$threshold_{class}$ & $threshold_{drift}$ & Liczba cech & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
0.0                 & 0.7                 & 6027        & 0.9501            & 0.53             \\ \hline
0.0                 & 0.05                & 2867        & 0.9062            & 0.5668           \\ \hline
0.0                 & 0.1                 & 3559        & 0.9256            & 0.5374           \\ \hline
0.0                 & 0.2                 & 4362        & 0.9267            & 0.5379           \\ \hline
\textbf{0.25}                & \textbf{0.05}                & \textbf{950}         & \textbf{0.8594}            & \textbf{0.5756}           \\ \hline
0.25                & 0.1                 & 1448        & 0.8985            & 0.5295           \\ \hline
0.25                & 0.2                 & 2246        & 0.9342            & 0.5507           \\ \hline
0.5                 & 0.05                & 266         & 0.7179            & 0.3884           \\ \hline
0.5                 & 0.1                 & 597         & 0.9039            & 0.524            \\ \hline
0.5                 & 0.2                 & 1379        & 0.9114            & 0.5153           \\ \hline
0.5                 & 0.4                 & 2044        & 0.9213            & 0.5266           \\ \hline
1.0                 & 0.1                 & 15          & 0.1719            & 0.1192           \\ \hline
1.0                 & 0.3                 & 443         & 0.7094            & 0.4488           \\ \hline
1.0                 & 0.5                 & 920         & 0.6926            & 0.4644           \\ \hline
1.5                 & 0.7                 & 486         & 0.696             & 0.2582          \\ \hline
\end{tabular}
\end{table}

\begin{table}[!htbp]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji dla ró¿nych warto¶ci progowych przy u¿yciu informacji wzajemnej i lasów losowych}
\label{t:tt_mutual_info_random}
\begin{tabular}{|c|c|c|c|c|}
\hline
$threshold_{class}$ & $threshold_{drift}$ & Liczba cech & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
0.0                 & 0.7                 & 6027        & 0.9952            & 0.7118           \\ \hline
0.0                 & 0.05                & 2867        & 0.9862            & 0.6932           \\ \hline
0.0                 & 0.1                 & 3559        & 0.992             & 0.7194           \\ \hline
0.0                 & 0.2                 & 4362        & 0.9933            & 0.7055           \\ \hline
0.25                & 0.05                & 950         & 0.9892            & 0.7044           \\ \hline
0.25                & 0.1                 & 1448        & 0.9923            & 0.7167           \\ \hline
\textbf{0.25}                & \textbf{0.2}                 & \textbf{2246}        & \textbf{0.9927}            & \textbf{0.7249}           \\ \hline
0.5                 & 0.05                & 266         & 0.9868            & 0.6625           \\ \hline
0.5                 & 0.1                 & 597         & 0.9924            & 0.7172           \\ \hline
0.5                 & 0.2                 & 1379        & 0.9935            & 0.6886           \\ \hline
0.5                 & 0.4                 & 2044        & 0.9954            & 0.7089           \\ \hline
1.0                 & 0.1                 & 15          & 0.8553            & 0.2661           \\ \hline
1.0                 & 0.3                 & 443         & 0.9935            & 0.6888           \\ \hline
1.0                 & 0.5                 & 920         & 0.9951            & 0.7064           \\ \hline
1.5                 & 0.7                 & 486         & 0.9914            & 0.6438           \\ \hline
\end{tabular}
\end{table}

Zastosowanie opisanej selekcji cech pomog³o poprawiæ wynik o oko³o $0.045$ w najlepszym przypadku. Oczekiwane rezultaty zaobserwowaæ mo¿na przyk³adowo dla warto¶ci \\ $threshold_{class} = 0.25$ i $threshold_{drift} = 0.05$ przy u¿yciu obydwu klasyfikatorów liniowych - po wybraniu 950 cech, wynik na zbiorze treningowym obni¿y³ siê, podczas gdy wynik na zbiorze testowym wzrós³. Wybrana reprezentacja, mimo ¿e teoretycznie gorsza je¶li chodzi o klasyfikacjê czynno¶ci stra¿aków, okaza³a siê bardziej odporna na zmianê dziedziny.

\subsubsection{Jednoczynnikowa analiza wariancji}

Rozk³ad jako¶ci atrybutów mierzony przy u¿yciu jednoczynnikowej analizy wariancji (wykres \ref{tt_anova}) prezentuje siê du¿o korzystniej ni¿ w poprzednim przypadku. Cechy skupione s± przy osiach $x$ i $y$, zatem wybiór zmiennych odpornych na zmianê dziedziny nie powinnien powodowaæ spadku jako¶ci klasyfikatora.

\begin{figure}[!htbp]
\centering
\includegraphics[scale=0.7]{train_test_anova_f.png}
\captionsetup{justification=centering}
\captionsetup{width=0.7\textwidth}
\caption{Rozk³ad jako¶ci cech przy u¿yciu jednoczynnikowej analizy wariancji \label{tt_anova}}
\end{figure}

Znajduje to swoje odwzierciedlenie w otrzymanych rezultatach. Najwiêkszy zysk wydajno¶ci zaobserwowano dla klasyfikatorów liniowych. Wynik na zbiorze testowym dla regresji logistycznej i SVM przy odpowiednich warto¶ci progów poprawi³ siê nawet o $0.15$ (tabele \ref{t:tt_anova_logit} i \ref{t:tt_anova_svm}), przy jednoczesnym niewielkim spadku $BAC$ na zbiorze treningowym. Dla lasów losowych poprawa miary jako¶ci wynios³a oko³o $0.05$ w najlepszym przypadku (tabela \ref{t:tt_anova_random}). Nale¿y przy tym zauwa¿yæ, ¿e polepszenie jako¶ci klasyfikatora nast±pi³a wraz z redukcj± przestrzeni cech - najlepsze wyniki uzyskano dla ok. $1500$ atrybutów. Niesie to ze sob± kolejn± zaletê, jak± jest obni¿enie czasu budowy modelu. \\
Warto te¿ zwróciæ uwagê na wyniki klasyfikatorów dla ustalonej warto¶ci $threshold_{class}$. Praktycznie w ka¿dym przypadku obni¿anie $threshold_{drift}$ przy ustalonym $threshold_{class}$ (a co za tym idzie - eliminowanie wiêkszej liczby cech wra¿liwych na zmianê dziedziny) skutkuje wzrostem jako¶ci modelu.

\newpage

\begin{table}[!htbp]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji dla ró¿nych warto¶ci progowych przy u¿yciu analizy wariancji i regresji logistycznej}
\label{t:tt_anova_logit}
\begin{tabular}{|c|c|c|c|c|}
\hline
$threshold_{class}$ & $threshold_{drift}$ & Liczba cech   & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
0.0                 & 8000                & 6027          & 0.9497            & 0.5348           \\ \hline
0.0                 & 250                 & 3813          & 0.9067            & 0.5853           \\ \hline
0.0                 & 500                 & 4434          & 0.9295            & 0.5940           \\ \hline
0.0                 & 750                 & 4694          & 0.9387            & 0.5931           \\ \hline
0.0                 & 1000                & 4871          & 0.9445            & 0.5838           \\ \hline
\textbf{250}        & \textbf{250}        & \textbf{1890} & \textbf{0.9188}   & \textbf{0.6711}  \\ \hline
250                 & 500                 & 2278          & 0.9426            & 0.6333           \\ \hline
250                 & 750                 & 2446          & 0.9538            & 0.6102           \\ \hline
250                 & 1000                & 2560          & 0.9559            & 0.6289           \\ \hline
\textbf{500}        & \textbf{250}        & \textbf{1309} & \textbf{0.8926}   & \textbf{0.6680}  \\ \hline
500                 & 500                 & 1566          & 0.9124            & 0.6050           \\ \hline
500                 & 750                 & 1656          & 0.9171            & 0.5898           \\ \hline
500                 & 1000                & 1714          & 0.9310            & 0.6169           \\ \hline
500                 & 2000                & 1805          & 0.9214            & 0.5495           \\ \hline
1000                & 500                 & 873           & 0.7031            & 0.5725           \\ \hline
1000                & 1000                & 927           & 0.7118            & 0.5436           \\ \hline
1000                & 2000                & 946           & 0.8019            & 0.4943           \\ \hline
\end{tabular}
\end{table}

\begin{table}[!htbp]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji dla ró¿nych warto¶ci progowych przy u¿yciu analizy wariancji i SVM}
\label{t:tt_anova_svm}
\begin{tabular}{|c|c|c|c|c|}
\hline
$threshold_{class}$ & $threshold_{drift}$ & Liczba cech   & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
0.0                 & 8000                & 6027          & 0.9586            & 0.5346           \\ \hline
0.0                 & 250                 & 3813          & 0.9064            & 0.5603           \\ \hline
0.0                 & 500                 & 4434          & 0.9334            & 0.5857           \\ \hline
0.0                 & 750                 & 4694          & 0.9301            & 0.6035           \\ \hline
0.0                 & 1000                & 4871          & 0.9342            & 0.6054           \\ \hline
\textbf{250}        & \textbf{250}        & \textbf{1890} & \textbf{0.9254}   & \textbf{0.6733}  \\ \hline
250                 & 500                 & 2278          & 0.9357            & 0.6492           \\ \hline
250                 & 750                 & 2446          & 0.9510            & 0.6015           \\ \hline
250                 & 1000                & 2560          & 0.9578            & 0.6176           \\ \hline
\textbf{500}        & \textbf{250}        & \textbf{1309} & \textbf{0.8599}   & \textbf{0.6849}  \\ \hline
500                 & 500                 & 1566          & 0.9069            & 0.5904           \\ \hline
500                 & 750                 & 1656          & 0.9135            & 0.6239           \\ \hline
500                 & 1000                & 1714          & 0.9188            & 0.6006           \\ \hline
500                 & 2000                & 1805          & 0.9128            & 0.5373           \\ \hline
1000                & 500                 & 873           & 0.7966            & 0.4923           \\ \hline
1000                & 1000                & 927           & 0.8039            & 0.5589           \\ \hline
1000                & 2000                & 946           & 0.8005            & 0.5950           \\ \hline
\end{tabular}
\end{table}

\newpage

\begin{table}[!htbp]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji dla ró¿nych warto¶ci progowych przy u¿yciu analizy wariancji i lasów losowych}
\label{t:tt_anova_random}
\begin{tabular}{|c|c|c|c|c|}
\hline
$threshold_{class}$ & $threshold_{drift}$ & Liczba cech   & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
0.0                 & 8000                & 6027          & 0.9948            & 0.7118           \\ \hline
0.0                 & 250                 & 3813          & 0.9915            & 0.7401           \\ \hline
0.0                 & 500                 & 4434          & 0.9923            & 0.7362           \\ \hline
0.0                 & 750                 & 4694          & 0.9922            & 0.7311           \\ \hline
0.0                 & 1000                & 4871          & 0.9929            & 0.7275           \\ \hline
\textbf{250}        & \textbf{250}        & \textbf{1890} & \textbf{0.9919}   & \textbf{0.7659}  \\ \hline
250                 & 500                 & 2278          & 0.9933            & 0.7225           \\ \hline
250                 & 750                 & 2446          & 0.9927            & 0.7300           \\ \hline
250                 & 1000                & 2560          & 0.9931            & 0.7233           \\ \hline
500                 & 250                 & 1309          & 0.9911            & 0.7171           \\ \hline
500                 & 500                 & 1566          & 0.9921            & 0.7235           \\ \hline
500                 & 750                 & 1656          & 0.9920            & 0.7238           \\ \hline
500                 & 1000                & 1714          & 0.9933            & 0.7056           \\ \hline
500                 & 2000                & 1805          & 0.9935            & 0.7113           \\ \hline
1000                & 500                 & 873           & 0.9912            & 0.6692           \\ \hline
1000                & 1000                & 927           & 0.9915            & 0.6685           \\ \hline
1000                & 2000                & 946           & 0.9919            & 0.6679           \\ \hline
\end{tabular}
\end{table}

\subsubsection{Zysk Giniego}

Rysunek \ref{tt_gini} przedstawia rozk³ad jako¶ci cech przy u¿yciu zysku Giniego. Podobnie jak w przypadku jednoczynnikowej analizy wariancji, rozk³ad cech jest korzystny dla opisywanej metody redukcji \textit{concept drift} - atrybuty s± skupione przy osiach $x$ i $y$. Otrzymane wyniki przedstawiaj± tabele \ref{t:tt_gini_logit}, \ref{t:tt_gini_svm} i  \ref{t:tt_gini_random}.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.99\linewidth]{train_test_random_forest.png}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.99\linewidth]{train_test_random_forest_zoomed.png}
\end{subfigure}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption[Rozk³ad jako¶ci cech przy u¿yciu zysku Giniego]{Rozk³ad jako¶ci cech przy u¿yciu zysku Giniego. Wykres po prawej stronie stanowi przybli¿enie wykresu po stronie lewej}
\label{tt_gini}
\end{figure}

\begin{table}[!htbp]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji dla ró¿nych warto¶ci progowych przy u¿yciu zysku Giniego i regresji logistycznej}
\label{t:tt_gini_logit}
\begin{tabular}{|c|c|c|c|c|}
\hline
$threshold_{class}$ & $threshold_{drift}$ & Liczba cech   & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
0.0                 & 0.05                & 6027          & 0.9497            & 0.5348           \\ \hline
0.0                 & 1e-05               & 2018          & 0.8548            & 0.4719           \\ \hline
0.0                 & 5e-05               & 3776          & 0.9165            & 0.4847           \\ \hline
0.0                 & 0.0001              & 4386          & 0.9289            & 0.5472           \\ \hline
0.0                 & 0.001               & 5185          & 0.9436            & 0.5285           \\ \hline
5e-05               & 1e-05               & 429           & 0.7764            & 0.5359           \\ \hline
5e-05               & 5e-05               & 1053          & 0.8935            & 0.5245           \\ \hline
5e-05               & 0.0001              & 1392          & 0.9254            & 0.5516           \\ \hline
5e-05               & 0.0025              & 1999          & 0.9610            & 0.5643           \\ \hline
5e-05               & 0.005               & 2028          & 0.9529            & 0.5484           \\ \hline
0.0001              & 5e-05               & 620           & 0.8859            & 0.5913           \\ \hline
0.0001              & 0.0001              & 841           & 0.8947            & 0.6004           \\ \hline
\textbf{0.0001}     & \textbf{0.005}      & \textbf{1331} & \textbf{0.9553}   & \textbf{0.6176}  \\ \hline
0.001               & 0.0001              & 117           & 0.6451            & 0.4872           \\ \hline
0.001               & 0.0025              & 185           & 0.6829            & 0.5600           \\ \hline
\end{tabular}
\end{table}

\begin{table}[!htbp]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji dla ró¿nych warto¶ci progowych przy u¿yciu zysku Giniego i SVM}
\label{t:tt_gini_svm}
\begin{tabular}{|c|c|c|c|c|}
\hline
$threshold_{class}$ & $threshold_{drift}$ & Liczba cech  & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
0.0                 & 0.05                & 6027         & 0.9586            & 0.5346           \\ \hline
0.0                 & 1e-05               & 2018         & 0.8562            & 0.4723           \\ \hline
0.0                 & 5e-05               & 3776         & 0.9109            & 0.4935           \\ \hline
0.0                 & 0.0001              & 4386         & 0.9318            & 0.5489           \\ \hline
0.0                 & 0.001               & 5185         & 0.9317            & 0.5273           \\ \hline
5e-05               & 1e-05               & 429          & 0.8063            & 0.5762           \\ \hline
5e-05               & 5e-05               & 1053         & 0.9296            & 0.4788           \\ \hline
5e-05               & 0.0001              & 1392         & 0.9288            & 0.5371           \\ \hline
5e-05               & 0.0025              & 1999         & 0.9532            & 0.5141           \\ \hline
5e-05               & 0.005               & 2028         & 0.9580            & 0.5358           \\ \hline
0.0001              & 5e-05               & 620          & 0.8727            & 0.5763           \\ \hline
\textbf{0.0001}     & \textbf{0.0001}     & \textbf{841} & \textbf{0.8693}   & \textbf{0.5952}  \\ \hline
0.0001              & 0.005               & 1331         & 0.9562            & 0.5876           \\ \hline
0.001               & 0.0001              & 117          & 0.6483            & 0.4387           \\ \hline
0.001               & 0.0025              & 185          & 0.6582            & 0.5136           \\ \hline
\end{tabular}
\end{table}

\newpage

\begin{table}[!htbp]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji dla ró¿nych warto¶ci progowych przy u¿yciu zysku Giniego i lasów losowych}
\label{t:tt_gini_random}
\begin{tabular}{|c|c|c|c|c|}
\hline
$threshold_{class}$ & $threshold_{drift}$ & Liczba cech  & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
0.0                 & 0.05                & 6027         & 0.9948            & 0.7118           \\ \hline
0.0                 & 1e-05               & 2018         & 0.9859            & 0.7000           \\ \hline
0.0                 & 5e-05               & 3776         & 0.9893            & 0.7254           \\ \hline
0.0                 & 0.0001              & 4386         & 0.9914            & 0.7271           \\ \hline
0.0                 & 0.001               & 5185         & 0.9933            & 0.7163           \\ \hline
5e-05               & 1e-05               & 429          & 0.9890            & 0.7207           \\ \hline
5e-05               & 5e-05               & 1053         & 0.9925            & 0.7393           \\ \hline
5e-05               & 0.0001              & 1392         & 0.9925            & 0.7338           \\ \hline
5e-05               & 0.0025              & 1999         & 0.9953            & 0.7112           \\ \hline
5e-05               & 0.005               & 2028         & 0.9962            & 0.7246           \\ \hline
0.0001              & 5e-05               & 620          & 0.9933            & 0.7281           \\ \hline
\textbf{0.0001}     & \textbf{0.0001}     & \textbf{841} & \textbf{0.9927}   & \textbf{0.7502}  \\ \hline
0.0001              & 0.005               & 1331         & 0.9960            & 0.7205           \\ \hline
0.001               & 0.0001              & 117          & 0.9918            & 0.7298           \\ \hline
0.001               & 0.0025              & 185          & 0.9928            & 0.7100           \\ \hline
\end{tabular}
\end{table}

Dla ka¿dego z algorytmów ucz±cych mo¿na ponownie zauwa¿yæ poprawê jako¶ci klasyfikatora. Wzrost $BAC$, chocia¿ nie tak wyra¼ny jak w przypadku ANOVA, jest te¿ znaczny i wyniós³ kolejno: $0.08$ dla regresji logistycznej, $0.06$ dla maszyny wektorów no¶nych i $0.04$ dla lasów losowych. \\
Warto te¿ zwróciæ uwagê, ¿e mimo korzystnego rozk³adu cech, obni¿anie $threshold_{drift}$ (a co za tym idzie - eliminacja wiêkszej liczby cech wra¿liwych na ewolucjê pojêæ) nie zawsze nios³o ze sob± poprawê jako¶ci klasyfikatora. Najlepiej widaæ to na przyk³adzie regresji logistycznej. Przy $threshold_{class} = 0$, obni¿enie $threshold_{drift}$ z $0.0001$ na $0.00005$ spowodowa³o do¶æ wyra¼ny spadek jako¶ci klasyfikatora - z $0.5472$ na $0.4847$. Jest to o tyle zaskakuj±ce, ¿e:
\begin{itemize}
\item na podstawie wykresu \ref{tt_gini} wywnioskowaæ mo¿na, ¿e wiêkszo¶æ wyeliminowanych cech by³a bezu¿yteczna dla klasyfikacji czynno¶ci stra¿aka
\item obni¿enie progu nie poskutkowa³o drastycznym spadkiem liczby wybranych cech (z 4386 na 3776)
\end{itemize}

\section{Detekcja zmiany dziedziny przy u¿yciu klasteryzacji}

Problem adaptacji dziedziny w kontek¶cie analizowanego zbioru danych dotyczy ró¿nic w wykonywaniu tych samych czynno¶ci przez ró¿nych stra¿aków. Szukaj±c cech odpornych na ewolucjê pojêæ, naturalne by³oby wiêc wybieranie tych atrybutów, które najgorzej rozró¿niaj± funkcjonariuszy stra¿y miêdzy sob±. Problemem okaza³ siê jednak brak identyfikatora stra¿aka. W zamian dostêpna by³a inna informacja: liczba osób, od których zbierane by³y dane w ka¿dym ze zbiorów (gwoli przypomnienia: zbiór treningowy i testowy pochodzi³y od ró¿nych czteroosobowych grup stra¿aków). Wykorzystuj±c tê wiedzê, modyfikacjê metody opisanej na wstêpie rozdzia³u, w której identyfikator funkcjonariusza próbuje siê "odzyskaæ" przez klastrowanie.

\subsection{Algorytmy klasteryzacji}

Klasteryzacja (inaczej analiza skupieñ) jest metod± uczenia bez nadzoru (por. z sekcj± \ref{ss:pardigms}). Jest to metoda grupowania elementów danego zbioru we wzglêdnie jednorodne klasy. Podstaw± grupowania w wiêkszo¶ci algorytmów jest podobieñstwo miêdzy elementami - wyra¿one przy pomocy pewnej funkcji podobieñstwa. Algorytmy analizy skupieñ dzieli siê na kilka podstawowych kategorii:
\begin{itemize}
\item metody hierarchiczne - tworzy dla zbioru obiektów hierarchiê klasyfikacji, zaczynaj±c od takiego podzia³u, w którym ka¿dy obiekt stanowi samodzielne skupienie, a koñcz±c na podziale, w którym wszystkie obiekty nale¿± do jednego skupienia.
\item metody rozmytej analizy skupieñ - metody z tej grupy mog± przydzielaæ element do wiêcej ni¿ jednego klastra. Z tego powodu algorytmy rozmytej analizy skupieñ stosowane s± w zadaniu kategoryzacji (przydzia³u obiektów do jednej lub wielu kategorii).
\item grupa metod k-centroidów - polega na podzieleniu zbioru na dan± z góry liczbê klas. Polega na iteracyjnym przyporz±dkowaniu danego obiektu do klastra, którego ¶rodek znajduje siê najbli¿ej. Schemat algorytmu jest nastêpuj±cy:
\begin{enumerate}
\item losowy wybór ¶rodków (centroidów) klastrów
\item przypisanie punktów do najbli¿szych centroidów
\item wyliczenie nowych ¶rodków skupieñ
\item powtarzanie algorytmu a¿ do osi±gniêcia kryterium zbie¿no¶ci
\end{enumerate}
Przyk³ad obiektów pogrupowanych przy u¿yciu algorytmu k-centroidów przedstawia rys. \ref{kcentroids}.
\begin{figure}[!htbp]
\centering
\includegraphics[scale=0.55]{kmeans.png}
\captionsetup{justification=centering}
\captionsetup{width=0.7\textwidth}
\caption{Przyk³ad klastrowania danych przy u¿yciu algorytmu k-centroidów}
\label{kcentroids}
\end{figure}
\end{itemize}
\newpage

\subsection{Opis algorytmu}

W sekcji \ref{s:tt} wyliczano jako¶æ cech wzglêdem etykiet "train" i "test" w celu wykrycia cech najbardziej odpornych na \textit{concept drift}. Intuicyjnie, lepsze wyniki powinno siê uzyskaæ, u¿ywaj±c jako klas rzeczywistych identyfikatorów dziedzin - w tym przypadku, identyfikatorów stra¿aków. Te identyfikatory nie by³y jednak obecne w zbiorze danych. Jak wspomniano na pocz±tku bie¿±cej sekcji, mo¿na je jednak imitowaæ na podstawie wyników analizy skupieñ. \\
Nasuwaj±cym siê pomys³em jest wiêc pogrupowanie obiektów w tyle grup, ilu stra¿aków dostarczy³o dane, a nastêpnie wykorzystanie identyfikatorów tak powsta³ych klastrów do wyznaczenia jako¶ci cech. Taka metoda wyda³a siê jednak autorowi niewystarczaj±ca - klastry mog³y skupiaæ w sobie instancje odpowiadaj±ce podobnym czynno¶ciom (tak jak $running$ i $stairs\_up$), a nie pomiary pobrane od jednego stra¿aka. Z tego powodu autor zastosowa³ inny algorytm, w którym grupowanie dokonywane by³o osobno na zbiorach obiektów nale¿±cych do tej samej klasy. Nastêpnie jako¶æ danej cechy dla problemu \textit{concept drift} by³a mierzona osobno na ka¿dym z tych zbiorów, a ostateczny wynik by³ ¶redni± wyników czê¶ciowych. \\
\hfill \\
Schemat algorytmu dla cechy $f$ i miary $quality\_measure$ przedstawia poni¿szy pseudokod: \\


\begin{lstlisting}[mathescape=true, frame=top, frame=bottom, caption={Algorytm pomiaru jako¶ci cechy dla problemu wykrycia ewoluuj±cych pojêæ przy u¿yciu klasteryzacji}, label=alg_cluster][language=Python]
def get_quality(f, quality_measure, X_train, y_train):
    labels = set(y_train)
    partial_qualities = []
    for label in labels:
        X_label = {x_i $\in$ X_train: y_i = label}
        # Zbiór treningowy pochodzi³ od 4 stra¿aków - 
        # st±d podzia³ na 4 klastry
        firefighter_ids = cluster(X_label, 4)
        # Pomiar jako¶ci cechy dla czêsciowego zbioru
        # wzglêdem identyfikatorów stra¿aków
        partial_quality = quality_measure(
            X_label,
            f,
            firefighter_ids
        )
        partial_qualities.append(partial_quality)
    return mean(partial_qualities)
\end{lstlisting}

\hfill \\
Poniewa¿ liczba klastrów by³a z góry ustalona, do klastrowania u¿yto algorytmu k-centroidów (przy $k=4$). Jako miarê jako¶ci zastosowano (podobnie jak w poprzedniej sekcji): informacjê wzajemn±, jednoczynnikow± analizê wariancji oraz zysk Giniego.

\subsection{Wyniki eksperymentów}

\subsubsection{Informacja wzajemna i jednoczynnikowa analiza wariancji}

Analogicznie do eksperymentów opisanych w sekcji \ref{s:tt}, rozpatrzmy rozk³ad jako¶ci cech dla dwóch problemów: klasyfikacji czynno¶ci stra¿aka oraz wykrywania ewoluuj±cych pojêæ. W tym przypadku jako¶æ cechy dla problemu detekcji \textit{concept drift} wyznaczana by³a przy u¿yciu algorytmu \ref{alg_cluster}. \\
Rys. \ref{clustering_mutual_anova} przedstawia rozk³ad jako¶ci przy zastosowaniu informacji wzajemnej (rysunek po lewej) i jednoczynnikowej analizy wariancji (rysunek po prawej) jako miar. W obu przypadkach widaæ wysok± korelacjê miêdzy jako¶ci± cechy dla klasyfikacji a jej jako¶ci± dla wykrycia dziedziny. Jak wspomniano w sekcji \ref{s:tt}, znacznie utrudnia to dobranie odpowiednich warto¶ci progów $threshold_{drift}$ oraz $threshold_{class}$. Znalaz³o to swoje odzwierciedlenie w jako¶ci klasyfikacji - w obu przypadkach zastosowanie selekcji atrybutów albo pogarsza³o wynik, albo poprawia³o go bardzo nieznacznie. Rezultaty uzyskane dla ró¿nych klasyfikatorów by³y zbli¿one do tych prezentowanych w tabelach \ref{t:tt_mutual_info_logit}, \ref{t:tt_mutual_info_lsvm} i \ref{t:tt_mutual_info_random}.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.99\linewidth]{clustering_mutual_info.png}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.99\linewidth]{clustering_anova_f.png}
\end{subfigure}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption[Rozk³ad jako¶ci cech przy u¿yciu informacji wzajemnej i jednoczynnikowej analizy wariancji mierzonej za pomoc± algorytmu \ref{alg_cluster}]{Rozk³ad jako¶ci cech przy u¿yciu informacji wzajemnej (po lewej) i jednoczynnikowej analizy wariancji (po prawej) mierzonej za pomoc± algorytmu \ref{alg_cluster}}
\label{clustering_mutual_anova}
\end{figure}

\subsubsection{Zysk Giniego}

Sytuacja prezentuje siê znacznie korzystniej, gdy jako miary u¿yje siê zysku Giniego (rys. \ref{clustering_gini}). Cechy skupione s± przy osiach $x$ i $y$, co pozwala ³atwo dobraæ dobre warto¶ci progów $threshold_{drift}$ i $threshold_{class}$. Uzyskane rezultatys przedstawiaj± tabele \ref{t:cluster_gini_logit}, \ref{t:cluster_gini_svm} i  \ref{t:cluster_gini_random}.

\begin{figure}[!htbp]
\centering
\begin{subfigure}{.45\textwidth}
  \centering
  \includegraphics[width=.99\linewidth]{clustering_gini.png}
\end{subfigure}%
\begin{subfigure}{.45\textwidth}
  \centering
  \includegraphics[width=.99\linewidth]{clustering_gini_zoomed.png}
\end{subfigure}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption[Rozk³ad jako¶ci cech przy u¿yciu zysku Giniego i algorytmu \ref{alg_cluster}]{Rozk³ad jako¶ci cech przy u¿yciu zysku Giniego i algorytmu \ref{alg_cluster}. Wykres po prawej stronie stanowi przybli¿enie wykresu po stronie lewej}
\label{clustering_gini}
\end{figure}


\begin{table}[!htbp]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji dla ró¿nych warto¶ci progowych przy u¿yciu algorytmu \ref{alg_cluster}, zysku Giniego i regresji logistycznej}
\label{t:cluster_gini_logit}
\begin{tabular}{|c|c|c|c|c|}
\hline
$threshold_{class}$ & $threshold_{drift}$ & Liczba cech  & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
0.0                 & 0.4                 & 6027         & 0.9497            & 0.5348           \\ \hline
0.0                 & 5e-05               & 3900         & 0.9263            & 0.5000           \\ \hline
0.0                 & 2.5e-05             & 3566         & 0.9314            & 0.4985           \\ \hline
0.0                 & 1e-05               & 3001         & 0.9193            & 0.5101           \\ \hline
2.5e-05             & 0.4                 & 2754         & 0.9651            & 0.5284           \\ \hline
2.5e-05             & 5e-05               & 1661         & 0.9128            & 0.5383           \\ \hline
2.5e-05             & 2.5e-05             & 1458         & 0.9147            & 0.5372           \\ \hline
5e-05               & 0.4                 & 2057         & 0.9630            & 0.5311           \\ \hline
5e-05               & 5e-05               & 1186         & 0.9034            & 0.5641           \\ \hline
5e-05               & 1.25e-05            & 819          & 0.8789            & 0.5764           \\ \hline
0.00025             & 0.4                 & 703          & 0.9272            & 0.6193           \\ \hline
\textbf{0.00025}    & \textbf{0.002}      & \textbf{678} & \textbf{0.9039}   & \textbf{0.6294}  \\ \hline
0.00025             & 2.5e-05             & 339          & 0.8835            & 0.6161           \\ \hline
0.001               & 0.4                 & 187          & 0.6823            & 0.5260           \\ \hline
0.001               & 0.0005              & 172          & 0.6801            & 0.5296           \\ \hline
0.001               & 5e-05               & 114          & 0.7202            & 0.4882           \\ \hline
\end{tabular}
\end{table}

\begin{table}[!htbp]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji dla ró¿nych warto¶ci progowych przy u¿yciu algorytmu \ref{alg_cluster}, zysku Giniego i SVM}
\label{t:cluster_gini_svm}
\begin{tabular}{|c|c|c|c|c|}
\hline
$threshold_{class}$ & $threshold_{drift}$ & Liczba cech  & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
0.0                 & 0.4                 & 6027         & 0.9586            & 0.5346           \\ \hline
0.0                 & 5e-05               & 3900         & 0.9264            & 0.4974           \\ \hline
0.0                 & 2.5e-05             & 3566         & 0.9222            & 0.4821           \\ \hline
0.0                 & 1e-05               & 3001         & 0.9085            & 0.5064           \\ \hline
2.5e-05             & 0.4                 & 2754         & 0.9673            & 0.5346           \\ \hline
2.5e-05             & 5e-05               & 1661         & 0.9308            & 0.5080           \\ \hline
2.5e-05             & 2.5e-05             & 1458         & 0.9116            & 0.5279           \\ \hline
5e-05               & 0.4                 & 2057         & 0.9618            & 0.5513           \\ \hline
5e-05               & 5e-05               & 1186         & 0.9300            & 0.5308           \\ \hline
5e-05               & 1.25e-05            & 819          & 0.8888            & 0.5760           \\ \hline
0.00025             & 0.4                 & 703          & 0.9100            & 0.5945           \\ \hline
\textbf{0.00025}    & \textbf{0.002}      & \textbf{678} & \textbf{0.9169}   & \textbf{0.6287}  \\ \hline
0.00025             & 2.5e-05             & 339          & 0.8849            & 0.5973           \\ \hline
0.001               & 0.4                 & 187          & 0.6946            & 0.5908           \\ \hline
0.001               & 0.0005              & 172          & 0.6849            & 0.4715           \\ \hline
0.001               & 5e-05               & 114          & 0.6968            & 0.4628           \\ \hline
\end{tabular}
\end{table}

\newpage

\begin{table}[!htbp]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Jako¶æ klasyfikacji dla ró¿nych warto¶ci progowych przy u¿yciu algorytmu \ref{alg_cluster}, zysku Giniego i lasów losowych}
\label{t:cluster_gini_random}
\begin{tabular}{|c|c|c|c|c|}
\hline
$threshold_{class}$ & $threshold_{drift}$ & Liczba cech  & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
0.0                 & 0.4                 & 6027         & 0.9948            & 0.7118           \\ \hline
0.0                 & 5e-05               & 3900         & 0.9926            & 0.7258           \\ \hline
0.0                 & 2.5e-05             & 3566         & 0.9907            & 0.7366           \\ \hline
0.0                 & 1e-05               & 3001         & 0.9908            & 0.7359           \\ \hline
2.5e-05             & 0.4                 & 2754         & 0.9954            & 0.7258           \\ \hline
2.5e-05             & 5e-05               & 1661         & 0.9937            & 0.7265           \\ \hline
2.5e-05             & 2.5e-05             & 1458         & 0.9920            & 0.7372           \\ \hline
5e-05               & 0.4                 & 2057         & 0.9958            & 0.7175           \\ \hline
5e-05               & 5e-05               & 1186         & 0.9943            & 0.7307           \\ \hline
5e-05               & 1.25e-05            & 819          & 0.9919            & 0.7337           \\ \hline
0.00025             & 0.4                 & 703          & 0.9961            & 0.7325           \\ \hline
0.00025             & 0.002               & 678          & 0.9948            & 0.7417           \\ \hline
\textbf{0.00025}    & \textbf{2.5e-05}    & \textbf{339} & \textbf{0.9937}   & \textbf{0.7596}  \\ \hline
0.001               & 0.4                 & 187          & 0.9940            & 0.7209           \\ \hline
0.001               & 0.0005              & 172          & 0.9917            & 0.7219           \\ \hline
0.001               & 5e-05               & 114          & 0.9898            & 0.7027           \\ \hline
\end{tabular}
\end{table}


Ponownie dla ka¿dego z klasyfikatorów zauwa¿yæ mo¿na wzrost jako¶ci (wynosz±cy oko³o $0.09$ dla klasyfikatorów liniowych i prawie $0.05$ dla lasów losowych). Warto przy tym zwróciæ uwagê, ¿e najwy¿sze wyniki otrzymano dla niewielkiej liczby wybranych atrybutów - 678 w przypadku regresji logistycznej i SVM oraz 339 dla lasów losowych. Znaczne zmniejszenie wymiarowo¶ci mo¿e mieæ wiele pozytywnych skutków w biznesowych zastosowaniach modelu, znacznie obni¿aj±c czas i zasoby potrzebne do uczenia. \\
Porównuj±c rezultaty z wynikami otrzymanymi dla metody detekcji \textit{concept drift} z sekcji \ref{s:tt} (tabele \ref{t:tt_gini_logit}, \ref{t:tt_gini_svm} i \ref{t:tt_gini_random}) przy u¿yciu zysku Giniego, mo¿na zauwa¿yæ niewielk± poprawê. Autorska metoda wykrywania ewoluuj±cych pojêæ mo¿e zatem konkurowaæ z metod± zaproponowan± w \cite{Boulle15}, co czyni j± z pewno¶ci± wart± uwagi.

\section{Wnioski z przeprowadzonych eksperymentów}

W rozdziale \ref{r:drift_reduction} przedstawiono generyczn± metodê wyboru podprzestrzeni cech odpornych na zmianê dziedziny. Jedn± z najwiêkszych zalet opisywanej metody jest w³a¶nie jej generyczno¶æ - mo¿e byæ ona stosowana niezale¿nie od typu badanych danych czy algorytmów ucz±cych. Innym znacz±cym plusem jest wydajno¶æ - miejscami osi±gniêto poprawê jako¶ci (mierzon± w mierze $BAC$) siêgaj±c± $0.15$. Du¿± zalet± jest te¿ prostota tego podej¶cia, zarówno pod k±tem ideologicznym, jak i implementacyjnym. \\
Do wad zaliczyæ nale¿y natomiast zale¿no¶æ skuteczno¶ci metody od danej przestrzeni cech - je¶li dana reprezentacja zawiera niewielk± liczbê atrybutów odpornych na \textit{concept drift}, stosowanie selekcji cech oka¿e siê bezu¿yteczne. Innym istotnym czynnikiem jest wybór miary jako¶ci cech. Jak pokaza³y opisane eksperymenty, dla niektórych miar rozk³ad jako¶ci uniemo¿liwia³ takie dobranie warto¶ci progów $threshold_{drift}$ i $threshold_{class}$, aby usun±æ cechy wra¿liwe na ewolucjê pojêæ i jednocze¶nie zostawiæ atrybuty warto¶ciowe dla klasyfikacji czynno¶ci stra¿aka.

\chapter{Inne metody adaptacji dziedziny} \label{r:other}

W poni¿szym rozdziale przedstawione zostan± dwie inne metody adaptacji dziedziny: uczenie iteracyjne oraz metoda zmiany przestrzeni cech zaproponowana przez Daum{\'{e}} w \cite{Daume07}.

\section{Uczenie iteracyjne}

\subsection{Opis algorytmu}

Idea uczenia iteracyjnego jest stosunkowo intuicyjna. Algorytm ten polega na iteracyjnym powiêkszaniu zbioru treningowego na czê¶ci poprzednio sklasyfikowanych przyk³adów ze zbioru testowego. Bardziej szczegó³owo, uczenie iteracyjne dzia³a wed³ug nastêpuj±cego schematu:

\begin{enumerate}
\item klasyfikator $c$ jest uczony na zbiorze treningowym
\item $c$ klasyfikuje czê¶æ przyk³adów ze zbioru testowego
\item zbiór treningowy powiêkszany jest o uprzednio sklasyfikowane instancje
\end{enumerate}

Poni¿ej znajduje siê pseudokod algorytmu uczenia iteracyjnego. \\

\begin{lstlisting}[mathescape=true, frame=top, frame=bottom, caption={Algorytm uczenia iteracyjnego}][language=Python]
def iterative_learning(classifier, X_train, y_train,
        X_test, rows_percentage):
    num_of_rows_per_iteration = rows_percentage * size(X_test)
    classifier.learn(X_train, y_train)
    y_test = []
    while size(X_test) > 0:
        current_sample = sample(X_test, num_of_rows_per_iteration)
        X_test = X_test \ current_sample
        current_y = classifier.classify(current_sample)
        y_test = y_test $\cup$ current_y
        y_train = y_train $\cup$ current_y
        X_train = X_train $\cup$ current_sample
        classifier.learn(X_train, y_train)
    return y_test
\end{lstlisting}

\hfill \\
Argument $rows\_percentage$ jest liczb± z przedzia³u $(0, 1]$ i okre¶la, jaka czê¶æ zbioru testowego jest do³±czana do zbioru treningowego w ka¿dej iteracji. \\
Jedn± z zalet uczenia iteracyjnego jest z pewno¶ci± prostota implementacji. Kolejn± - mo¿liwo¶æ stosowania go dla dowolnych danych oraz klasyfikatora bazowego. Wad± mo¿e natomiast okazaæ siê zwiêkszona czas uczenia - w zale¿no¶ci od warto¶ci $rows\_percentage$, model trenowany jest kilka razy.

\subsection{Eksperymenty i wnioski}

Wyniki klasyfikacji przy zastosowaniu zaprezentowanego wy¿ej algorytmu opisuj± tabele \ref{t:iterative}. Pierwszy wiersz ka¿dej z tabel podaje jako¶æ klasyfikacji bez zastosowania uczenia iteracyjnego. \\


\begin{table}[!htpb]
    \begin{subtable}{.55\linewidth}
      \centering
\begin{tabular}{|c|c|c|}
\hline
$rows\_percentage$ & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
-                & 0.9497            & 0.5348           \\ \hline
0.5                & 0.9541            & 0.5449           \\ \hline
0.34               & 0.9411            & 0.5302           \\ \hline
0.25               & 0.9474            & 0.5274           \\ \hline
0.1                & 0.9507            & 0.5073           \\ \hline
\end{tabular}
\caption{Regresja logistyczna}
    \end{subtable}%
    \begin{subtable}{.55\linewidth}
      \centering
        
\begin{tabular}{|c|c|c|}
\hline
$rows\_percentage$ & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
-                & 0.9586            & 0.5348             \\ \hline
0.5                & 0.9535            & 0.537             \\ \hline
0.34               & 0.9457            & 0.5389            \\ \hline
0.25               & 0.9525            & 0.5282            \\ \hline
0.1                & 0.95127           & 0.5091            \\ \hline
\end{tabular}
\caption{SVM}
    \end{subtable}
    \begin{subtable}{1.0\linewidth}
      \centering

\begin{tabular}{|c|c|c|}
\hline
$rows\_percentage$ & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
-              & 0.9948      & 0.7118     \\ \hline
0.5             & 0.9949      & 0.7249     \\ \hline
0.34            & 0.9945      & 0.7257     \\ \hline
0.25            & 0.995       & 0.7273     \\ \hline
0.1             & 0.9948      & 0.7317     \\ \hline
\end{tabular}
        \caption{Lasy losowe}
    \end{subtable} 
    \captionsetup{justification=centering}
    \captionsetup{width=0.8\textwidth}
    \caption{Jako¶æ klasyfikatora budowanego przy u¿yciu uczenia iteracyjnego dla ró¿nych algorytmów ucz±cych i warto¶ci $rows\_percentage$}
    \label{t:iterative}    
\end{table}

Zastosowanie \textit{iterative learning} nie mia³o znacz±cego wp³ywu na jako¶æ klasyfikacji. Mo¿na zauwa¿yæ, ¿e w przypadku "s³abszych" algorytmów (regresji logistycznej i SVM) nast±pi³o obni¿enie wyniku. By³o to najpewniej spowodowane tym, ¿e klasyfikator z ka¿d± iteracj± dopasowywa³ siê coraz bardziej do du¿ej liczby b³êdnie sklasyfikowanych obiektów. Jest to jedna z wad uczenia iteracyjnego - dla klasyfikatora bazowego miernej jako¶ci wynik najpewniej nie ulegnie poprawie. \\
W przypadku lasów losowych mo¿na z kolei zauwa¿yæ nieznaczny, ale sta³y wzrost jako¶ci przy obni¿aniu warto¶ci $rows\_percentage$.

\section{Powiêkszenie przestrzeni cech}

\subsection{Opis algorytmu}

Adaptacja dziedziny przez powiêkszenie przestrzeni cech zosta³a zaproponowana przez Daum{\'{e}} w \cite{Daume07}. Jak wiêkszo¶æ tego typu metod, pochodzi ona z dziedziny przetwarzania jêzyka naturalnego. Powiêkszenie przestrzeni cech polega na zast±pieniu ka¿dego atrybutu jego trzema wersjami: wersj± ogóln±, wersj± odpowiadaj±c± dziedzinie ¼ród³owej $D^{source}$ oraz wersj± odpowiadaj±c± dziedzinie docelowej $D^{target}$. \\
Aby zdefiniowaæ tê operacjê bardziej formalnie, przyjmijmy oznaczenia jak w sekcji \ref{s:superv}. Niech dla czytelno¶ci $X = \mathbb{R}^F$, dla pewnego $F > 0$. Wtedy powiêkszona przestrzeñ przyk³adów zdefiniowana jest jako $\hat{X} = \mathbb{R}^{3F}$.
Nastêpnie definiuje siê funkcje:
\begin{displaymath}
\Phi^{train}: X_{train} \rightarrow \hat{X}, \quad \Phi^{train}(\textbf{x}) = (\textbf{x}, \textbf{x}, \textbf{0})
\end{displaymath}
oraz
\begin{displaymath}
\Phi^{test}: X_{test} \rightarrow \hat{X}, \quad \Phi^{test}(\textbf{x}) = (\textbf{x}, \textbf{0}, \textbf{x}),
\end{displaymath}
gdzie $\textbf{0} = (0, 0, \dots, 0) \in \mathbb{R}^F$. Funkcje te mapuj± instance ze zbioru treningowego (pochodz±ce z za³o¿enia z dziedziny $D^{source}$) oraz testowego (pochodz±ce z $D^{target}$) w rozszerzon± przestrzeñ atrybutów $\hat{X}$. \\
Spróbujmy wyja¶niæ intuicjê stoj±c± za takim podej¶ciem. Rozwa¿my problem rozpoznawania czê¶ci mowy (ang. \textit{Part-of-speech tagging}, w skrócie POS), gdzie zbiór treningowy tworz± artyku³y z Wall Street Journal\footnote{http://www.wsj.com}, a zbiór testowy - anglojêzyczne artyku³y o sprzêcie komputerowym. Przy tak postawionym problemie, s³owo "in" powinno byæ traktowane w obu dziedzinach jako przyimek, podczas gdy s³owo "monitor" powinno byæ traktowane jako czasownik w dziedzinie treningowej oraz rzeczownik w dziedzinie testowej. \\
Rozwa¿my prosty przypadek, w którym $X = \mathbb{R}^2$, gdzie wymiar $x_1$ odpowiada s³owu "in", a wymiar $x_2$ - s³owu "monitor". Wtedy, w $\hat{X}$, $\hat{x}_1$ i $\hat{x}_2$ odpowiadaj± "ogólnym" znaczeniom tych s³ów, $\hat{x}_3$ i $\hat{x}_4$ - znaczeniom w dziedzinie artyku³ów finansowych, a $\hat{x}_5$ i $\hat{x}_6$ - znaczeniom w dziedzinie artyku³ów komputerowych. \\
Zastanówmy siê teraz, co mo¿e zrobiæ algorytm ucz±cy, aby zauwa¿yæ, ¿e "in" powinno byæ traktowane jako przyimek w obydwu dziedzinach, natomiast klasyfikacja s³owa "monitor" mo¿e siê ró¿niæ w zale¿no¶ci od dziedziny. W tym przypadku, wektor wag odpowiadaj±cy klasie "przyimek" bêdzie wygl±da³ nastêpuj±co: $(1, 0, 0, 0, 0, 0)$. Podkre¶la to, ¿e "in" jest przyimkiem niezale¿nie od dziedziny. Z kolei wektor wag dla klasy "rzeczownik" bêdzie postaci $(0, 0, 0, 0, 0, 1)$, co oznacza, ¿e "monitor" jest rzeczownikiem tylko w zbiorze testowym. Analogicznie, wektor dla klasy "czasownik" bêdzie postaci $(0, 0, 0, 1, 0, 0)$.

\subsection{Eksperymenty i wnioski}

Prezentowana metoda znacznie powiêksza przestrzeñ cech. Przy 6000 atrybutach otrzymanych w rozdziale \ref{r:features}. daje ona 18000 cech, co jest stosunkowo du¿± liczb± dla 20000 instancji treningowych. Z tego powodu autor postanowi³ po³±czyæ metodê Damue z metod± selekcji cech opisan± w rozdziale \ref{r:drift_reduction}. Do selekcji cech u¿yto jednoczynnikowej analizy wariancji (por. tabele \ref{t:tt_anova_logit}, \ref{t:tt_anova_svm}, \ref{t:tt_anova_svm}). Wyniki przedstawia tabela \ref{t:easy_augmented}. Dla czytelno¶ci, tabela \ref{t:easy_original} przedstawia jako¶æ klasyfikacji na oryginalnej (niepowiêkszonej) przestrzeni cech. \\
Rezultaty s± bardzo interesuj±ce. W przypadku klasyfikatorów liniowych zwiêkszenie liczby atrybutów mia³o praktycznie zerowy wp³yw na jako¶æ klasyfikacji - zarówno regresja logistyczna, jak i SVM zdaj± siê ignorowaæ dodane cechy. Dla lasów losowych metoda Daum{\'{e}} mia³a jednak katastrofalne skutki - wynik spad³ z oko³o $0.7$ do oko³o $0.15$! Mo¿na zatem wyci±gn±æ wniosek, ¿e metoda powiêkszania przetrzeni cech nie ma szerszego zastosowania poza dziedzin± przetwarzania jêzyka naturalnego.


\begin{table}[!htpb]
    \begin{subtable}{1.\linewidth}
      \centering
\begin{tabular}{|c|c|c|c|}
\hline
Klasyfikator & Liczba cech & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
logit        & 6027        & 0.9497            & 0.5348           \\ \hline
SVM          & 6027        & 0.9586            & 0.5346           \\ \hline
lasy losowe  & 6027        & 0.9948            & 0.7118           \\ \hline
logit        & 1309        & 0.8926            & 0.6680           \\ \hline
SVM          & 1309        & 0.8599            & 0.6849           \\ \hline
lasy losowe  & 1309        & 0.9911            & 0.7171           \\ \hline
logit        & 1890        & 0.9188            & 0.6711           \\ \hline
SVM          & 1890        & 0.9254            & 0.6733           \\ \hline
lasy losowe  & 1890        & 0.9919            & 0.7659           \\ \hline
logit        & 2278        & 0.9426            & 0.6333           \\ \hline
SVM          & 2278        & 0.9357            & 0.6492           \\ \hline
lasy losowe  & 2278        & 0.9933            & 0.7225           \\ \hline
\end{tabular}
\caption{Oryginalne wyniki}
\label{t:easy_original}
    \end{subtable}
    \begin{subtable}{1.\linewidth}
      \centering
        
\begin{tabular}{|c|c|c|c|}
\hline
Klasyfikator & Liczba cech & $X_{train}$ $BAC$ & $X_{test}$ $BAC$ \\ \hline
logit        & 6027        & 0.9498            & 0.5348           \\ \hline
SVM          & 6027        & 0.9568            & 0.5346           \\ \hline
lasy losowe  & 6027        & 0.9957            & 0.2080           \\ \hline
logit        & 1309        & 0.8964            & 0.6516           \\ \hline
SVM          & 1309        & 0.8652            & 0.6800           \\ \hline
lasy losowe  & 1309        & 0.9902            & 0.1682           \\ \hline
logit        & 1890        & 0.9382            & 0.6726           \\ \hline
SVM          & 1890        & 0.9209            & 0.6606           \\ \hline
lasy losowe  & 1890        & 0.9908            & 0.1460           \\ \hline
logit        & 2278        & 0.9407            & 0.6333           \\ \hline
SVM          & 2278        & 0.9428            & 0.6438           \\ \hline
lasy losowe  & 2278        & 0.9921            & 0.1647           \\ \hline
\end{tabular}
\caption{Wyniki po powiêkszeniu przestrzeni cech}
\label{t:easy_augmented}
    \end{subtable}
    \captionsetup{justification=centering}
    \captionsetup{width=0.8\textwidth}
    \caption{Jako¶æ klasyfikatora budowanego przy u¿yciu metody powiêkszania przestrzeni cech}
    \label{t:augmentation}    
\end{table}

\chapter{Podsumowanie} \label{r:summary}

G³ównym celem pracy by³o zbudowanie wydajnego klasyfikatora na zbiorze wielowymiarowych szeregów czasowych, w którym obecny by³ problem ewolucji pojêæ miêdzy zbiorem treningowym a testowym. Autor skupi³ siê na dwóch sk³adowych procesu budowy klasyfikatora:
\begin{itemize}
\item ekstrakcji cech z szeregów czasowych
\item redukcji \textit{concept drift}
\end{itemize} 

Ca³y proces ekstrakcji cech zosta³ opisany w rozdziale \ref{r:features}. Warto zauwa¿yæ, ¿e zastosowane podej¶cie jest bardzo ogólne - mo¿e byæ u¿yte dla dowolnych szeregów czasowych, nie wymagaj±c jednocze¶nie specjalistycznej wiedzy z dziedziny, z której pochodz± dane. Dodatkowo pozwala na otrzymanie sensownej liczby cech (z 42 szeregów czasowych o d³ugo¶ci 400 uzyskano 6000 atrybutów) w stosunkowo niewielkim czasie oko³o dwóch godzin na komputerze przeznaczonym do u¿ytku domowego. Nale¿y przy tym zwróciæ uwagê na fakt, i¿ cechy wyliczane by³y sekwencyjnie - zastosowanie mocniejszej maszyny i zrównoleglenia ca³ego procesu mog³oby zatem znacznie obni¿yæ czas dzia³ania. \\

Kolejnym krokiem by³a redukcja problemu ewoluuj±cych pojêæ. G³ównym celem autora by³o rozwiniêcie metody opisanej w \cite{Boulle15} i dok³adne przetestowanie jej jako¶ci dla ró¿nych kombinacji miar jako¶ci cech i algorytmów ucz±cych. Uzyskane wyniki mo¿na uznaæ za satysfakcjonuj±ce - poprawa wyniku siêga³a nawet 30\%. Dodatkowo zaproponowane zosta³o rozszerzenie tego podej¶cia przez zastosowanie analizy skupieñ. Autor u¿y³ algorytmu k-centroidów do identyfikacji ¼ród³a, z którego pochodz± obiekty. Takie podej¶cie wydaje siê autorowi obiecuj±ce i zas³uguj±ce na dalsze badania w przysz³o¶ci. \\

W rozdziale \ref{r:other}. opisano dwie inne metody stosowane do rozwi±zania problemu adaptacji dziedziny - uczenie iteracyjne oraz powiêkszanie przestrzeni cech zaproponowane w \cite{Daume07}. Obie okaza³y siê nieskuteczne - wyniki otrzymane przy ich u¿yciu by³y du¿o gorsze ni¿ te uzyskane przy zastosowaniu selekcji cech. Potwierdza to tylko fakt, ¿e metoda przedstawiona w rozdziale \ref{r:drift_reduction}. jest warta rozwijania.

\listoffigures
 
\listoftables

\nocite{*}
\bibliographystyle{apalike}
\bibliography{pracamgr.bib}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: latin-2
%%% End:
