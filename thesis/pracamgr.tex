%
% Niniejszy plik stanowi przyk³ad formatowania pracy magisterskiej na
% Wydziale MIM UW.  Szkielet u¿ytych poleceñ mo¿na wykorzystywaæ do
% woli, np. formatujac wlasna prace.
%
% Zawartosc merytoryczna stanowi oryginalnosiagniecie
% naukowosciowe Marcina Wolinskiego.  Wszelkie prawa zastrze¿one.
%
% Copyright (c) 2001 by Marcin Woliñski <M.Wolinski@gust.org.pl>
% Poprawki spowodowane zmianami przepisów - Marcin Szczuka, 1.10.2004
% Poprawki spowodowane zmianami przepisow i ujednolicenie 
% - Seweryn Kar³owicz, 05.05.2006
% dodaj opcjê [licencjacka] dla pracy licencjackiej
\documentclass{pracamgr}

\usepackage{polski}

%Jesli uzywasz kodowania polskich znakow ISO-8859-2 nastepna linia powinna byc 
%odkomentowana
\usepackage[latin2]{inputenc}
%Jesli uzywasz kodowania polskich znakow CP-1250 to ta linia powinna byc 
%odkomentowana
%\usepackage[cp1250]{inputenc}
\usepackage[linesnumbered]{algorithm2e}
\usepackage{caption}
\usepackage{afterpage}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{makecell}

\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \newpage}


% Dane magistranta:

\author{Grzegorz Szpak}

\nralbumu{319400}

\title{Klasyfikacja wielowymiarowych szeregów czasowych przy ewoluuj±cych pojêciach}

\tytulang{Classification of multivariate time series in the presence of concept drift}

%kierunek: Matematyka, Informatyka, ...
\kierunek{Informatyka}

% informatyka - nie okreslamy zakresu (opcja zakomentowana)
% matematyka - zakres moze pozostac nieokreslony,
% a jesli ma byc okreslony dla pracy mgr,
% to przyjmuje jedna z wartosci:
% {metod matematycznych w finansach}
% {metod matematycznych w ubezpieczeniach}
% {matematyki stosowanej}
% {nauczania matematyki}
% Dla pracy licencjackiej mamy natomiast
% mozliwosc wpisania takiej wartosci zakresu:
% {Jednoczesnych Studiow Ekonomiczno--Matematycznych}

% \zakres{Tu wpisac, jesli trzeba, jedna z opcji podanych wyzej}

% Praca wykonana pod kierunkiem:
% (podaæ tytu³/stopieñ imiê i nazwisko opiekuna
% Instytut
% ew. Wydzia³ ew. Uczelnia (je¿eli nie MIM UW))
\opiekun{dra Andrzeja Janusza \\
  Instytut Informatyki \\
  }

% miesi±c i~rok:
\date{Grudzieñ 2016}

%Podaæ dziedzinê wg klasyfikacji Socrates-Erasmus:
\dziedzina{ 
%11.0 Matematyka, Informatyka:\\ 
%11.1 Matematyka\\ 
%11.2 Statystyka\\ 
%11.3 Informatyka\\ 
11.4 Sztuczna inteligencja TODO\\ 
%11.5 Nauki aktuarialne\\
%11.9 Inne nauki matematyczne i informatyczne
}

%Klasyfikacja tematyczna wedlug AMS (matematyka) lub ACM (informatyka)
\klasyfikacja{D. Software TODO\\
}

% S³owa kluczowe:
\keywords{Eksploracja danych, wielowymiarowy szereg czasowy, ewoluuj±ce pojêcia, dopasowanie dziedziny, ekstrakcja cech, selekcja cech, lasy losowe, regresja logistyczna, maszyna wektorów wspieraj±cych}

% Tu jest dobre miejsce na Twoje w³asne makra i~¶rodowiska:
\newtheorem{defi}{Definicja}[section]

% koniec definicji

\begin{document}
\maketitle

%tu idzie streszczenie na strone poczatkowa
\begin{abstract}
  W pracy przedstawiono sposoby wydajnej klasyfikacji szeregów czasowych dla danych pochodz±cych ze ¼ród³a o zmiennym rozk³adzie. Opisane zosta³y metody ekstrakcji cech z wielowymiarowego szeregu czasowego. Autor opisuje tak¿e metody wyboru przestrzeni atrybutów odpornej na zmiany rozk³adu ¼ród³a.
\end{abstract}

\tableofcontents
%\listoffigures
%\listoftables


\chapter{Wprowadzenie}\label{r:wprowadzenie}

\section{Uczenie z nadzorem a \textit{concept drift}} \label{s:superv}

Podstawowym problemem rozwa¿anym w teorii uczenia maszynowego jest problem uczenia z nadzorem (ang. \textit{supervised learning}). Niech dane bêd±:
\begin{itemize}
\item zbiór $X$ przyk³adów
\item zbiór $Y$ decyzji
\item funkcja $f: X \rightarrow Y$
\item Parê zbiorów $(X_{train} \subseteq X, Y_{train} \subseteq Y)$ instancji $x_1, x_2, \dots, x_n$ oraz odpowiadaj±cych im decyzji $f(x_1), f(x_2), \dots, f(x_n)$, zwan± \textit{zbiorem treningowym}
\end{itemize}
Zadanie uczenia z nadzorem polega na wyznaczeniu na podstawie zbioru treningowego oraz przy u¿yciu pewnego algorytmu ucz±cego (\textit{klasyfikatora}) takiej funkcji $c: X \rightarrow Y$ (zwanej \textit{modelem}) bêd±cej dobr± aproksymacj± funkcji $f$. Jako¶æ modelu $c$ okre¶la siê, porównuj±c jego warto¶ci dla elementów skoñczonego \textit{zbioru testowego} $X_{test}$ z rzeczywistymi warto¶ciami funkcji $f$ dla tych elementów. Istotne jest przy tym za³o¿enie, ¿e elementy zbiorów $X_{train}$ oraz $X_{test}$ losowane s± ze zbioru $X$ wed³ug tego samego rozk³adu prawdopodobieñstwa $D$. \\

Schemat rozwi±zywania problemu uczenia z nadzorem przedstawia rys. \ref{supervised}. \\

\begin{figure}[t!]
\centering
\includegraphics[scale=0.8]{supervised.png}
\caption{Schemat uczenia z nadzorem \label{supervised}}
\end{figure}


Na przestrzeni ostatnich dziesiêcioleci opracowanych zosta³o wiele algorytmów ucz±cych wykazuj±cych siê du¿± skuteczno¶ci± w przeró¿nych dziedzinach: od rozpoznawania obrazów, przez klasyfikacjê tekstów, rekomendacjê produktów, wykrywanie spamu, po przewidywanie zmian na gie³dzie czy diagnostykê medyczn±. \\

Sytuacja zmienia siê diametralnie, gdy pominiemy za³o¿enie o równo¶ci rozk³adów dla zbiorów treningowych i testowych. Problem ten nazywa siê \textit{ewolucj± pojêæ} (ang. \textit{concept drift}) lub \textit{dopasowaniem dziedziny} (ang. \textit{domain adaptation}). Jest on szczególnie widoczny w zadaniach przetwarzania jêzyka naturalnego (ang. \textit{natural language processing}, w skrócie NLP). Rozpatrzmy dla przyk³adu problem rozpoznawania nazw w³asnych (ang. \textit{named entity recognition}). Za³ó¿my, ¿e klasyfikator uczony jest na podstawie danych encyklopedycznych oraz testowany na danych pochodz±cych z komunikatora internetowego. Obydwa zbiory, jakkolwiek powi±zane, ró¿ni± siê w znacz±cy sposób - przyk³adowo, szukanie wielkich liter mo¿e byæ bardzo pomocne w pierwszej dziedzinie, a nie¶æ znacznie mniej informacji w wiadomo¶ciach z komunikatora.\\
St±d te¿ w³a¶nie w dziedzinie NLP powsta³o najwiêcej metod maj±cych rozwi±zaæ problem ewoluuj±cych pojêæ. Przyk³adami takich metod s± algorytm \textit{structural correspondence learning} opisywany w \cite{1} czy metoda odpowiedniego dopasowania przestrzeni parametrów zaproponowana przez Daume w \cite{2}. \\

Problem \textit{domain adaptation} nie jest jednak czêsto poruszany w przypadku klasyfikacji szeregów czasowych. W poni¿szej pracy autor przedstawia sposoby radzenia sobie z \textit{concept drift} podczas klasyfikacji szeregów czasowych oraz wykonuje studium przypadku na wybranym zbiorze danych.

\section{Formalizacja problemu}

\subsection{Paradygmaty uczenia siê}

Przyjmijmy definicje jak na pocz±tku sekcji \ref{s:superv}. W zale¿no¶ci od rozk³adów $D_{train}$, $D_{test}$ oraz od dostêpno¶ci zbiorów $Y_{train}, X_{test}, Y_{test}$, mo¿na (za \cite{arnold3}) zdefiniowaæ inne paradygmaty uczenia. \\
I tak, je¶li zbiór $Y_{train}$ jest nieznany w momencie tworzenia modelu, mamy do czynienia z \textit{uczeniem bez nadzoru} (ang. \textit{unsupervised learning}). \\
Gdy zbiór $X_{test}$ nie jest znany podczas uczenia, mowa o \textit{uczeniu indukcyjnym} (ang. \textit{inductive learning}). W przeciwnym razie takie uczenie nazywa siê \textit{uczeniem transdukcyjnym} (ang. transductive learning). \\
W powy¿szym przyk³adach istotne jest za³o¿enie, i¿ zbiory $X_{train}$, $X_{test}$ pochodz± z tego samego rozkladu $D$. Odwrotna sytuacja rozpatrywana jest w paradygmacie \textit{uczenia z przeniesieniem wiedzy} (ang. \textit{transfer learning}). Przyjmuje siê w nim, ¿e dane s± dwa ró¿ne rozk³ady $D^{source}$ i $D^{target}$. Model wyuczony na danych treningowych $X^{source}_{train}, Y^{source}_{train}$ wykorzystywany jest zatem do klasyfikacji zbioru testowego $X^{target}_{test}, Y^{target}_{test}$ pochodz±cych z rozk³adu $D^{target}$. W poni¿szej pracy autor skupia siê na problemie \textit{dopasowania dziedziny}, który zak³ada, ¿e zbiór dostêpnych klas $Y$ jest ten sam dla $D^{source}$ i $D^{target}$. Przeciwieñstwem dopasowania dziedziny jest zadanie \textit{uczenia wielozadaniowego} (ang. \textit{multi-task learning}, wiêcej miêdzy innymi w \cite{4}), gdzie zbiory $X_{train}$, $ X_{test}$ pochodz± z tego samego rozk³adu, natomiast zbiory $Y_{train}$, $Y_{test}$ s± ró¿ne. \\

Powy¿sze rozwa¿ania podsumowuje tabela \ref{t:paradigms}. \\

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{Paradygmaty uczenia w teorii uczenia maszynowego. We wszystkich przypadkach zak³adamy, ¿e zbiór $X_{train}$ jest dostêpny podczas uczenia, podczas gdy zbiór $Y_{test}$ nie jest znany.}
\label{t:paradigms}
\begin{tabular}{|c|c|c|c|}
\hline
Paradygmat & $Y_{train}$ dostêpny? & $X_{test}$ dostêpny? & Rozk³ad danych testowych \\ \hline
\makecell{Indukcyjne uczenie \\ bez nadzoru}  & Nie & Nie & $D^{source}$ \\ \hline
\makecell{Transdukcyjne uczenie \\ bez nadzoru}  & Nie & Tak & $D^{source}$ \\ \hline
\makecell{Indukcyjne uczenie \\ z nadzorem}  & Tak & Nie & $D^{source}$ \\ \hline
\makecell{Transdukcyjne uczenie \\ z nadzorem}  & Tak & Tak & $D^{source}$ \\ \hline
\makecell{Indukcyjne uczenie \\ bez nadzoru \\ z przeniesieniem wiedzy}  & Nie & Nie & $D^{target}$ \\ \hline
\makecell{Transdukcyjne uczenie \\ bez nadzoru \\ z przeniesieniem wiedzy}  & Nie & Tak & $D^{target}$ \\ \hline
\makecell{Indukcyjne uczenie \\ z nadzorem \\ z przeniesieniem wiedzy}  & Tak & Nie & $D^{target}$ \\ \hline
\makecell{Transdukcyjne uczenie \\ z nadzorem \\ z przeniesieniem wiedzy}  & Tak & Tak & $D^{target}$ \\ \hline
\end{tabular}
\end{table}

W poni¿szej pracy autor skupi siê na problemie transdukcyjnego uczenia z nadzorem z przeniesieniem wiedzy. Przedstawione zostan± algorytmy, które wykorzystuj± dostêpny zbiór $X_{test}$ do znalezienia reprezentacji odpornej na zmiany rozk³adu, co skutkowaæ bêdzie zwiêkszon± jako¶ci± klasyfikacji w stosunku do standardowego podej¶cia opisanego w \ref{s:superv}.

\subsection{Ewolucja pojêæ a \textit{overfitting}}

Mówi±c o problemie ewoluuj±cych pojêæ, nale¿y wspomnieæ o zagadnieniu przeuczenia (ang. \textit{overfitting}). Polega on na zbudowaniu nadmiernie skomplikowanego modelu, co skutkuje s³ab± jego jako¶ci±. \\
Obydwa pojêcia mog± byæ mylone przy niew³a¶ciwym sposobie walidacji modelu. Je¶li jako¶æ klasyfikacji sprawdzana jest wy³±cznie na zbiorach treningowym i testowym, zarówno \textit{concept drift}, jak i \textit{overfitting} daj± podobne objawy - wysoki wynik na zbiorze treningowym oraz niski na zbiorze testowym. W przypadku przeuczenia jest to spowodowane nadmiernym dopasowaniem modelu do danych treningowych i jego nisk± zdolno¶ci± do uogólniania. Je¶li mamy do czynienia z ewoluuj±cymi pojêciami, s³aba jako¶æ modelu jest spowodowana innym rozk³adem dla zbioru testowego. \\
W rozró¿nienu obydwu sytuacji pomagaæ mo¿e zastosowanie \textit{walidacji krzy¿owej} (ang. \textit{cross-validation}) na zbiorze treningowym. Walidacja krzy¿owa polega na podziale zbioru treningowego na $n$ równolicznych czê¶ci. Nastêpnie budowane jest $n$ modeli, przy czym $n - 1$ czê¶ci tworzy zbiór treningowy, natomiast pozosta³a czê¶æ - zbiór testowy. Ostateczny wynik jest ¶rednim wynikiem powsta³ych $n$ modeli. \\
Nietrudno zauwa¿yæ, ¿e w przypadku \textit{concept drift} nie powinno siê zauwa¿yæ znacznego spadku jako¶ci modelu przy wykonaniu walidacji krzy¿owej - w tym przypadku zbiór testowym pochodzi z tej samej dziedziny co treningowy. Inaczej bêdzie w przypadku przeuczenia - tu wynik walidacji krzy¿owej bêdzie wyra¼nie ni¿szy ni¿ wynik na zbiorze treningowym (tabela \ref{t:overfit}). \\ 

\begin{table}[ht]
\centering
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{\textit{Concept drift} a \textit{overfitting} - obni¿ony wynik modelu 1. przy walidacji krzy¿owej ¶wiadczy o przeuczeniu, a nie wystêpowaniu ewoluuj±cych pojêæ. W drugim przypadku model mimo dobrej umiejêtno¶ci klasyfikacji elementów pochodz±cych z rozk³adu $D^{source}$, cierpi na spadek jako¶ci przy ewaluacji na zbiorze pochodz±cym z rozk³adu $D^{target}$.}
\label{t:overfit}
\begin{tabular}{|c|c|c|c|}
\hline
  & Wynik na $X_{train}$ & Wynik CV & Wynik na $X_{test}$ \\ \hline
Model 1  & 0.98 & 0.73 & 0.68 \\ \hline
Model 2  & 0.97 & 0.92 & 0.76 \\ \hline
\end{tabular}
\end{table}


\chapter{Opis przeprowadzanego eksperymentu}\label{r:wprowadzenie}

\section{Przedstawienie badanego problemu} \label{s:problem}

\subsection{Opis zbioru danych} \label{ss:data}

Dane, na których sprawdzana by³a jako¶æ analizowanych algorytmów, pochodz± z konkursu \textit{AAIA'15 Data Mining Competition: Tagging Firefighter Activities at a Fire Scene}\footnote{https://knowledgepit.fedcsis.org/contest/view.php?id=106} organizowanego przez Uniwersytet Warszawski oraz Szko³ê G³ówn± S³u¿by Po¿arniczej w Warszawie. \\
Na potrzeby konkursu zebrano odczyty pochodz±ce z "inteligentnego kombinezonu", który monitoruje ruchy oraz funkcje ¿yciowe stra¿aka. W sk³ad kombinezonu wchodzi³o po siedem akcelerometrów i ¿yroskopów umieszczonych na: tu³owiu, ramionach, d³oniach i nogach (rys. \ref{fireman}).

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.4]{fireman.png}
\caption{Rozmieszczenie czujników na ciele stra¿aka \label{fireman}}
\end{figure}

Ka¿da instancja w zbiorze danych sk³ada³a siê z zebranych w krótkich odcinkach czasu (oko³o 1.8 s) odczytów z zamontowanych sensorów. Dla ka¿dego akcelerometru oraz ¿yroskopu zebrano po 400 odczytów wzd³u¿ osi $x$, $y$, $z$, wraz ze wzglêdnym czasem wykonania odczytu. Dla ka¿dego wiersza daje to 42 - wymiarowy szereg czasowy o d³ugo¶ci 400. Jak ³atwo wywnioskowaæ, ¶redni odstêp miêdzy kolejnymi odczytami wynosi³ oko³o 4.5 ms. Zestaw atrybutów uzupe³nia³y dodatkowo 42 agregaty ze wskazañ urz±dzeñ monitoruj±cych funkcje ¿yciowe stra¿aka (takie jak EKG, czêstotliwo¶æ oddechu, temperatura skóry). Nieprzetworzone dane zawiera³y wiêc $400 * 43 + 42 = 17242$ atrybuty. Zarówno zbiór treningowy, jak i testowy sk³ada³y siê z $20000$ przyk³adów. Bardzo istotny dla dla analizy tego zbioru danych okaza³ siê fakt, ¿e dane treningowe i testowe pochodzi³y od ró¿nych czteroosobowych grup stra¿aków. \\
Zadaniem uczestników konkursu by³o przypisanie ka¿dej instancji w zbiorze postury stra¿aka w danym momencie oraz wykonywanej przez niego czynno¶ci. Zastosowane algorytmy mia³y pomóc w stworzeniu systemu monitoruj±cego bezpieczeñstwo stra¿aka podczas akcji. \\

Jako ¿e problem klasyfikacji wieloetykietowej nie jest tematem niniejszej pracy, autor postanowi³ skupiæ siê na problemie przewidywania czynno¶ci wykonywanej przez stra¿aka. Zbiór klas liczy³ wiêc $16$ elementów. Postawiony problem utrudnia³ dodatkowo fakt, ¿e klasy by³y wysoce niezbalansowane - najczêstsza klasa ($manipulating$) wyst±pi³a w zbiorze treningowym $6349$ razy, podczas gdy najrzadsza ($signal\_hose\_pullback$) - jedynie 98 razy.\\
Rozk³ad klas przedstawia rys. \ref{classes}. \\

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.6]{classes.png}
\caption{Rozk³ad klas w zbiorze treningowym \label{classes}}
\end{figure}

\subsection{Ewaluacja jako¶ci klasyfikatora} \label{ss:evaluation}

Standardow± miar± jako¶ci jest prezycja (ang. \textit{accuracy}):
\begin{displaymath}
ACC(c) = \frac{1}{n} \sum_{i=1}^n \mathbf{1}[c(\textbf{x}_i) = y_i]
\end{displaymath}

W opisywanym konkursie zastosowano modyfikacjê tej miary zwan± \textit{balanced accuracy}, zdefiniowan± nastêpuj±co:

\begin{equation}
ACC_i(c) = \frac{|j: \,c(\textbf{x}_j) = y_j = i|}{|j: y_j = i|} \\
\end{equation}

\begin{equation} \label{bac}
BAC(c) = \frac{\sum_{i=1}^l ACC_i(c)}{l} 
\end{equation}
Nietrudno zauwa¿yæ, ¿e miara $BAC$ jest bardziej wra¿liwa na b³êdn± klasyfikacjê rzadkich klas ni¿ standardowa miara $ACC$.

\section{Opis u¿ytych klasyfikatorów} \label{s:klasyfikatory}

W kolejnych rozdzia³ach przedstawione zostan± metody maj±ce na celu zwiêkszenie jako¶ci modelu budowanego na danych, w których obecny jest problem ewoluuj±cych pojêæ. U¿yteczno¶æ tych metod sprawdzana bêdzie dla trzech ró¿nych algorytmów uczenia: klasyfikatorze opartym na regresji logistycznej, maszynie wektorów no¶nych (ang. \textit{support vector machine}, SVM) oraz drzewach decyzyjnych.

\subsection{Klasyfikator liniowy} \label{ss:linear}

Regresja logistyczna i maszyna wektorów wspieraj±cych nale¿± do grupy klasyfikatorów liniowych. Przyjmijmy oznaczenia jak w sekcji \ref{s:superv}. Za³ó¿my, ¿e zbiór klas $Y$ jest dwuelementowy - dla uproszczenia niech $Y = \{+1, -1 \}$. Niech dalej $y \in Y$ bêdzie decyzj± dla elementu $\textbf{x} = (x_1, x_2, \dots, x_m) \in X \subseteq \mathbb{R}^m$. Klasyfikatorem liniowym nazywamy $m - 1$ - wymiarow± hiepr³aszczyznê rozdzielaj±c± punkty z $X$. Niech $\textbf{w} = (w_1, w_2, \dots, w_m) \in \mathbb{R}^m$ bêdzie wektorem wspó³czynników tej hiperp³aszczyzny. Uczenie klasyfikatora liniowego zwykle polega na minimalizacji warto¶ci pewnej funkcji b³êdu $l(\textbf{w})$ na zbiorze treningowym.

\subsubsection{Klasyfikacja oparta na regresji logistycznej (\textit{logit})}

Niech
\begin{displaymath}
g(z) = \frac{1}{1 + e^{-z}}
\end{displaymath}
zwana bêdzie funkcj± logistyczn±. Jej wykres przedstawia rysunek \ref{sigmoid}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.3]{sigmoid.png}
\caption{Wykres funkcji sigmoidalnej \label{sigmoid}}
\end{figure}

Funkcja $g$ jest oczywi¶cie ci±g³a. Jednocze¶nie $lim_{z \to -\inf} g(z) = 0$ oraz $lim_{z \to \inf} g(z) = 1$. Dziêki tym w³a¶ciwo¶ciom nadaje siê ona do modelowania prawdopodobieñstwa jakiego¶ zjawiska. Klasyfikator bazuj±cy na regresji logistycznej modeluje prawdopodobieñstwo nale¿enia do klasy pozytywnej przez funkcjê:
\begin{displaymath}
p_w(\textbf{x}) = g(\textbf{w}^\intercal\textbf{x}) = \frac{1}{1 + e^{-\textbf{w}^\intercal\textbf{x}}},
\end{displaymath}

przy czym klasyfikacja dokonywana jest przez: 

\begin{displaymath}
c_w(\textbf{x}) = 1 \iff p_w(\textbf{x}) \geq \frac{1}{2}.
\end{displaymath}

Funkcja straty zdefiniowana jest nastêpuj±co:

\begin{displaymath}
l_{log\_loss}(\textbf{w}) = \sum_{i = i}^n log(1 + e^{-y_i\textbf{w}^\intercal\textbf{x}_i}).
\end{displaymath}

\subsubsection{Maszyna wektorów no¶nych}

Innym typem klasyfikatora liniowego jest (ang. \textit{support vector machine}, SVM). Uczenie SVM polega na znalezieniu hiperp³aszczyzny o najwiêkszej odleg³o¶ci od punktów obydwu klas (rys. \ref{svm}) - z tego powodu SVM nazywany jest klasyfikatorem maksymalnego marginesu (ang. \textit{max margin classifier}).

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.4]{svm.png}
\captionsetup{justification=centering}
\captionsetup{width=0.8\textwidth}
\caption{P³aszczyzna $H_1$ nie rozdziela klas. \\ P³aszczyzna $H_2$ rozdziela je, ale z niewielkim marginesem. \\P³aszczyzna $H_3$ rozdziela je z maksymalnym marginesem. \label{svm}}
\end{figure}

Za³o¿enie o liniowej separowalno¶ci klas jest jednak rzadko spe³nione. Uczenie klasyfikatora SVM polega wiêc na znalezieniu hiperp³aszczyzny $\textbf{w}$, która minimalizuje funkcjê
straty dan± jako

\begin{displaymath}
l_{hinge\_loss}(\textbf{w}) = \sum_{i = i}^n max(0, 1 - y_i\textbf{w}^\intercal\textbf{x}_i).
\end{displaymath}

\subsubsection{Klasyfikator "jeden przeciwko wszystkim"}

Jak wspomniano wcze¶niej, zarówno regresja logistyczna, jak i SVM s± klasyfikatorami binarnymi - zak³adaj±, ¿e zbiór klas $Y$ jest dwuelementowy. Aby u¿yæ ich do klasyfikacji danego zbioru, potrzebna by³a metoda klasyfikacji wieloklasowej. Zastosowano podej¶cie zwane "jeden przeciw wszystkim" (ang. \textit{one-vs.-all}, OvA, b±d¼ \textit{one-vs.-rest}, OvR). \\
Niech $Y = \{1, 2, \dots, k \}$. Klasyfikacja OvA polega na nauczeniu $k$ binarnych klasyfikatorów $c_1, c_2, \dots, c_k$. Klasa dla $j$ - tego klasyfikatora zdefiniowana jest nastêpuj±co:

\begin{displaymath}
y^j_i = 1 \iff y_i = j
\end{displaymath}

Ostatecznie elementowi $x$ przypisywana jest klasa, której klasyfikator daje najmniejsz± warto¶æ funkcji b³êdu:

\begin{displaymath}
c(\textbf{x}) = arg \min_{j \in 1\dots k} \,  l_j(\textbf{x})
\end{displaymath}


\subsection{Lasy losowe} \label{ss:random_forest}
Innym typem klasyfikatora jest las losowy. Jest to klasyfikator wykorzystuj±cy prostszy klasyfikator - drzewo decyzyjne. Drzewo decyzyjne to etykietowane drzewo, którego ka¿dy wêze³ odpowiada przeprowadzeniu pewnego testu na warto¶ciach atrybutów. Z wêz³a wewnêtrznego wychodzi tyle ga³êzi, ile jest mo¿liwych wyników testu odpowiadaj±cego temu wêz³owi. Ka¿dy li¶æ zawiera decyzjê o klasyfikacji obiektu. Przyk³adowe drzewo decyzyjne przedstawia rys. \ref{dec_tree}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.6]{decision_tree.png}
\caption{Przyk³adowe drzewo decyzyjne \label{dec_tree}}
\end{figure}

Uczenie lasu losowego polega na uczeniu okre¶lonej liczby drzew decyzyjnych - ka¿dego na losowej podprzestrzeni atrybutów. Finalna klasa jest mod± klas wyznaczonych przez poszczególne drzewa. Lasy losowe, podpbnie jak drzewa decyzyjne, wspieraj± klasyfikacjê wieloklasow±.

\section{Przyk³ad Ewolucji pojêæ w analizowanym zbiorze} \label{s:data_concept_drift}

Okazuje siê, ¿e g³ównym wyzwaniem w konkursie opisywanym w sekcji \ref{ss:data} s± ró¿nice w wykonywaniu poszczególnych czynno¶ci miêdzy stra¿akami. Aby siê o tym przekonaæ, nauczono las losowy na $42$ atrybutach opisuj±cych funkcje ¿yciowe, nastêpnie zmierzono jego jako¶æ (u¿ywaj±c miary $BAC$) na zbiorach treningowym i testowym. Do pomiaru jako¶ci na zbiorze treningowym zastosowano trójwarstwow± walidacjê krzy¿ow±. Problem \textit{concept drift} spowodowa³ drastyczne obni¿enie jako¶ci klasyfikatora, która spad³a z $0.993$ na $0.079$. 

\chapter{Ekstrakcja cech z szeregów czasowych} \label{c:features}

\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliografia}

\bibitem[1]{1} John Blitzer, Ryan McDonald, Fernando Pereira, \textit{Domain adaptation with structural correspondence learning}

\bibitem[2]{2} Hall Daume, \textit{Frustratingly easy domain adaptation}

\bibitem[3]{3} Andrew Arnold, Ramesh Nallapati, William W. Cohen, \textit{A comparative study of methods for transductive transfer learning}

\bibitem[4]{4} R. K. Ando, T. Zhang, \textit{A framework for learning predictive structures from multiple tasks and unlabeled data}

\bibitem[4]{4} L. Breiman, \textit{Random forests}, Machine Learning, 45(1), 5-32, 2001.


\end{thebibliography}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: latin-2
%%% End:
